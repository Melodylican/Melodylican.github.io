<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[MySQL分库分表环境下全局ID生成方案]]></title>
      <url>http://Melodylican.github.io/2017/11/03/MySQL%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%85%A8%E5%B1%80ID%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88/</url>
      <content type="html"><![CDATA[<h1 id="MySQL分库分表环境下全局ID生成方案"><a href="#MySQL分库分表环境下全局ID生成方案" class="headerlink" title="MySQL分库分表环境下全局ID生成方案"></a>MySQL分库分表环境下全局ID生成方案</h1><p>在大型互联网应用中，随着用户数的增加，为了提高应用的性能，我们经常需要对数据库进行分库分表操作。在单表时代，我们可以完全依赖于数据库的自增 ID来唯一标识一个用户或数据对象。但是当我们对数据库进行了分库分表后，就不能依赖于每个表的自增ID来全局唯一标识这些数据了。因此，我们需要提供一 个全局唯一的ID号生成策略来支持分库分表的环境。下面来介绍两种非常优秀的解决方案：<br><a id="more"></a></p>
<h2 id="数据库自增ID——来自Flicker的解决方案"><a href="#数据库自增ID——来自Flicker的解决方案" class="headerlink" title="数据库自增ID——来自Flicker的解决方案"></a>数据库自增ID——来自Flicker的解决方案</h2><p>因为MySQL本身支持auto_increment操作，很自然地，我们会想到借助这个特性来实现这个功能。Flicker在解决全局ID生成方 案里就采用了MySQL自增长ID的机制（auto_increment + replace into + MyISAM）。一个生成64位ID方案具体就是这样的：<br>先创建单独的数据库(eg:ticket)，然后创建一个表：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE Tickets64 (</div><div class="line">            id bigint(20) unsigned NOT NULL auto_increment,</div><div class="line">            stub char(1) NOT NULL default &apos;&apos;,</div><div class="line">            PRIMARY KEY  (id),</div><div class="line">            UNIQUE KEY stub (stub)</div><div class="line">    ) ENGINE=MyISAM</div></pre></td></tr></table></figure></p>
<p>当我们插入记录后，执行SELECT * from Tickets64，查询结果就是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">+-------------------+------+</div><div class="line">| id                | stub |</div><div class="line">+-------------------+------+</div><div class="line">| 72157623227190423 |    a |</div><div class="line">+-------------------+------+</div></pre></td></tr></table></figure></p>
<p>在我们的应用端需要做下面这两个操作，在一个事务会话里提交：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">REPLACE INTO Tickets64 (stub) VALUES (&apos;a&apos;);</div><div class="line">SELECT LAST_INSERT_ID();</div></pre></td></tr></table></figure></p>
<p>这样我们就能拿到不断增长且不重复的ID了。<br>到上面为止，我们只是在单台数据库上生成ID，从高可用角度考虑，接下来就要解决单点故障问题：<strong>Flicker</strong>启用了两台数据库服务器来生成ID，通过区分auto_increment的起始值和步长来生成<strong>奇偶数</strong>的ID。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">TicketServer1:</div><div class="line">auto-increment-increment = 2</div><div class="line">auto-increment-offset = 1</div><div class="line"></div><div class="line">TicketServer2:</div><div class="line">auto-increment-increment = 2</div><div class="line">auto-increment-offset = 2</div></pre></td></tr></table></figure></p>
<p>最后，在客户端只需要通过<strong>轮询方式</strong>取ID就可以了。</p>
<p><strong>优点</strong>：充分借助数据库的自增ID机制，提供高可靠性，生成的ID有序。<br><strong>缺点</strong>：占用两个独立的MySQL实例，有些浪费资源，成本较高。<br>参考：<a href="http://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/" target="_blank" rel="external">http://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/</a></p>
<h2 id="独立的应用程序——来自Twitter的解决方案"><a href="#独立的应用程序——来自Twitter的解决方案" class="headerlink" title="独立的应用程序——来自Twitter的解决方案"></a>独立的应用程序——来自Twitter的解决方案</h2><p>Twitter在把存储系统从MySQL迁移到Cassandra的过程中由于Cassandra没有顺序ID生成机制，于是自己开发了一套全局唯一ID生成服务：Snowflake。GitHub地址：<a href="https://github.com/twitter/snowflake" target="_blank" rel="external">https://github.com/twitter/snowflake</a>。根据twitter的业务需求，snowflake系统生成64位的ID。由3部分组成：</p>
<p>41位的时间序列（精确到毫秒，41位的长度可以使用69年）<br>10位的机器标识（10位的长度最多支持部署1024个节点）<br>12位的计数顺序号（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号）<br>最高位是符号位，始终为0。</p>
<p><strong>优点</strong>：高性能，低延迟；独立的应用；按时间有序。<br><strong>缺点</strong>：需要独立的开发和部署。</p>
<font color="red"><strong>注</strong>：last_insert_id()的值是由MySQL server来维护的，而且是为每条连接维护独立的值，也即，某条连接调用last_insert_id()获取到的值是这条连接最近一次insert操作执行后的自增值，该值不会被其它连接的sql语句所影响。这个行为保证了不同的连接能正确地获取到它最近一次insert sql执行所插入的行的自增值，也就是说，last_insert_id()的值不需要通过加锁或事务机制来保证其在多连接场景下的正确性.</font>

<h2 id="在Twitter基础上的改进"><a href="#在Twitter基础上的改进" class="headerlink" title="在Twitter基础上的改进"></a>在Twitter基础上的改进</h2><p>可参考 <a href="http://geek.csdn.net/news/detail/72973" target="_blank" rel="external">http://geek.csdn.net/news/detail/72973</a> </p>
<h2 id="使用缓存队列"><a href="#使用缓存队列" class="headerlink" title="使用缓存队列"></a>使用缓存队列</h2><p>使用队列服务，如redis、memcacheq等等，将一定量的ID预分配在一个队列里，每次插入操作，先从队列中获取一个ID，若插入失败的话，将该ID再次添加到队列中，同时监控队列数量，当小于阀值时，自动向队列中添加元素。<br>这种方式可以有规划的对ID进行分配，还会带来经济效应，比如ＱＱ号码，各种靓号，明码标价。如网站的userid, 允许uid登陆，推出各种靓号，明码标价，对于普通的ID打乱后再随机分配。</p>
<h2 id="在Redis中使用lua脚本"><a href="#在Redis中使用lua脚本" class="headerlink" title="在Redis中使用lua脚本"></a>在Redis中使用lua脚本</h2><p>详细参见——<a href="http://blog.csdn.net/hengyunabc/article/details/19025973" target="_blank" rel="external">http://blog.csdn.net/hengyunabc/article/details/19025973</a></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> MySQL </tag>
            
            <tag> 分库分表 </tag>
            
            <tag> 全局ID </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java 线程间的状态转换]]></title>
      <url>http://Melodylican.github.io/2017/11/02/%E7%BA%BF%E7%A8%8B%E9%97%B4%E7%9A%84%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2/</url>
      <content type="html"><![CDATA[<p>线程间的状态转换： </p>
<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.jpg" alt=""><br></center><br><a id="more"></a></p>
<ol>
<li><p><strong>新建(new)</strong>：新创建了一个线程对象。</p>
</li>
<li><p><strong>可运行(runnable)</strong>：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。</p>
</li>
<li><p><strong>运行(running)</strong>：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。</p>
</li>
<li><p><strong>阻塞(block)</strong>：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种：<br> (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。</p>
<p> (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。</p>
<p> (三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。</p>
</li>
<li><p><strong>死亡(dead)</strong>：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 线程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java技能图谱]]></title>
      <url>http://Melodylican.github.io/2017/11/01/java%E6%8A%80%E8%83%BD%E5%9B%BE%E8%B0%B1/</url>
      <content type="html"><![CDATA[<center><br><img src="http://ojwkevhas.bkt.clouddn.com/2.1%20JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E5%9B%BE%E8%B0%B1.png" alt=""><br><a id="more"></a><br><img src="http://ojwkevhas.bkt.clouddn.com/1.2%20Java%E6%9E%B6%E6%9E%84%E5%B8%88%E5%9B%BE%E8%B0%B1.jpg" alt=""><br><br><img src="http://ojwkevhas.bkt.clouddn.com/2.3%20Java%E9%9B%86%E5%90%88%E5%9B%BE%E8%B0%B1.jpg" alt=""><br><br><img src="http://ojwkevhas.bkt.clouddn.com/2.7%20Java%20Set%E7%B1%BB%E5%9B%BE.jpg" alt=""><br><br><img src="http://ojwkevhas.bkt.clouddn.com/2.5%20Java%20List%E7%B1%BB%E5%9B%BE.jpg" alt=""><br><br><img src="http://ojwkevhas.bkt.clouddn.com/2.4%20Java%E9%9B%86%E5%90%88%E7%B1%BB%E5%9B%BE.jpg" alt=""><br><br><img src="http://ojwkevhas.bkt.clouddn.com/2.2%20Java%E5%B9%B6%E5%8F%91%E5%9B%BE%E8%B0%B1.jpg" alt=""><br></center>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Java技能图谱 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch日志清理脚本]]></title>
      <url>http://Melodylican.github.io/2017/10/20/ES%E6%97%A5%E5%BF%97%E6%B8%85%E9%99%A4%E5%B7%A5%E5%85%B7%E8%84%9A%E6%9C%AC/</url>
      <content type="html"><![CDATA[<p>有的时候我们在使用ES时，由于资源有限或业务需求，我们只想保存最近一段时间的数据，所以有如下脚本可以定时删除数据</p>
<a id="more"></a> 
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/sh</span></div><div class="line"><span class="comment"># example: sh  delete_es_by_day.sh logstash-* logsdate 30</span></div><div class="line"></div><div class="line">index_name=<span class="variable">$1</span></div><div class="line">daycolumn=<span class="variable">$2</span></div><div class="line">savedays=<span class="variable">$3</span></div><div class="line">format_day=<span class="variable">$4</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ ! -n <span class="string">"<span class="variable">$savedays</span>"</span> ]; <span class="keyword">then</span></div><div class="line">  <span class="built_in">echo</span> <span class="string">"the args is not right,please input again...."</span></div><div class="line">  <span class="built_in">exit</span> 1</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ ! -n <span class="string">"<span class="variable">$format_day</span>"</span> ]; <span class="keyword">then</span></div><div class="line">   format_day=<span class="string">'%Y%m%d'</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line">sevendayago=`date <span class="_">-d</span> <span class="string">"-<span class="variable">$&#123;savedays&#125;</span> day "</span> +<span class="variable">$&#123;format_day&#125;</span>`</div><div class="line"></div><div class="line">curl -XDELETE <span class="string">"172.16.150.170:9200/<span class="variable">$&#123;index_name&#125;</span>/_query?pretty"</span> <span class="_">-d</span> <span class="string">"</span></div><div class="line">&#123;</div><div class="line">        "query<span class="string">": &#123;</span></div><div class="line">                "filtered<span class="string">": &#123;</span></div><div class="line">                        "filter<span class="string">": &#123;</span></div><div class="line">                                "bool<span class="string">": &#123;</span></div><div class="line">                                        "must<span class="string">": &#123;</span></div><div class="line">                                                "range<span class="string">": &#123;</span></div><div class="line">                                                        "<span class="variable">$&#123;daycolumn&#125;</span><span class="string">": &#123;</span></div><div class="line">                                                                "from<span class="string">": null,</span></div><div class="line">                                                                "to<span class="string">": <span class="variable">$&#123;sevendayago&#125;</span>,</span></div><div class="line">                                                                "include_lower<span class="string">": true,</span></div><div class="line">                                                                "include_upper<span class="string">": true</span></div><div class="line">                                                        &#125;</div><div class="line">                                                &#125;</div><div class="line">                                        &#125;</div><div class="line">                                &#125;</div><div class="line">                        &#125;</div><div class="line">                &#125;</div><div class="line">        &#125;</div><div class="line">&#125;"</div><div class="line"></div><div class="line"><span class="built_in">echo</span> <span class="string">"ok"</span></div></pre></td></tr></table></figure>
<p>注解：脚本传入参数说明：1.索引名；2.日期字段名；3.保留最近几天数据，单位天；4.日期格式，可不输（默认形式20171020）</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux日志清理]]></title>
      <url>http://Melodylican.github.io/2017/10/16/Linux%E5%AE%9A%E6%97%B6%E6%B8%85%E7%90%86%E6%97%A5%E5%BF%97/</url>
      <content type="html"><![CDATA[<p>linux是一个很能自动产生文件的系统，日志、邮件、备份等。虽然现在硬盘廉价，我们可以有很多硬盘空间供这些文件浪费，让系统定时清理一些不需要的文件很有一种爽快的事情。不用你去每天惦记着是否需要清理日志，不用每天收到硬盘空间不足的报警短信，想好好休息的话，让我们把这个事情交给机器定时去执行吧。<br><a id="more"></a></p>
<p><strong>1.删除文件命令</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">find 对应目录 -mtime +天数 -name &quot;文件名&quot; -exec rm -rf &#123;&#125; \;</div></pre></td></tr></table></figure></p>
<p>实例命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">find /opt/soft/log/ -mtime +30 -name &quot;*.log&quot; -exec rm -rf &#123;&#125; \;</div></pre></td></tr></table></figure></p>
<p>说明：</p>
<p>将/opt/soft/log/目录下所有30天前带”.log”的文件删除。具体参数说明如下：</p>
<p>find：linux的查找命令，用户查找指定条件的文件；</p>
<p>/opt/soft/log/：想要进行清理的任意目录；</p>
<p>-mtime：标准语句写法；</p>
<p>+30：查找30天前的文件，这里用数字代表天数；</p>
<p>“<em>.log”：希望查找的数据类型，”</em>.jpg”表示查找扩展名为jpg的所有文件，”*”表示查找所有文件，这个可以灵活运用，举一反三；</p>
<p>-exec：固定写法；</p>
<p>rm -rf：强制删除文件，包括目录；</p>
<p>{} \; ：固定写法，一对大括号+空格++; </p>
<p><strong>2.计划任务</strong>：</p>
<p>若嫌每次手动执行语句太麻烦，可以将这小语句写到一个可执行shell脚本文件中，再设置cron调度执行，那就可以让系统自动去清理相关文件。</p>
<p><strong>2.1创建shell</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">touch /opt/soft/bin/auto-del-30-days-ago-log.sh</div><div class="line"></div><div class="line">chmod +x auto-del-30-days-ago-log.sh</div></pre></td></tr></table></figure></p>
<p>新建一个可执行文件auto-del-30-days-ago-log.sh，并分配可运行权限</p>
<p><strong>2.2编辑shell脚本</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi auto-del-30-days-ago-log.sh</div></pre></td></tr></table></figure></p>
<p>编辑auto-del-30-days-ago-log.sh文件如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#!/bin/sh</div><div class="line"></div><div class="line">find /opt/soft/log/ -mtime +30 -name &quot;*.log&quot; -exec rm -rf &#123;&#125; \;</div></pre></td></tr></table></figure>
<p>ok，保存退出(:wq)。</p>
<p><strong>2.3计划任务</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">#crontab -e</div></pre></td></tr></table></figure></p>
<p>将auto-del-30-days-ago-log.sh执行脚本加入到系统计划任务，到点自动执行</p>
<p>输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">10 0 * * * /opt/soft/log/auto-del-7-days-ago-log.sh</div></pre></td></tr></table></figure></p>
<p>这里的设置是每天凌晨0点10分执行auto-del-7-days-ago-log.sh文件进行数据清理任务了。</p>
<p>完成以上三步，你就再也不每天惦记是否硬盘空间满了，该清理日志文件了，再也不会受到服务器硬盘空间不足的报警信息了，放心的去看书喝咖啡去吧！</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[架构之路]]></title>
      <url>http://Melodylican.github.io/2017/10/12/%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%B7%AF/</url>
      <content type="html"><![CDATA[<h2 id="安全优化"><a href="#安全优化" class="headerlink" title="安全优化"></a>安全优化</h2><ul>
<li>阿里云的VPN虚拟专有网络以及安全组配置</li>
<li>自建机房的话，要自行配置防火墙安全策略</li>
<li>相关服务访问，比如Mysql、Redis、Solr等如果没有特殊需求尽量使用内网访问并设置鉴权</li>
<li>尽量使用代理服务器，不要对外开放过多的端口</li>
<li>https配合HTTP/2.0也是个不错的选择<a id="more"></a>
<h2 id="架构装逼必备词汇"><a href="#架构装逼必备词汇" class="headerlink" title="架构装逼必备词汇"></a>架构装逼必备词汇</h2><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3></li>
<li>负载均衡（负载均衡算法）</li>
<li>反向代理</li>
<li>服务隔离</li>
<li>服务限流</li>
<li>服务降级（自动优雅降级）</li>
<li>失效转移</li>
<li>超时重试</li>
<li>回滚机制</li>
</ul>
<h3 id="高并发"><a href="#高并发" class="headerlink" title="高并发"></a>高并发</h3><ul>
<li>应用缓存</li>
<li>HTTP缓存</li>
<li>多级缓存</li>
<li>分布式缓存</li>
<li>连接池</li>
<li>异步并发</li>
</ul>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><ul>
<li>二阶段提交(强一致)</li>
<li>三阶段提交(强一致)</li>
<li>消息中间件(最终一致性)，推荐阿里的RocketMQ</li>
</ul>
<h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><ul>
<li>任务队列</li>
<li>消息队列</li>
<li>请求队列</li>
</ul>
<h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><ul>
<li>单体垂直扩容</li>
<li>单体水平扩容</li>
<li>应用拆分</li>
<li>数据库拆分</li>
<li>数据库分库分表</li>
<li>数据异构</li>
<li>分布式任务</li>
</ul>
<h3 id="网络安全"><a href="#网络安全" class="headerlink" title="网络安全"></a>网络安全</h3><ul>
<li>SQL注入</li>
<li>XSS攻击</li>
<li>CSRF攻击</li>
<li>拒绝服务（DoS，Denial　of　Service）攻击</li>
</ul>
<h2 id="架构装逼必备工具"><a href="#架构装逼必备工具" class="headerlink" title="架构装逼必备工具"></a>架构装逼必备工具</h2><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><p>Linux（必备）、某软的</p>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>DNS、F5、LVS、Nginx、HAproxy、负载均衡SLB（阿里云）</p>
<h3 id="分布式框架"><a href="#分布式框架" class="headerlink" title="分布式框架"></a>分布式框架</h3><p>Dubbo、Motan、Spring-Could</p>
<h3 id="数据库中间件"><a href="#数据库中间件" class="headerlink" title="数据库中间件"></a>数据库中间件</h3><p>DRDS （阿里云）、Mycat、360 Atlas、Cobar (不维护了)</p>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>RabbitMQ、ZeroMQ、Redis、ActiveMQ、Kafka</p>
<h3 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h3><p>Zookeeper、Redis</p>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>Redis、Oscache、Memcache、Ehcache</p>
<h3 id="集成部署"><a href="#集成部署" class="headerlink" title="集成部署"></a>集成部署</h3><p>Docker、Jenkins、Git、Maven</p>
<h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><p>OSS、NFS、FastDFS、MogileFS</p>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><p>MySql、Redis、MongoDB、PostgreSQL、Memcache、HBase</p>
<h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>专用网络VPC、弹性公网IP、CDN</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 架构相关 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[解决npm install很缓慢的问题]]></title>
      <url>http://Melodylican.github.io/2017/10/10/%E8%A7%A3%E5%86%B3npm-install%E7%BC%93%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<p>使用NPM（Node.js包管理工具）安装依赖时速度特别慢，为了安装Express，执行命令后两个多小时都没安装成功，最后只能取消安装，笔者20M带宽，应该不是我网络的原因，后来在网上找了好久才找到一种最佳解决办法，在安装时可以手动指定从哪个镜像服务器获取资源，我们可以使用阿里巴巴在国内的镜像服务器，命令如下：<br><a id="more"></a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install -gd express --registry=http://registry.npm.taobao.org</div></pre></td></tr></table></figure></p>
<p>只需要使用–registry参数指定镜像服务器地址，为了避免每次安装都需要–registry参数，可以使用如下命令进行永久设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm config set registry http://registry.npm.taobao.org</div></pre></td></tr></table></figure>
<p>换了国内镜像，安装速度就很快了。</p>
<p>Ubuntu16.04亲测有效。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> npm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Kafka offset的重置]]></title>
      <url>http://Melodylican.github.io/2017/09/25/kafka-offset%E7%9A%84%E9%87%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p>最近在spark读取kafka消息时，每次读取都会从kafka最新的offset读取。但是如果数据丢失，如果在使用Kafka来分发消息，在数据处理的过程中可能会出现处理程序出异常或者是其它的错误，会造成数据丢失或不一致。这个时候你也许会想要通过kafka把数据从新处理一遍，或者指定kafka的offset读取。kafka默认会在磁盘上保存到7天的数据，你只需要把kafka的某个topic的consumer的offset设置为某个值或者是最小值，就可以使该consumer从你设置的那个点开始消费。这就需要从zk里面修改offset的值。<br> <a id="more"></a></p>
<h2 id="查询topic的offset的范围"><a href="#查询topic的offset的范围" class="headerlink" title="查询topic的offset的范围"></a>查询topic的offset的范围</h2><p>用下面命令可以查询到topic:DynamicRange broker:SparkMaster:9092的offset的最小值：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list slave6:9092 -topic videoplay --time -2</div></pre></td></tr></table></figure></p>
<h2 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">DynamicRange:0:1288</div></pre></td></tr></table></figure>
<h2 id="查询offset的最大值："><a href="#查询offset的最大值：" class="headerlink" title="查询offset的最大值："></a>查询offset的最大值：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list slave6:9092 -topic videoplay --time -1</div></pre></td></tr></table></figure>
<h2 id="输出-1"><a href="#输出-1" class="headerlink" title="输出"></a>输出</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">DynamicRange:0:7885</div></pre></td></tr></table></figure>
<p>从上面的输出可以看出topic:DynamicRange只有一个partition:0 offset范围为:[1288,7885]</p>
<p>设置consumer group的offset<br>启动zookeeper client<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/zookeeper/bin/zkCli.sh</div></pre></td></tr></table></figure></p>
<p>通过下面命令设置consumer group:DynamicRangeGroup topic:DynamicRange partition:0的offset为1288:</p>
<p>set /consumers/DynamicRangeGroup/offsets/DynamicRange/0 1288</p>
<p>注意如果你的kafka设置了zookeeper root，比如为/kafka，那么命令应该改为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">set /kafka/consumers/DynamicRangeGroup/offsets/DynamicRange/0 1288</div></pre></td></tr></table></figure></p>
<h2 id="生效"><a href="#生效" class="headerlink" title="生效"></a>生效</h2><p>重启相关的应用程序，就可以从设置的offset开始读数据了。 </p>
<p>参考：<a href="https://metabroadcast.com/blog/resetting-kafka-offsets" target="_blank" rel="external">https://metabroadcast.com/blog/resetting-kafka-offsets</a></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark应用案例-关于购物篮的设计]]></title>
      <url>http://Melodylican.github.io/2017/08/21/spark%E8%B4%AD%E7%89%A9%E7%AF%AE%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="购物篮的定义"><a href="#购物篮的定义" class="headerlink" title="购物篮的定义"></a>购物篮的定义</h3><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE1.png" alt=""><br></center>

<a id="more"></a>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE2.png" alt=""><br></center><br>　<br>### 相关概念 ###<br><br><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE3.png" alt=""><br></center>　<br><br>### 步骤 ###<br><br><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE4.png" alt=""><br></center>　　<br><br>### 编程实现 ###<br><br><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE5.png" alt=""><br></center>　<br>　<br>### 步骤 ###<br><br><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE6.png" alt=""><br></center>　<br>　　<br><br>## 程序实现 ##<br><br>### 程序 ###<br><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FileSystem</span>, <span class="type">Path</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"></div><div class="line"><span class="keyword">import</span> scala.collection.mutable</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * 使用SparkCore实现购物篮分析</div><div class="line">  */</div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">FindAssociationRulesSparkCore</span> </span>&#123;</div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 先从缓存中获取数据，如果不存在，直接重新获取</div><div class="line">    *</div><div class="line">    * @param items</div><div class="line">    * @param size</div><div class="line">    * @param cache</div><div class="line">    * @return</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">findItemSetsByCache</span></span>(items: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)], size: <span class="type">Int</span>, cache: mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]): <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = &#123;</div><div class="line">    cache.get(size).orElse &#123;</div><div class="line">      <span class="comment">// 获取值</span></div><div class="line">      <span class="keyword">val</span> result = findItemSets(items, size, cache)</div><div class="line"></div><div class="line">      <span class="comment">// 更新缓存</span></div><div class="line">      cache += size -&gt; result</div><div class="line"></div><div class="line">      <span class="comment">// 返回值</span></div><div class="line">      <span class="type">Some</span>(result)</div><div class="line">    &#125;.get</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 构建项集基于items商品列表，项集中的商品数量是size指定</div><div class="line">    *</div><div class="line">    * @param items 商品列表：eg: [A, B, C]</div><div class="line">    * @param size  最终项集包含商品的数量</div><div class="line">    * @return</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">findItemSets</span></span>(items: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)], size: <span class="type">Int</span>, cache: mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]): <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = &#123;</div><div class="line">    <span class="keyword">if</span> (size == <span class="number">1</span>) &#123;</div><div class="line">      <span class="comment">// items中的每个商品都是一个项集</span></div><div class="line">      items.map(item =&gt; item :: <span class="type">Nil</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// 当size不是1的时候</span></div><div class="line">      <span class="comment">// 1. 获取项集大小为size-1的项集列表</span></div><div class="line">      <span class="keyword">val</span> tmpItemSets = findItemSetsByCache(items, size - <span class="number">1</span>, cache)</div><div class="line">      <span class="comment">// 2. 给tmpItemSets中添加一个新的不重复的项 ==&gt; 数据的转换</span></div><div class="line">      <span class="keyword">val</span> itemSets = tmpItemSets.flatMap(itemSets =&gt; &#123;</div><div class="line">        <span class="comment">// 给itemSets项集添加一个新的商品ID，要求不重复</span></div><div class="line">        <span class="keyword">val</span> newItemSets = items</div><div class="line">          <span class="comment">// 将包含的商品过滤掉&amp;要求下标必须大于以及存在</span></div><div class="line">          .filter(item =&gt; !itemSets.contains(item) &amp;&amp; itemSets.forall(_._2 &lt; item._2))</div><div class="line">          <span class="comment">// 将商品添加到项集中，产生一个新的项集</span></div><div class="line">          <span class="comment">// 为了使用distinct做去重操作，进行一个排序操作</span></div><div class="line">          .map(item =&gt; (item :: itemSets))</div><div class="line"></div><div class="line">        <span class="comment">// 返回值</span></div><div class="line">        newItemSets</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// 返回项集的值</span></div><div class="line">      itemSets</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="comment">// 1. 创建SparkContext</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</div><div class="line">      .setAppName(<span class="string">"find-association-rules"</span>)</div><div class="line">      .setMaster(<span class="string">"local[*]"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="type">SparkContext</span>.getOrCreate(conf)</div><div class="line"></div><div class="line">    <span class="comment">// ===========================================</span></div><div class="line">    <span class="comment">// 测试数据存储的路径</span></div><div class="line">    <span class="keyword">val</span> path = <span class="string">"data/transactions/10"</span></div><div class="line">    <span class="keyword">val</span> savePath = <span class="string">"data/transactions/result"</span></div><div class="line">    <span class="comment">// 最小支持度</span></div><div class="line">    <span class="keyword">val</span> minSupport = <span class="number">2</span></div><div class="line">    <span class="comment">// 最小置信度</span></div><div class="line">    <span class="keyword">val</span> minConfidence = <span class="number">0.4</span></div><div class="line"></div><div class="line">    <span class="comment">// 创建rdd读取原始的交易数据，</span></div><div class="line">    <span class="comment">// 假设交易数据是按行存储的，每行是一条交易，每条交易数据包含的商品ID使用","分割</span></div><div class="line">    <span class="keyword">val</span> rdd = sc.textFile(path, <span class="number">20</span>)</div><div class="line"></div><div class="line">    <span class="comment">// 1. 计算频繁项集</span></div><div class="line">    <span class="comment">// 1.1 获取每条交易存在的项集</span></div><div class="line">    <span class="keyword">val</span> itemSetsRDD: <span class="type">RDD</span>[<span class="type">String</span>] = rdd.flatMap(transaction =&gt; &#123;</div><div class="line">      <span class="comment">// 1) 获取当前交易所包含的商品ID</span></div><div class="line">      <span class="keyword">val</span> items = transaction</div><div class="line">        .split(<span class="string">","</span>) <span class="comment">// 分割</span></div><div class="line">        .filter(!_.isEmpty) <span class="comment">// 过滤</span></div><div class="line">        .sorted <span class="comment">//排序</span></div><div class="line">        .toList <span class="comment">// 转换为list</span></div><div class="line">        .zipWithIndex <span class="comment">// 将数据和下标合并，下标从0开始</span></div><div class="line"></div><div class="line">      <span class="comment">// 2) 构建辅助对象</span></div><div class="line">      <span class="keyword">val</span> itemSize = items.size</div><div class="line">      <span class="keyword">val</span> cache = mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]()</div><div class="line"></div><div class="line">      <span class="comment">// 3) 根据获取的商品ID的信息产生项集</span></div><div class="line">      <span class="comment">// allItemSets集合中最后数据量是:2^itemSize - 1</span></div><div class="line">      <span class="keyword">val</span> allItemSets: <span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]] = (<span class="number">1</span> to itemSize).map(size =&gt; &#123;</div><div class="line">        <span class="comment">// 产生项集中项的数量是size的项集</span></div><div class="line">        findItemSets(items, size, cache)</div><div class="line">      &#125;).foldLeft(<span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]]())((v1, v2) =&gt; &#123;</div><div class="line">        v2.map(_.map(_._1)) ::: v1</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// 4) 返回结果</span></div><div class="line">      allItemSets.map(_.mkString(<span class="string">","</span>))</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 1.2 获取频繁项集</span></div><div class="line">    <span class="keyword">val</span> supportedItemSetsRDD = itemSetsRDD</div><div class="line">      <span class="comment">// 数据转换</span></div><div class="line">      .map(items =&gt; (items, <span class="number">1</span>))</div><div class="line">      <span class="comment">// 聚合求支持度</span></div><div class="line">      .reduceByKey(_ + _)</div><div class="line">      <span class="comment">// 过滤产生频繁项集</span></div><div class="line">      .filter(_._2 &gt;= minSupport)</div><div class="line"></div><div class="line">    <span class="comment">// 2. 计算关联规则</span></div><div class="line">    <span class="comment">// 2.1 对每个频繁项集获取子项集</span></div><div class="line">    <span class="keyword">val</span> subSupportedItemSetsRDD = supportedItemSetsRDD.flatMap(tuple =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> itemSets = tuple._1.split(<span class="string">","</span>).toList.zipWithIndex <span class="comment">// 频繁项集</span></div><div class="line">      <span class="keyword">val</span> frequency = tuple._2 <span class="comment">// 该频繁项集的支持度</span></div><div class="line"></div><div class="line">      <span class="comment">// 2) 构建辅助对象</span></div><div class="line">      <span class="keyword">val</span> itemSize = itemSets.size</div><div class="line">      <span class="keyword">val</span> cache = mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]()</div><div class="line"></div><div class="line">      <span class="comment">// 3) 获取子项集</span></div><div class="line">      <span class="keyword">val</span> allSubItemSets: <span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]] = (<span class="number">1</span> to itemSize).map(size =&gt; &#123;</div><div class="line">        <span class="comment">// 产生项集中项的数量是size的项集</span></div><div class="line">        findItemSets(itemSets, size, cache)</div><div class="line">      &#125;).foldLeft(<span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]]())((v1, v2) =&gt; &#123;</div><div class="line">        v2.map(_.map(_._1)) ::: v1</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// 4) 转换数据并输出</span></div><div class="line">      <span class="keyword">val</span> items = itemSets.map(_._1)</div><div class="line">      allSubItemSets.map(subItemSets =&gt; &#123;</div><div class="line">        <span class="comment">// (A,B,frequency) ==&gt; 表示A出现的时候B也出现的次数是frequency次</span></div><div class="line">        <span class="comment">// 当subItemSets就是itemSets的时候，返回的二元组的第二个元素的(元组)第一个元素是空的列表</span></div><div class="line">        (subItemSets.mkString(<span class="string">","</span>), ((items.toBuffer -- subItemSets).toList.mkString(<span class="string">","</span>), frequency))</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 2.2 计算置信度</span></div><div class="line">    <span class="keyword">val</span> assocRulesRDD = subSupportedItemSetsRDD</div><div class="line">      .groupByKey() <span class="comment">// 数据聚合</span></div><div class="line">      .flatMap(tuple =&gt; &#123;</div><div class="line">      <span class="comment">// 计算执行度: (A, B, k) =&gt; A存在的时候B也存储的几率是k</span></div><div class="line">      <span class="comment">// A就是tuple的第一个元素</span></div><div class="line">      <span class="comment">// 获取左件</span></div><div class="line">      <span class="keyword">val</span> lhs = tuple._1.split(<span class="string">","</span>).mkString(<span class="string">"&lt;"</span>, <span class="string">","</span>, <span class="string">"&gt;"</span>)</div><div class="line"></div><div class="line">      <span class="comment">// 获取左件在所有的交易中出现的总的次数 tuple._2中第一个元素为空的数据就是总的次数</span></div><div class="line">      <span class="keyword">val</span> frequency = tuple._2</div><div class="line">        <span class="comment">// 只要第一个元素为空的值，表示from本身</span></div><div class="line">        .filter(_._1.isEmpty)</div><div class="line">        <span class="comment">// 需要的是第二个元素</span></div><div class="line">        .map(_._2).toList <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> head :: <span class="type">Nil</span> =&gt; head</div><div class="line">        <span class="keyword">case</span> _ =&gt; &#123;</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"异常"</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// 计算右件出现次数占左件次数的百分比, 并返回最终结果</span></div><div class="line">      tuple._2</div><div class="line">        <span class="comment">// 要求第一个数据非空</span></div><div class="line">        .filter(!_._1.isEmpty)</div><div class="line">        <span class="comment">// 数据转换，获取置信度</span></div><div class="line">        .map &#123;</div><div class="line">        <span class="keyword">case</span> (rhs, support) =&gt; &#123;</div><div class="line">          <span class="comment">// 计算置信度</span></div><div class="line">          (lhs, rhs.split(<span class="string">","</span>).mkString(<span class="string">"&lt;"</span>, <span class="string">","</span>, <span class="string">"&gt;"</span>), <span class="number">1.0</span> * support / frequency)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 2.3 过滤置信度太低的数据</span></div><div class="line">    <span class="keyword">val</span> resultRDD = assocRulesRDD.filter(_._3 &gt;= minConfidence)</div><div class="line"></div><div class="line">    <span class="comment">// 3. RDD数据保存</span></div><div class="line">    <span class="comment">//resultRDD.collect()</span></div><div class="line">    <span class="type">FileSystem</span>.get(sc.hadoopConfiguration).delete(<span class="keyword">new</span> <span class="type">Path</span>(savePath), <span class="literal">true</span>)</div><div class="line">    <span class="comment">//resultRDD.repartition(1).saveAsTextFile(savePath)</span></div><div class="line"></div><div class="line">    <span class="comment">// ===========================================</span></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><br><br>### 注意点（本地的完全运行） ###<br><br>　　不需要开启服务，也不需要上传文件，讲文件保存在本地的方式<br><center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E8%B4%AD%E7%89%A9%E7%AF%AE7.png" alt=""><br></center>

<h2 id="优化程序"><a href="#优化程序" class="headerlink" title="优化程序"></a>优化程序</h2><p>　　1.优化的是相集的个数</p>
<p>　　2.使用广播变量</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FileSystem</span>, <span class="type">Path</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.broadcast.<span class="type">Broadcast</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"></div><div class="line"><span class="keyword">import</span> scala.collection.mutable</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * 使用SparkCore实现购物篮分析</div><div class="line">  */</div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">FindAssociationRulesSparkCore</span> </span>&#123;</div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 先从缓存中获取数据，如果不存在，直接重新获取</div><div class="line">    *</div><div class="line">    * @param items</div><div class="line">    * @param size</div><div class="line">    * @param cache</div><div class="line">    * @return</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">findItemSetsByCache</span></span>(items: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)], size: <span class="type">Int</span>, cache: mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]): <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = &#123;</div><div class="line">    cache.get(size).orElse &#123;</div><div class="line">      <span class="comment">// 获取值</span></div><div class="line">      <span class="keyword">val</span> result = findItemSets(items, size, cache)</div><div class="line"></div><div class="line">      <span class="comment">// 更新缓存</span></div><div class="line">      cache += size -&gt; result</div><div class="line"></div><div class="line">      <span class="comment">// 返回值</span></div><div class="line">      <span class="type">Some</span>(result)</div><div class="line">    &#125;.get</div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 构建项集基于items商品列表，项集中的商品数量是size指定</div><div class="line">    *</div><div class="line">    * @param items 商品列表：eg: [A, B, C]</div><div class="line">    * @param size  最终项集包含商品的数量</div><div class="line">    * @return</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">findItemSets</span></span>(items: <span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)], size: <span class="type">Int</span>, cache: mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]): <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = &#123;</div><div class="line">    <span class="keyword">if</span> (size == <span class="number">1</span>) &#123;</div><div class="line">      <span class="comment">// items中的每个商品都是一个项集</span></div><div class="line">      items.map(item =&gt; item :: <span class="type">Nil</span>)</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="comment">// 当size不是1的时候</span></div><div class="line">      <span class="comment">// 1. 获取项集大小为size-1的项集列表</span></div><div class="line">      <span class="keyword">val</span> tmpItemSets = findItemSetsByCache(items, size - <span class="number">1</span>, cache)</div><div class="line">      <span class="comment">// 2. 给tmpItemSets中添加一个新的不重复的项 ==&gt; 数据的转换</span></div><div class="line">      <span class="keyword">val</span> itemSets = tmpItemSets.flatMap(itemSets =&gt; &#123;</div><div class="line">        <span class="comment">// 给itemSets项集添加一个新的商品ID，要求不重复</span></div><div class="line">        <span class="keyword">val</span> newItemSets = items</div><div class="line">          <span class="comment">// 将包含的商品过滤掉&amp;要求下标必须大于以及存在</span></div><div class="line">          .filter(item =&gt; !itemSets.contains(item) &amp;&amp; itemSets.forall(_._2 &lt; item._2))</div><div class="line">          <span class="comment">// 将商品添加到项集中，产生一个新的项集</span></div><div class="line">          <span class="comment">// 为了使用distinct做去重操作，进行一个排序操作</span></div><div class="line">          .map(item =&gt; (item :: itemSets))</div><div class="line"></div><div class="line">        <span class="comment">// 返回值</span></div><div class="line">        newItemSets</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// 返回项集的值</span></div><div class="line">      itemSets</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> n = <span class="number">10000</span></div><div class="line">    <span class="comment">// 1. 创建SparkContext</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</div><div class="line">      .setAppName(<span class="string">s"find-association-rules-<span class="subst">$&#123;n&#125;</span>"</span>)</div><div class="line">      .setMaster(<span class="string">"local[*]"</span>)</div><div class="line">    <span class="comment">//      .set("spark.eventLog.enabled", "true")</span></div><div class="line">    <span class="comment">//      .set("spark.eventLog.dir","hdfs://hadoop-senior01:8020/spark-history")</span></div><div class="line">    <span class="comment">//      .set("spark.executor.memory","3g")</span></div><div class="line">    <span class="keyword">val</span> sc = <span class="type">SparkContext</span>.getOrCreate(conf)</div><div class="line"></div><div class="line">    <span class="comment">// ===========================================</span></div><div class="line">    <span class="comment">// 测试数据存储的路径</span></div><div class="line">    <span class="keyword">val</span> path = <span class="string">s"data/transactions/<span class="subst">$&#123;n&#125;</span>"</span></div><div class="line">    <span class="keyword">val</span> savePath = <span class="string">s"result2/<span class="subst">$&#123;n&#125;</span>"</span></div><div class="line">    <span class="comment">// 最小支持度</span></div><div class="line">    <span class="keyword">val</span> minSupport = <span class="number">2</span></div><div class="line">    <span class="comment">// 最小置信度</span></div><div class="line">    <span class="keyword">val</span> minConfidence = <span class="number">0.1</span></div><div class="line"></div><div class="line">    <span class="comment">// 创建rdd读取原始的交易数据，</span></div><div class="line">    <span class="comment">// 假设交易数据是按行存储的，每行是一条交易，每条交易数据包含的商品ID使用","分割</span></div><div class="line">    <span class="keyword">val</span> rdd = sc.textFile(path, <span class="number">20</span>)</div><div class="line"></div><div class="line">    <span class="comment">// 过滤无效数据：对于在整个交易集合中出现比较少的商品过滤掉，先进行需要过滤的商品的RDD数据</span></div><div class="line">    <span class="keyword">val</span> minGoodCount = <span class="number">3</span> <span class="comment">// 要求商品在整个交易集中至少出现3次</span></div><div class="line">    <span class="keyword">val</span> needFilterGoodsRDD = rdd</div><div class="line">      .flatMap(transaction =&gt; transaction</div><div class="line">        .split(<span class="string">","</span>)</div><div class="line">        .filter(!_.isEmpty)</div><div class="line">        .map(good =&gt; (good, <span class="number">1</span>))</div><div class="line">      )</div><div class="line">      .reduceByKey(_ + _)</div><div class="line">      .filter(_._2 &lt; minGoodCount)</div><div class="line">      .map(_._1)</div><div class="line">    <span class="comment">// 使用广播变量将数据广播输出</span></div><div class="line">    <span class="keyword">val</span> needFilterGoods: <span class="type">Broadcast</span>[<span class="type">List</span>[<span class="type">String</span>]] = sc.broadcast(needFilterGoodsRDD.collect().toList)</div><div class="line"></div><div class="line">    <span class="comment">// 1. 计算频繁项集</span></div><div class="line">    <span class="comment">// 1.1 获取每条交易存在的项集</span></div><div class="line">    <span class="keyword">val</span> itemSetsRDD: <span class="type">RDD</span>[<span class="type">String</span>] = rdd.flatMap(transaction =&gt; &#123;</div><div class="line">      <span class="comment">// 1) 获取当前交易所包含的商品ID</span></div><div class="line">      <span class="keyword">val</span> goods: <span class="type">Array</span>[<span class="type">String</span>] = transaction</div><div class="line">        .split(<span class="string">","</span>) <span class="comment">// 分割</span></div><div class="line">        .filter(!_.isEmpty) <span class="comment">// 过滤</span></div><div class="line"></div><div class="line"></div><div class="line">      <span class="comment">// 将需要过滤的数据过滤掉</span></div><div class="line">      <span class="keyword">val</span> items = (goods.toBuffer -- needFilterGoods.value)</div><div class="line">        .sorted <span class="comment">//排序</span></div><div class="line">        .toList <span class="comment">// 转换为list</span></div><div class="line">        .zipWithIndex <span class="comment">// 将数据和下标合并，下标从0开始</span></div><div class="line"></div><div class="line">      <span class="comment">// 2) 构建辅助对象</span></div><div class="line">      <span class="comment">// 最大的项集只允许存在5个项的，5怎么来？根据业务规则&amp;根据运行之后的情况</span></div><div class="line">      <span class="keyword">val</span> itemSize = <span class="type">Math</span>.min(items.size, <span class="number">5</span>)</div><div class="line">      <span class="keyword">val</span> cache = mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]()</div><div class="line"></div><div class="line">      <span class="comment">// 3) 根据获取的商品ID的信息产生项集</span></div><div class="line">      <span class="comment">// allItemSets集合中最后数据量是:2^itemSize - 1</span></div><div class="line">      <span class="keyword">val</span> allItemSets: <span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]] = (<span class="number">1</span> to itemSize).map(size =&gt; &#123;</div><div class="line">        <span class="comment">// 产生项集中项的数量是size的项集</span></div><div class="line">        findItemSets(items, size, cache)</div><div class="line">      &#125;).foldLeft(<span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]]())((v1, v2) =&gt; &#123;</div><div class="line">        v2.map(_.map(_._1)) ::: v1</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// 4) 返回结果</span></div><div class="line">      allItemSets.map(_.mkString(<span class="string">","</span>))</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 1.2 获取频繁项集</span></div><div class="line">    <span class="keyword">val</span> supportedItemSetsRDD = itemSetsRDD</div><div class="line">      <span class="comment">// 数据转换</span></div><div class="line">      .map(items =&gt; (items, <span class="number">1</span>))</div><div class="line">      <span class="comment">// 聚合求支持度</span></div><div class="line">      .reduceByKey(_ + _)</div><div class="line">      <span class="comment">// 过滤产生频繁项集</span></div><div class="line">      .filter(_._2 &gt;= minSupport)</div><div class="line"></div><div class="line">    <span class="comment">// 2. 计算关联规则</span></div><div class="line">    <span class="comment">// 2.1 对每个频繁项集获取子项集</span></div><div class="line">    <span class="keyword">val</span> subSupportedItemSetsRDD = supportedItemSetsRDD.flatMap(tuple =&gt; &#123;</div><div class="line">      <span class="keyword">val</span> itemSets = tuple._1.split(<span class="string">","</span>).toList.zipWithIndex <span class="comment">// 频繁项集</span></div><div class="line">      <span class="keyword">val</span> frequency = tuple._2 <span class="comment">// 该频繁项集的支持度</span></div><div class="line"></div><div class="line">      <span class="comment">// 2) 构建辅助对象</span></div><div class="line">      <span class="keyword">val</span> itemSize = itemSets.size</div><div class="line">      <span class="keyword">val</span> cache = mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">List</span>[<span class="type">List</span>[(<span class="type">String</span>, <span class="type">Int</span>)]]]()</div><div class="line"></div><div class="line">      <span class="comment">// 3) 获取子项集</span></div><div class="line">      <span class="keyword">val</span> allSubItemSets: <span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]] = (<span class="number">1</span> to itemSize).map(size =&gt; &#123;</div><div class="line">        <span class="comment">// 产生项集中项的数量是size的项集</span></div><div class="line">        findItemSets(itemSets, size, cache)</div><div class="line">      &#125;).foldLeft(<span class="type">List</span>[<span class="type">List</span>[<span class="type">String</span>]]())((v1, v2) =&gt; &#123;</div><div class="line">        v2.map(_.map(_._1)) ::: v1</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">      <span class="comment">// 4) 转换数据并输出</span></div><div class="line">      <span class="keyword">val</span> items = itemSets.map(_._1)</div><div class="line">      allSubItemSets.map(subItemSets =&gt; &#123;</div><div class="line">        <span class="comment">// (A,B,frequency) ==&gt; 表示A出现的时候B也出现的次数是frequency次</span></div><div class="line">        <span class="comment">// 当subItemSets就是itemSets的时候，返回的二元组的第二个元素的(元组)第一个元素是空的列表</span></div><div class="line">        (subItemSets.mkString(<span class="string">","</span>), ((items.toBuffer -- subItemSets).toList.mkString(<span class="string">","</span>), frequency))</div><div class="line">      &#125;)</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 2.2 计算置信度</span></div><div class="line">    <span class="keyword">val</span> assocRulesRDD = subSupportedItemSetsRDD</div><div class="line">      .groupByKey() <span class="comment">// 数据聚合</span></div><div class="line">      .flatMap(tuple =&gt; &#123;</div><div class="line">      <span class="comment">// 计算执行度: (A, B, k) =&gt; A存在的时候B也存储的几率是k</span></div><div class="line">      <span class="comment">// A就是tuple的第一个元素</span></div><div class="line">      <span class="comment">// 获取左件</span></div><div class="line">      <span class="keyword">val</span> lhs = tuple._1.split(<span class="string">","</span>).mkString(<span class="string">"&lt;"</span>, <span class="string">","</span>, <span class="string">"&gt;"</span>)</div><div class="line"></div><div class="line">      <span class="comment">// 获取左件在所有的交易中出现的总的次数 tuple._2中第一个元素为空的数据就是总的次数</span></div><div class="line">      <span class="keyword">val</span> frequency = tuple._2</div><div class="line">        <span class="comment">// 只要第一个元素为空的值，表示from本身</span></div><div class="line">        .filter(_._1.isEmpty)</div><div class="line">        <span class="comment">// 需要的是第二个元素</span></div><div class="line">        .map(_._2).toList <span class="keyword">match</span> &#123;</div><div class="line">        <span class="keyword">case</span> head :: <span class="type">Nil</span> =&gt; head</div><div class="line">        <span class="keyword">case</span> _ =&gt; &#123;</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"异常"</span>)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="comment">// 计算右件出现次数占左件次数的百分比, 并返回最终结果</span></div><div class="line">      tuple._2</div><div class="line">        <span class="comment">// 要求第一个数据非空</span></div><div class="line">        .filter(!_._1.isEmpty)</div><div class="line">        <span class="comment">// 数据转换，获取置信度</span></div><div class="line">        .map &#123;</div><div class="line">        <span class="keyword">case</span> (rhs, support) =&gt; &#123;</div><div class="line">          <span class="comment">// 计算置信度</span></div><div class="line">          (lhs, rhs.split(<span class="string">","</span>).mkString(<span class="string">"&lt;"</span>, <span class="string">","</span>, <span class="string">"&gt;"</span>), <span class="number">1.0</span> * support / frequency)</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 2.3 过滤置信度太低的数据</span></div><div class="line">    <span class="keyword">val</span> resultRDD = assocRulesRDD.filter(_._3 &gt;= minConfidence)</div><div class="line"></div><div class="line">    <span class="comment">// 3. RDD数据保存</span></div><div class="line">    <span class="type">FileSystem</span>.get(sc.hadoopConfiguration).delete(<span class="keyword">new</span> <span class="type">Path</span>(savePath), <span class="literal">true</span>)</div><div class="line">    resultRDD.repartition(<span class="number">1</span>).saveAsTextFile(savePath)</div><div class="line"></div><div class="line">    <span class="comment">// ===========================================</span></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<font color="grey" size="1">注：此博客仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Spark案例 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark应用案例-Spark完成PV和UV的计算]]></title>
      <url>http://Melodylican.github.io/2017/08/20/spark%E5%AE%8C%E6%88%90PV%E5%92%8CUV%E7%9A%84%E8%AE%A1%E7%AE%97/</url>
      <content type="html"><![CDATA[<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">LogPVAndUV</span></span>&#123;</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args:<span class="type">Array</span>[<span class="type">String</span>]):<span class="type">Unit</span>=&#123;</div><div class="line">        <span class="keyword">val</span> conf=<span class="keyword">new</span> <span class="type">SparkConf</span>()</div><div class="line">            .setMaster(<span class="string">"local[*]"</span>)</div><div class="line">            .setAppName(<span class="string">"PVAndUV"</span>)</div><div class="line">        <span class="keyword">val</span> sc=<span class="type">SparkContext</span>.getOrCreate(conf)</div><div class="line">        <span class="keyword">val</span> logPath=<span class="string">"/user/***/spark/logs/page_views.data"</span></div><div class="line">        <span class="keyword">val</span> logRDD=sc.textFile(logPath)</div><div class="line">        <span class="keyword">val</span> filterRDD=logRDD.filter(_.length&gt;<span class="number">0</span>)</div><div class="line">        <span class="comment">//转换</span></div><div class="line">        <span class="keyword">val</span> mapRDD=filterRDD.map(line=&gt;&#123;</div><div class="line">            <span class="keyword">val</span> arr=line.split(<span class="string">"\t"</span>)</div><div class="line">            <span class="keyword">if</span>(arr.length==<span class="number">7</span>)&#123;</div><div class="line">                <span class="keyword">val</span> date=arr(<span class="number">0</span>).trim</div><div class="line">                <span class="keyword">val</span> url=arr(<span class="number">1</span>)</div><div class="line">                <span class="keyword">val</span> uuid=arr(<span class="number">2</span>)</div><div class="line">                (date.subString(<span class="number">0</span>,<span class="type">Math</span>.min(<span class="number">10.</span>date.length)).trim,url,uuid)</div><div class="line">            &#125;<span class="keyword">else</span>&#123;</div><div class="line">                (<span class="literal">null</span>,<span class="literal">null</span>,<span class="literal">null</span>)</div><div class="line">            &#125;</div><div class="line">        &#125;).filter(tuple=&gt;tuple._1!=<span class="literal">null</span>&amp;&amp;tuple._1.length&gt;<span class="number">0</span>)</div><div class="line">        <span class="comment">//PV计算</span></div><div class="line">        <span class="keyword">val</span> pvRDD=mapRDD</div><div class="line">            .filter(tuple=&gt;tuple._2.length&gt;<span class="number">0</span>)</div><div class="line">            .map(tuple=&gt;(tuple._1,<span class="number">1</span>))</div><div class="line">            .reduceByKey(_+_)</div><div class="line">        <span class="comment">//UV计算</span></div><div class="line">        <span class="keyword">val</span> uvRDD=mapRDD</div><div class="line">            .filter(tuple=&gt;tuple._3.length&gt;<span class="number">0</span>)</div><div class="line">            .map(tuple=&gt;(tuple._1,tuple._3))</div><div class="line">            .distinct</div><div class="line">            .reduceByKey(_+_)</div><div class="line">        <span class="comment">//合并</span></div><div class="line">        <span class="keyword">val</span> pvAndUv=pvRDD.join(uvRDD).map&#123;</div><div class="line">            <span class="keyword">case</span> (date,(pv,uv))=&gt;&#123;</div><div class="line">                (date,pv,uv)</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="comment">//输出</span></div><div class="line">        pvAndUv.saveAsTextFile(<span class="string">"/user/***/spark/output/"</span>+<span class="type">System</span>.currentTimeMillis())</div><div class="line">        sc.stop()</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<font color="grey" size="1">注：此博客仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Spark案例 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark优化]]></title>
      <url>http://Melodylican.github.io/2017/08/20/spark%E4%BC%98%E5%8C%96/</url>
      <content type="html"><![CDATA[<center><br><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E4%BC%98%E5%8C%96.png" alt=""><br><br></center>

<font color="grey" size="1">注：此博客仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Spark案例 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark应用案例 日志数据分析案例]]></title>
      <url>http://Melodylican.github.io/2017/08/20/Spark%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B-%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</url>
      <content type="html"><![CDATA[<h2 id="四个需求"><a href="#四个需求" class="headerlink" title="四个需求"></a>四个需求</h2><ul>
<li>　　需求一：求contentsize的平均值、最小值、最大值 </li>
<li>　　需求二：请各个不同返回值的出现的数据 ===&gt; wordCount程序 </li>
<li>　　需求三：获取访问次数超过N次的IP地址 </li>
<li>　　需求四：获取访问次数最多的前K个endpoint的值 ==&gt; TopN</li>
</ul>
<a id="more"></a>
<h2 id="主程序LogAnalyzer-scala"><a href="#主程序LogAnalyzer-scala" class="headerlink" title="主程序LogAnalyzer.scala"></a>主程序LogAnalyzer.scala</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * Apache日志分析</div><div class="line">  */</div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">LogAnalyzer</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</div><div class="line">      .setAppName(<span class="string">"log-analyzer"</span>)</div><div class="line">      .setMaster(<span class="string">"local[*]"</span>)</div><div class="line">      .set(<span class="string">"spark.eventLog.enabled"</span>, <span class="string">"true"</span>)</div><div class="line">      .set(<span class="string">"spark.eventLog.dir"</span>, <span class="string">"hdfs://hadoop-senior01:8020/spark-history"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="type">SparkContext</span>.getOrCreate(conf)</div><div class="line"></div><div class="line">    <span class="comment">// ================日志分析具体代码==================</span></div><div class="line">    <span class="comment">// HDFS上日志存储路径</span></div><div class="line">    <span class="keyword">val</span> path = <span class="string">"/beifeng/spark/access/access.log"</span></div><div class="line"></div><div class="line">    <span class="comment">// 创建rdd</span></div><div class="line">    <span class="keyword">val</span> rdd = sc.textFile(path)</div><div class="line"></div><div class="line">    <span class="comment">// rdd转换，返回进行后续操作</span></div><div class="line">    <span class="keyword">val</span> apacheAccessLog: <span class="type">RDD</span>[<span class="type">ApacheAccessLog</span>] = rdd</div><div class="line">      <span class="comment">// 过滤数据</span></div><div class="line">      .filter(line =&gt; <span class="type">ApacheAccessLog</span>.isValidateLogLine(line))</div><div class="line">      .map(line =&gt; &#123;</div><div class="line">        <span class="comment">// 对line数据进行转换操作</span></div><div class="line">        <span class="type">ApacheAccessLog</span>.parseLogLine(line)</div><div class="line">      &#125;)</div><div class="line"></div><div class="line">    <span class="comment">// 对多次时候用的rdd进行cache</span></div><div class="line">    apacheAccessLog.cache()</div><div class="line"></div><div class="line">    <span class="comment">// 需求一：求contentsize的平均值、最小值、最大值</span></div><div class="line">    <span class="comment">/*</span></div><div class="line">    * The average, min, and max content size of responses returned from the server.</div><div class="line">    * */</div><div class="line">    <span class="keyword">val</span> contentSizeRDD: <span class="type">RDD</span>[<span class="type">Long</span>] = apacheAccessLog</div><div class="line">      <span class="comment">// 提取计算需要的字段数据</span></div><div class="line">      .map(log =&gt; (log.contentSize))</div><div class="line"></div><div class="line">    <span class="comment">// 对重复使用的RDD进行cache</span></div><div class="line">    contentSizeRDD.cache()</div><div class="line"></div><div class="line">    <span class="comment">// 开始计算平均值、最小值、最大值</span></div><div class="line">    <span class="keyword">val</span> totalContentSize = contentSizeRDD.sum()</div><div class="line">    <span class="keyword">val</span> totalCount = contentSizeRDD.count()</div><div class="line">    <span class="keyword">val</span> avgSize = <span class="number">1.0</span> * totalContentSize / totalCount</div><div class="line">    <span class="keyword">val</span> minSize = contentSizeRDD.min()</div><div class="line">    <span class="keyword">val</span> maxSize = contentSizeRDD.max()</div><div class="line"></div><div class="line">    <span class="comment">// 当RDD不使用的时候，进行unpersist</span></div><div class="line">    contentSizeRDD.unpersist()</div><div class="line"></div><div class="line">    <span class="comment">// 结果输出</span></div><div class="line">    println(<span class="string">s"ContentSize Avg：<span class="subst">$&#123;avgSize&#125;</span>, Min: <span class="subst">$&#123;minSize&#125;</span>, Max: <span class="subst">$&#123;maxSize&#125;</span>"</span>)</div><div class="line"></div><div class="line">    <span class="comment">// 需求二：请各个不同返回值的出现的数据 ===&gt; wordCount程序</span></div><div class="line">    <span class="comment">/*</span></div><div class="line">    * A count of response code's returned.</div><div class="line">    * */</div><div class="line">    <span class="keyword">val</span> responseCodeResultRDD = apacheAccessLog</div><div class="line">      <span class="comment">// 提取需要的字段数据, 转换为key/value键值对，方便进行reduceByKey操作</span></div><div class="line">      <span class="comment">// 当连续出现map或者flatMap的时候，将多个map/flatMap进行合并</span></div><div class="line">      .map(log =&gt; (log.responseCode, <span class="number">1</span>))</div><div class="line">      <span class="comment">// 使用reduceByKey函数，按照key进行分组后，计算每个key出现的次数</span></div><div class="line">      .reduceByKey(_ + _)</div><div class="line"></div><div class="line">    <span class="comment">// 结果输出</span></div><div class="line">    println(<span class="string">s""</span><span class="string">"ResponseCode :$&#123;responseCodeResultRDD.collect().mkString("</span>,<span class="string">")&#125;"</span><span class="string">""</span>)</div><div class="line"></div><div class="line">    <span class="comment">// 需求三：获取访问次数超过N次的IP地址</span></div><div class="line">    <span class="comment">// 需求三额外：对IP地址进行限制，部分黑名单IP地址不统计</span></div><div class="line">    <span class="comment">/*</span></div><div class="line">    * All IPAddresses that have accessed this server more than N times.</div><div class="line">    * 1. 计算IP地址出现的次数 ===&gt; WordCount程序</div><div class="line">    * 2. 数据过滤</div><div class="line">    * */</div><div class="line">    <span class="keyword">val</span> blackIP = <span class="type">Array</span>(<span class="string">"200-55-104-193.dsl.prima.net.ar"</span>, <span class="string">"10.0.0.153"</span>, <span class="string">"208-38-57-205.ip.cal.radiant.net"</span>)</div><div class="line">    <span class="comment">// 由于集合比较大，将集合的内容广播出去</span></div><div class="line">    <span class="keyword">val</span> broadCastIP = sc.broadcast(blackIP)</div><div class="line">    <span class="keyword">val</span> <span class="type">N</span> = <span class="number">10</span></div><div class="line">    <span class="keyword">val</span> ipAddressRDD = apacheAccessLog</div><div class="line">      <span class="comment">// 过滤IP地址在黑名单中的数据</span></div><div class="line">      .filter(log =&gt; !broadCastIP.value.contains(log.ipAddress))</div><div class="line">      <span class="comment">// 获取计算需要的IP地址数据，并将返回值转换为Key/Value键值对类型</span></div><div class="line">      .map(log =&gt; (log.ipAddress, <span class="number">1</span>L))</div><div class="line">      <span class="comment">// 使用reduceByKey函数进行聚合操作</span></div><div class="line">      .reduceByKey(_ + _)</div><div class="line">      <span class="comment">// 过滤数据，要求IP地址必须出现N次以上</span></div><div class="line">      .filter(tuple =&gt; tuple._2 &gt; <span class="type">N</span>)</div><div class="line">    <span class="comment">// 获取满足条件IP地址, 为了展示方便，将下面这行代码注释</span></div><div class="line">    <span class="comment">//      .map(tuple =&gt; tuple._1)</span></div><div class="line"></div><div class="line">    <span class="comment">// 结果输出</span></div><div class="line">    println(<span class="string">s""</span><span class="string">"IP Address :$&#123;ipAddressRDD.collect().mkString("</span>,<span class="string">")&#125;"</span><span class="string">""</span>)</div><div class="line"></div><div class="line">    <span class="comment">// 需求四：获取访问次数最多的前K个endpoint的值 ==&gt; TopN</span></div><div class="line">    <span class="comment">/*</span></div><div class="line">    * The top endpoints requested by count.</div><div class="line">    * 1. 先计算出每个endpoint的出现次数</div><div class="line">    * 2. 再进行topK的一个获取操作，获取出现次数最多的前K个值</div><div class="line">    * */</div><div class="line">    <span class="keyword">val</span> <span class="type">K</span> = <span class="number">10</span></div><div class="line">    <span class="keyword">val</span> topKValues = apacheAccessLog</div><div class="line">      <span class="comment">// 获取计算需要的字段信息，并返回key/value键值对</span></div><div class="line">      .map(log =&gt; (log.endpoint, <span class="number">1</span>))</div><div class="line">      <span class="comment">// 获取每个endpoint对应的出现次数</span></div><div class="line">      .reduceByKey(_ + _)</div><div class="line">      <span class="comment">// 获取前10个元素, 而且使用我们自定义的排序类</span></div><div class="line">      .top(<span class="type">K</span>)(<span class="type">LogSortingUtil</span>.<span class="type">TupleOrdering</span>)</div><div class="line">    <span class="comment">// 如果只需要endpoint的值，不需要出现的次数，那么可以通过map函数进行转换</span></div><div class="line">    <span class="comment">//      .map(_._1)</span></div><div class="line"></div><div class="line">    <span class="comment">// 结果输出</span></div><div class="line">    println(<span class="string">s""</span><span class="string">"TopK values:$&#123;topKValues.mkString("</span>,<span class="string">")&#125;"</span><span class="string">""</span>)</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// 对不在使用的rdd，去除cache</span></div><div class="line">    apacheAccessLog.unpersist()</div><div class="line"></div><div class="line">    <span class="comment">// ================日志分析具体代码==================</span></div><div class="line"></div><div class="line">    sc.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="需要的辅助类一（返回匹配的日志）"><a href="#需要的辅助类一（返回匹配的日志）" class="headerlink" title="需要的辅助类一（返回匹配的日志）"></a>需要的辅助类一（返回匹配的日志）</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> scala.util.matching.<span class="type">Regex</span></div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * 64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] "GET /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables HTTP/1.1" 401 12846</div><div class="line">  */</div><div class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">ApacheAccessLog</span>(<span class="params"></span></span></div><div class="line">                            ipAddress: <span class="type">String</span>, // <span class="type">IP</span>地址</div><div class="line">                            clientId: <span class="type">String</span>, // 客户端唯一标识符</div><div class="line">                            userId: <span class="type">String</span>, // 用户唯一标识符</div><div class="line">                            serverTime: <span class="type">String</span>, // 服务器时间</div><div class="line">                            method: <span class="type">String</span>, // 请求类型/方式</div><div class="line">                            endpoint: <span class="type">String</span>, // 请求的资源</div><div class="line">                            protocol: <span class="type">String</span>, // 请求的协议名称</div><div class="line">                            responseCode: <span class="type">Int</span>, // 请求返回值：比如：200、401</div><div class="line">                            contentSize: <span class="type">Long</span> // 返回的结果数据大小</div><div class="line">                          )</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line">  * 64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] "GET /twiki/bin/edit/Main/Double_bounce_sender?topicparent=Main.ConfigurationVariables HTTP/1.1" 401 12846</div><div class="line">  * Created by ibf on 01/15.</div><div class="line">  * 提供一些操作Apache Log的工具类供SparkCore使用</div><div class="line">  */</div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">ApacheAccessLog</span> </span>&#123;</div><div class="line">  <span class="comment">// Apache日志的正则</span></div><div class="line">  <span class="keyword">val</span> <span class="type">PARTTERN</span>: <span class="type">Regex</span> =</div><div class="line">  <span class="string">""</span><span class="string">"^(\S+) (\S+) (\S+) \[([\w:/]+\s[+\-]\d&#123;4&#125;)\] "</span>(\<span class="type">S</span>+) (\<span class="type">S</span>+) (\<span class="type">S</span>+)<span class="string">" (\d&#123;3&#125;) (\d+)"</span><span class="string">""</span>.r</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 验证一下输入的数据是否符合给定的日志正则，如果符合返回true；否则返回false</div><div class="line">    *</div><div class="line">    * @param line</div><div class="line">    * @return</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">isValidateLogLine</span></span>(line: <span class="type">String</span>): <span class="type">Boolean</span> = &#123;</div><div class="line">    <span class="keyword">val</span> options = <span class="type">PARTTERN</span>.findFirstMatchIn(line)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (options.isEmpty) &#123;</div><div class="line">      <span class="literal">false</span></div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      <span class="literal">true</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 解析输入的日志数据</div><div class="line">    *</div><div class="line">    * @param line</div><div class="line">    * @return</div><div class="line">    */</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">parseLogLine</span></span>(line: <span class="type">String</span>): <span class="type">ApacheAccessLog</span> = &#123;</div><div class="line">    <span class="keyword">if</span> (!isValidateLogLine(line)) &#123;</div><div class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">"参数格式异常"</span>)</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// 从line中获取匹配的数据</span></div><div class="line">    <span class="keyword">val</span> options = <span class="type">PARTTERN</span>.findFirstMatchIn(line)</div><div class="line"></div><div class="line">    <span class="comment">// 获取matcher</span></div><div class="line">    <span class="keyword">val</span> matcher = options.get</div><div class="line"></div><div class="line">    <span class="comment">// 构建返回值</span></div><div class="line">    <span class="type">ApacheAccessLog</span>(</div><div class="line">      matcher.group(<span class="number">1</span>), <span class="comment">// 获取匹配字符串中第一个小括号中的值</span></div><div class="line">      matcher.group(<span class="number">2</span>),</div><div class="line">      matcher.group(<span class="number">3</span>),</div><div class="line">      matcher.group(<span class="number">4</span>),</div><div class="line">      matcher.group(<span class="number">5</span>),</div><div class="line">      matcher.group(<span class="number">6</span>),</div><div class="line">      matcher.group(<span class="number">7</span>),</div><div class="line">      matcher.group(<span class="number">8</span>).toInt,</div><div class="line">      matcher.group(<span class="number">9</span>).toLong</div><div class="line">    )</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="需要的辅助类二（自定义的一个二元组的比较器，方便进行TopN）"><a href="#需要的辅助类二（自定义的一个二元组的比较器，方便进行TopN）" class="headerlink" title="需要的辅助类二（自定义的一个二元组的比较器，方便进行TopN）"></a>需要的辅助类二（自定义的一个二元组的比较器，方便进行TopN）</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">LogSortingUtil</span> </span>&#123;</div><div class="line"></div><div class="line">  <span class="comment">/**</span></div><div class="line">    * 自定义的一个二元组的比较器</div><div class="line">    */</div><div class="line">  <span class="class"><span class="keyword">object</span> <span class="title">TupleOrdering</span> <span class="keyword">extends</span> <span class="title">scala</span>.<span class="title">math</span>.<span class="title">Ordering</span>[(<span class="type">String</span>, <span class="type">Int</span>)] </span>&#123;</div><div class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(x: (<span class="type">String</span>, <span class="type">Int</span>), y: (<span class="type">String</span>, <span class="type">Int</span>)): <span class="type">Int</span> = &#123;</div><div class="line">      <span class="comment">// 按照出现的次数进行比较，也就是按照二元组的第二个元素进行比较</span></div><div class="line">      x._2.compare(y._2)</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<font color="grey" size="1">注：此博客仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Spark案例 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark算子总结及案例]]></title>
      <url>http://Melodylican.github.io/2017/08/11/Spark%E7%AE%97%E5%AD%90%E6%80%BB%E7%BB%93%E5%8F%8A%E6%A1%88%E4%BE%8B/</url>
      <content type="html"><![CDATA[<p><strong>spark算子大致上可分三大类算子</strong>：</p>
<ol>
<li><p>　　Value数据类型的Transformation算子，这种变换不触发提交作业，针对处理的数据项是Value型的数据。</p>
</li>
<li><p>　　Key-Value数据类型的Transformation算子，这种变换不触发提交作业，针对处理的数据项是Key-Value型的数据。</p>
</li>
<li><p>　　Action算子，这类算子会触发SparkContext提交作业。</p>
<a id="more"></a>
</li>
</ol>
<h2 id="Value型Transformation算子"><a href="#Value型Transformation算子" class="headerlink" title="Value型Transformation算子"></a>Value型Transformation算子</h2><p><strong>1）map</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"salmon"</span>, <span class="string">"salmon"</span>, <span class="string">"rat"</span>, <span class="string">"elephant"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = a.map(_.length)</div><div class="line"><span class="keyword">val</span> c = a.zip(b)</div><div class="line">c.collect</div><div class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((dog,<span class="number">3</span>), (salmon,<span class="number">6</span>), (salmon,<span class="number">6</span>), (rat,<span class="number">3</span>), (elephant,<span class="number">8</span>))</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%901.png" alt=""><br></center>

<p><strong>2）flatMap</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">5</span>)</div><div class="line">a.flatMap(<span class="number">1</span> to _).collect</div><div class="line">res47: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</div><div class="line"></div><div class="line">sc.parallelize(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), <span class="number">2</span>).flatMap(x =&gt; <span class="type">List</span>(x, x, x)).collect</div><div class="line">res85: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%902.png" alt=""><br></center>


<p><strong>3）mapPartiions</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> x  = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</div><div class="line">x.flatMap(<span class="type">List</span>.fill(scala.util.<span class="type">Random</span>.nextInt(<span class="number">10</span>))(_)).collect</div><div class="line"></div><div class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%903.png" alt=""><br></center>

<p><strong>4）glom（形成一个Array数组）</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">100</span>, <span class="number">3</span>)</div><div class="line">a.glom.collect</div><div class="line">res8: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>), <span class="type">Array</span>(<span class="number">34</span>, <span class="number">35</span>, <span class="number">36</span>, <span class="number">37</span>, <span class="number">38</span>, <span class="number">39</span>, <span class="number">40</span>, <span class="number">41</span>, <span class="number">42</span>, <span class="number">43</span>, <span class="number">44</span>, <span class="number">45</span>, <span class="number">46</span>, <span class="number">47</span>, <span class="number">48</span>, <span class="number">49</span>, <span class="number">50</span>, <span class="number">51</span>, <span class="number">52</span>, <span class="number">53</span>, <span class="number">54</span>, <span class="number">55</span>, <span class="number">56</span>, <span class="number">57</span>, <span class="number">58</span>, <span class="number">59</span>, <span class="number">60</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">63</span>, <span class="number">64</span>, <span class="number">65</span>, <span class="number">66</span>), <span class="type">Array</span>(<span class="number">67</span>, <span class="number">68</span>, <span class="number">69</span>, <span class="number">70</span>, <span class="number">71</span>, <span class="number">72</span>, <span class="number">73</span>, <span class="number">74</span>, <span class="number">75</span>, <span class="number">76</span>, <span class="number">77</span>, <span class="number">78</span>, <span class="number">79</span>, <span class="number">80</span>, <span class="number">81</span>, <span class="number">82</span>, <span class="number">83</span>, <span class="number">84</span>, <span class="number">85</span>, <span class="number">86</span>, <span class="number">87</span>, <span class="number">88</span>, <span class="number">89</span>, <span class="number">90</span>, <span class="number">91</span>, <span class="number">92</span>, <span class="number">93</span>, <span class="number">94</span>, <span class="number">95</span>, <span class="number">96</span>, <span class="number">97</span>, <span class="number">98</span>, <span class="number">99</span>, <span class="number">100</span>))</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%904.png" alt=""><br></center>


<p><strong>5）union</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">3</span>, <span class="number">1</span>)</div><div class="line"><span class="keyword">val</span> b = sc.parallelize(<span class="number">5</span> to <span class="number">7</span>, <span class="number">1</span>)</div><div class="line">(a ++ b).collect</div><div class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%905.png" alt=""><br></center>


<p><strong>6）cartesian（笛卡尔操作）</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> x = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>))</div><div class="line"><span class="keyword">val</span> y = sc.parallelize(<span class="type">List</span>(<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>))</div><div class="line">x.cartesian(y).collect</div><div class="line">res0: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">6</span>), (<span class="number">1</span>,<span class="number">7</span>), (<span class="number">1</span>,<span class="number">8</span>), (<span class="number">1</span>,<span class="number">9</span>), (<span class="number">1</span>,<span class="number">10</span>), (<span class="number">2</span>,<span class="number">6</span>), (<span class="number">2</span>,<span class="number">7</span>), (<span class="number">2</span>,<span class="number">8</span>), (<span class="number">2</span>,<span class="number">9</span>), (<span class="number">2</span>,<span class="number">10</span>), (<span class="number">3</span>,<span class="number">6</span>), (<span class="number">3</span>,<span class="number">7</span>), (<span class="number">3</span>,<span class="number">8</span>), (<span class="number">3</span>,<span class="number">9</span>), (<span class="number">3</span>,<span class="number">10</span>), (<span class="number">4</span>,<span class="number">6</span>), (<span class="number">5</span>,<span class="number">6</span>), (<span class="number">4</span>,<span class="number">7</span>), (<span class="number">5</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>), (<span class="number">5</span>,<span class="number">8</span>), (<span class="number">4</span>,<span class="number">9</span>), (<span class="number">4</span>,<span class="number">10</span>), (<span class="number">5</span>,<span class="number">9</span>), (<span class="number">5</span>,<span class="number">10</span>))</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%906.png" alt=""><br></center>


<p><strong>7）groupBy（生成相应的key，相同的放在一起）</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">9</span>, <span class="number">3</span>)</div><div class="line">a.groupBy(x =&gt; &#123; <span class="keyword">if</span> (x % <span class="number">2</span> == <span class="number">0</span>) <span class="string">"even"</span> <span class="keyword">else</span> <span class="string">"odd"</span> &#125;).collect</div><div class="line">res42: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Seq</span>[<span class="type">Int</span>])] = <span class="type">Array</span>((even,<span class="type">ArrayBuffer</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>)), (odd,<span class="type">ArrayBuffer</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>)))</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%907.png" alt=""><br></center>


<p><strong>8）filter</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = a.filter(_ % <span class="number">2</span> == <span class="number">0</span>)</div><div class="line">b.collect</div><div class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%908.png" alt=""><br></center>


<p><strong>9）distinct（去重）</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"Gnu"</span>, <span class="string">"Cat"</span>, <span class="string">"Rat"</span>, <span class="string">"Dog"</span>, <span class="string">"Gnu"</span>, <span class="string">"Rat"</span>), <span class="number">2</span>)</div><div class="line">c.distinct.collect</div><div class="line">res6: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="type">Dog</span>, <span class="type">Gnu</span>, <span class="type">Cat</span>, <span class="type">Rat</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%909.png" alt=""><br></center>


<p><strong>10）subtract（去掉含有重复的项）</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">9</span>, <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = sc.parallelize(<span class="number">1</span> to <span class="number">3</span>, <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> c = a.subtract(b)</div><div class="line">c.collect</div><div class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">6</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">8</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9010.png" alt=""><br></center>


<p><strong>11）sample</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">10000</span>, <span class="number">3</span>)</div><div class="line">a.sample(<span class="literal">false</span>, <span class="number">0.1</span>, <span class="number">0</span>).count</div><div class="line">res24: <span class="type">Long</span> = <span class="number">960</span></div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9011.png" alt=""><br></center>

<p><strong>12）takesample</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> x = sc.parallelize(<span class="number">1</span> to <span class="number">1000</span>, <span class="number">3</span>)</div><div class="line">x.takeSample(<span class="literal">true</span>, <span class="number">100</span>, <span class="number">1</span>)</div><div class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">339</span>, <span class="number">718</span>, <span class="number">810</span>, <span class="number">105</span>, <span class="number">71</span>, <span class="number">268</span>, <span class="number">333</span>, <span class="number">360</span>, <span class="number">341</span>, <span class="number">300</span>, <span class="number">68</span>, <span class="number">848</span>, <span class="number">431</span>, <span class="number">449</span>, <span class="number">773</span>, <span class="number">172</span>, <span class="number">802</span>, <span class="number">339</span>, <span class="number">431</span>, <span class="number">285</span>, <span class="number">937</span>, <span class="number">301</span>, <span class="number">167</span>, <span class="number">69</span>, <span class="number">330</span>, <span class="number">864</span>, <span class="number">40</span>, <span class="number">645</span>, <span class="number">65</span>, <span class="number">349</span>, <span class="number">613</span>, <span class="number">468</span>, <span class="number">982</span>, <span class="number">314</span>, <span class="number">160</span>, <span class="number">675</span>, <span class="number">232</span>, <span class="number">794</span>, <span class="number">577</span>, <span class="number">571</span>, <span class="number">805</span>, <span class="number">317</span>, <span class="number">136</span>, <span class="number">860</span>, <span class="number">522</span>, <span class="number">45</span>, <span class="number">628</span>, <span class="number">178</span>, <span class="number">321</span>, <span class="number">482</span>, <span class="number">657</span>, <span class="number">114</span>, <span class="number">332</span>, <span class="number">728</span>, <span class="number">901</span>, <span class="number">290</span>, <span class="number">175</span>, <span class="number">876</span>, <span class="number">227</span>, <span class="number">130</span>, <span class="number">863</span>, <span class="number">773</span>, <span class="number">559</span>, <span class="number">301</span>, <span class="number">694</span>, <span class="number">460</span>, <span class="number">839</span>, <span class="number">952</span>, <span class="number">664</span>, <span class="number">851</span>, <span class="number">260</span>, <span class="number">729</span>, <span class="number">823</span>, <span class="number">880</span>, <span class="number">792</span>, <span class="number">964</span>, <span class="number">614</span>, <span class="number">821</span>, <span class="number">683</span>, <span class="number">364</span>, <span class="number">80</span>, <span class="number">875</span>, <span class="number">813</span>, <span class="number">951</span>, <span class="number">663</span>, <span class="number">344</span>, <span class="number">546</span>, <span class="number">918</span>, <span class="number">436</span>, <span class="number">451</span>, <span class="number">397</span>, <span class="number">670</span>, <span class="number">756</span>, <span class="number">512</span>, <span class="number">391</span>, <span class="number">70</span>, <span class="number">213</span>, <span class="number">896</span>, <span class="number">123</span>, <span class="number">858</span>)</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9012.png" alt=""><br></center>



<p><strong>13）cache、persist</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"Gnu"</span>, <span class="string">"Cat"</span>, <span class="string">"Rat"</span>, <span class="string">"Dog"</span>, <span class="string">"Gnu"</span>, <span class="string">"Rat"</span>), <span class="number">2</span>)</div><div class="line">c.getStorageLevel</div><div class="line">res0: org.apache.spark.storage.<span class="type">StorageLevel</span> = <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">1</span>)</div><div class="line">c.cache</div><div class="line">c.getStorageLevel</div><div class="line">res2: org.apache.spark.storage.<span class="type">StorageLevel</span> = <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">1</span>)</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9013.png" alt=""><br></center>

<h2 id="Key-Value型Transformation算子"><a href="#Key-Value型Transformation算子" class="headerlink" title="Key-Value型Transformation算子"></a>Key-Value型Transformation算子</h2><p><strong>1）mapValues</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"tiger"</span>, <span class="string">"lion"</span>, <span class="string">"cat"</span>, <span class="string">"panther"</span>, <span class="string">"eagle"</span>), <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> b = a.map(x =&gt; (x.length, x))</div><div class="line">b.mapValues(<span class="string">"x"</span> + _ + <span class="string">"x"</span>).collect</div><div class="line">res5: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">3</span>,xdogx), (<span class="number">5</span>,xtigerx), (<span class="number">4</span>,xlionx), (<span class="number">3</span>,xcatx), (<span class="number">7</span>,xpantherx), (<span class="number">5</span>,xeaglex))</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9014.png" alt=""><br></center>


<p><strong>2）combineByKey</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>,<span class="string">"cat"</span>,<span class="string">"gnu"</span>,<span class="string">"salmon"</span>,<span class="string">"rabbit"</span>,<span class="string">"turkey"</span>,<span class="string">"wolf"</span>,<span class="string">"bear"</span>,<span class="string">"bee"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> c = b.zip(a)</div><div class="line"><span class="keyword">val</span> d = c.combineByKey(<span class="type">List</span>(_), (x:<span class="type">List</span>[<span class="type">String</span>], y:<span class="type">String</span>) =&gt; y :: x, (x:<span class="type">List</span>[<span class="type">String</span>], y:<span class="type">List</span>[<span class="type">String</span>]) =&gt; x ::: y)</div><div class="line">d.collect</div><div class="line">res16: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">List</span>[<span class="type">String</span>])] = <span class="type">Array</span>((<span class="number">1</span>,<span class="type">List</span>(cat, dog, turkey)), (<span class="number">2</span>,<span class="type">List</span>(gnu, rabbit, salmon, bee, bear, wolf)))</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9015.png" alt=""><br></center>


<p><strong>3）reduceByKey</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"cat"</span>, <span class="string">"owl"</span>, <span class="string">"gnu"</span>, <span class="string">"ant"</span>), <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> b = a.map(x =&gt; (x.length, x))</div><div class="line">b.reduceByKey(_ + _).collect</div><div class="line">res86: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">3</span>,dogcatowlgnuant))</div><div class="line"></div><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"tiger"</span>, <span class="string">"lion"</span>, <span class="string">"cat"</span>, <span class="string">"panther"</span>, <span class="string">"eagle"</span>), <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> b = a.map(x =&gt; (x.length, x))</div><div class="line">b.reduceByKey(_ + _).collect</div><div class="line">res87: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">4</span>,lion), (<span class="number">3</span>,dogcat), (<span class="number">7</span>,panther), (<span class="number">5</span>,tigereagle))</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9016.png" alt=""><br></center>


<p><strong>4）partitionBy</strong></p>
<p>（对RDD进行分区操作）</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9017.png" alt=""><br></center>

<p><strong>5）cogroup</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>), <span class="number">1</span>)</div><div class="line"><span class="keyword">val</span> b = a.map((_, <span class="string">"b"</span>))</div><div class="line"><span class="keyword">val</span> c = a.map((_, <span class="string">"c"</span>))</div><div class="line">b.cogroup(c).collect</div><div class="line">res7: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">Iterable</span>[<span class="type">String</span>], <span class="type">Iterable</span>[<span class="type">String</span>]))] = <span class="type">Array</span>(</div><div class="line">(<span class="number">2</span>,(<span class="type">ArrayBuffer</span>(b),<span class="type">ArrayBuffer</span>(c))),</div><div class="line">(<span class="number">3</span>,(<span class="type">ArrayBuffer</span>(b),<span class="type">ArrayBuffer</span>(c))),</div><div class="line">(<span class="number">1</span>,(<span class="type">ArrayBuffer</span>(b, b),<span class="type">ArrayBuffer</span>(c, c)))</div><div class="line">)</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9018.png" alt=""><br></center>


<p><strong>6）join</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"salmon"</span>, <span class="string">"salmon"</span>, <span class="string">"rat"</span>, <span class="string">"elephant"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = a.keyBy(_.length)</div><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>,<span class="string">"cat"</span>,<span class="string">"gnu"</span>,<span class="string">"salmon"</span>,<span class="string">"rabbit"</span>,<span class="string">"turkey"</span>,<span class="string">"wolf"</span>,<span class="string">"bear"</span>,<span class="string">"bee"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> d = c.keyBy(_.length)</div><div class="line">b.join(d).collect</div><div class="line"></div><div class="line">res0: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">String</span>, <span class="type">String</span>))] = <span class="type">Array</span>((<span class="number">6</span>,(salmon,salmon)), (<span class="number">6</span>,(salmon,rabbit)), (<span class="number">6</span>,(salmon,turkey)), (<span class="number">6</span>,(salmon,salmon)), (<span class="number">6</span>,(salmon,rabbit)), (<span class="number">6</span>,(salmon,turkey)), (<span class="number">3</span>,(dog,dog)), (<span class="number">3</span>,(dog,cat)), (<span class="number">3</span>,(dog,gnu)), (<span class="number">3</span>,(dog,bee)), (<span class="number">3</span>,(rat,dog)), (<span class="number">3</span>,(rat,cat)), (<span class="number">3</span>,(rat,gnu)), (<span class="number">3</span>,(rat,bee)))</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9019.png" alt=""><br></center>


<p><strong>7）leftOutJoin</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"salmon"</span>, <span class="string">"salmon"</span>, <span class="string">"rat"</span>, <span class="string">"elephant"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = a.keyBy(_.length)</div><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>,<span class="string">"cat"</span>,<span class="string">"gnu"</span>,<span class="string">"salmon"</span>,<span class="string">"rabbit"</span>,<span class="string">"turkey"</span>,<span class="string">"wolf"</span>,<span class="string">"bear"</span>,<span class="string">"bee"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> d = c.keyBy(_.length)</div><div class="line">b.leftOuterJoin(d).collect</div><div class="line"></div><div class="line">res1: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">String</span>, <span class="type">Option</span>[<span class="type">String</span>]))] = <span class="type">Array</span>((<span class="number">6</span>,(salmon,<span class="type">Some</span>(salmon))), (<span class="number">6</span>,(salmon,<span class="type">Some</span>(rabbit))), (<span class="number">6</span>,(salmon,<span class="type">Some</span>(turkey))), (<span class="number">6</span>,(salmon,<span class="type">Some</span>(salmon))), (<span class="number">6</span>,(salmon,<span class="type">Some</span>(rabbit))), (<span class="number">6</span>,(salmon,<span class="type">Some</span>(turkey))), (<span class="number">3</span>,(dog,<span class="type">Some</span>(dog))), (<span class="number">3</span>,(dog,<span class="type">Some</span>(cat))), (<span class="number">3</span>,(dog,<span class="type">Some</span>(gnu))), (<span class="number">3</span>,(dog,<span class="type">Some</span>(bee))), (<span class="number">3</span>,(rat,<span class="type">Some</span>(dog))), (<span class="number">3</span>,(rat,<span class="type">Some</span>(cat))), (<span class="number">3</span>,(rat,<span class="type">Some</span>(gnu))), (<span class="number">3</span>,(rat,<span class="type">Some</span>(bee))), (<span class="number">8</span>,(elephant,<span class="type">None</span>)))</div></pre></td></tr></table></figure>
<p><strong>8）rightOutJoin</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"salmon"</span>, <span class="string">"salmon"</span>, <span class="string">"rat"</span>, <span class="string">"elephant"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> b = a.keyBy(_.length)</div><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>,<span class="string">"cat"</span>,<span class="string">"gnu"</span>,<span class="string">"salmon"</span>,<span class="string">"rabbit"</span>,<span class="string">"turkey"</span>,<span class="string">"wolf"</span>,<span class="string">"bear"</span>,<span class="string">"bee"</span>), <span class="number">3</span>)</div><div class="line"><span class="keyword">val</span> d = c.keyBy(_.length)</div><div class="line">b.rightOuterJoin(d).collect</div><div class="line"></div><div class="line">res2: <span class="type">Array</span>[(<span class="type">Int</span>, (<span class="type">Option</span>[<span class="type">String</span>], <span class="type">String</span>))] = <span class="type">Array</span>((<span class="number">6</span>,(<span class="type">Some</span>(salmon),salmon)), (<span class="number">6</span>,(<span class="type">Some</span>(salmon),rabbit)), (<span class="number">6</span>,(<span class="type">Some</span>(salmon),turkey)), (<span class="number">6</span>,(<span class="type">Some</span>(salmon),salmon)), (<span class="number">6</span>,(<span class="type">Some</span>(salmon),rabbit)), (<span class="number">6</span>,(<span class="type">Some</span>(salmon),turkey)), (<span class="number">3</span>,(<span class="type">Some</span>(dog),dog)), (<span class="number">3</span>,(<span class="type">Some</span>(dog),cat)), (<span class="number">3</span>,(<span class="type">Some</span>(dog),gnu)), (<span class="number">3</span>,(<span class="type">Some</span>(dog),bee)), (<span class="number">3</span>,(<span class="type">Some</span>(rat),dog)), (<span class="number">3</span>,(<span class="type">Some</span>(rat),cat)), (<span class="number">3</span>,(<span class="type">Some</span>(rat),gnu)), (<span class="number">3</span>,(<span class="type">Some</span>(rat),bee)), (<span class="number">4</span>,(<span class="type">None</span>,wolf)), (<span class="number">4</span>,(<span class="type">None</span>,bear)))</div></pre></td></tr></table></figure>
<h2 id="Actions算子"><a href="#Actions算子" class="headerlink" title="Actions算子"></a>Actions算子</h2><p><strong>1）foreach</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"cat"</span>, <span class="string">"dog"</span>, <span class="string">"tiger"</span>, <span class="string">"lion"</span>, <span class="string">"gnu"</span>, <span class="string">"crocodile"</span>, <span class="string">"ant"</span>, <span class="string">"whale"</span>, <span class="string">"dolphin"</span>, <span class="string">"spider"</span>), <span class="number">3</span>)</div><div class="line">c.foreach(x =&gt; println(x + <span class="string">"s are yummy"</span>))</div><div class="line">lions are yummy</div><div class="line">gnus are yummy</div><div class="line">crocodiles are yummy</div><div class="line">ants are yummy</div><div class="line">whales are yummy</div><div class="line">dolphins are yummy</div><div class="line">spiders are yummy</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9020.png" alt=""><br></center>

<p><strong>2）saveAsTextFile</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">10000</span>, <span class="number">3</span>)</div><div class="line">a.saveAsTextFile(<span class="string">"mydata_a"</span>)</div><div class="line"><span class="number">14</span>/<span class="number">04</span>/<span class="number">03</span> <span class="number">21</span>:<span class="number">11</span>:<span class="number">36</span> <span class="type">INFO</span> <span class="type">FileOutputCommitter</span>: <span class="type">Saved</span> output of task <span class="symbol">'attempt_201404032111_0000_m_000002_7</span>1' to file:/home/cloudera/<span class="type">Documents</span>/spark<span class="number">-0.9</span><span class="number">.0</span>-incubating-bin-cdh4/bin/mydata_a</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9021.png" alt=""><br></center>


<p><strong>3）saveAsObjectFile</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> x = sc.parallelize(<span class="number">1</span> to <span class="number">100</span>, <span class="number">3</span>)</div><div class="line">x.saveAsObjectFile(<span class="string">"objFile"</span>)</div><div class="line"><span class="keyword">val</span> y = sc.objectFile[<span class="type">Int</span>](<span class="string">"objFile"</span>)</div><div class="line">y.collect</div><div class="line">res52: <span class="type">Array</span>[<span class="type">Int</span>] =  <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>, <span class="number">36</span>, <span class="number">37</span>, <span class="number">38</span>, <span class="number">39</span>, <span class="number">40</span>, <span class="number">41</span>, <span class="number">42</span>, <span class="number">43</span>, <span class="number">44</span>, <span class="number">45</span>, <span class="number">46</span>, <span class="number">47</span>, <span class="number">48</span>, <span class="number">49</span>, <span class="number">50</span>, <span class="number">51</span>, <span class="number">52</span>, <span class="number">53</span>, <span class="number">54</span>, <span class="number">55</span>, <span class="number">56</span>, <span class="number">57</span>, <span class="number">58</span>, <span class="number">59</span>, <span class="number">60</span>, <span class="number">61</span>, <span class="number">62</span>, <span class="number">63</span>, <span class="number">64</span>, <span class="number">65</span>, <span class="number">66</span>, <span class="number">67</span>, <span class="number">68</span>, <span class="number">69</span>, <span class="number">70</span>, <span class="number">71</span>, <span class="number">72</span>, <span class="number">73</span>, <span class="number">74</span>, <span class="number">75</span>, <span class="number">76</span>, <span class="number">77</span>, <span class="number">78</span>, <span class="number">79</span>, <span class="number">80</span>, <span class="number">81</span>, <span class="number">82</span>, <span class="number">83</span>, <span class="number">84</span>, <span class="number">85</span>, <span class="number">86</span>, <span class="number">87</span>, <span class="number">88</span>, <span class="number">89</span>, <span class="number">90</span>, <span class="number">91</span>, <span class="number">92</span>, <span class="number">93</span>, <span class="number">94</span>, <span class="number">95</span>, <span class="number">96</span>, <span class="number">97</span>, <span class="number">98</span>, <span class="number">99</span>, <span class="number">100</span>)</div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9022.png" alt=""><br></center>

<p><strong>4）collect</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"Gnu"</span>, <span class="string">"Cat"</span>, <span class="string">"Rat"</span>, <span class="string">"Dog"</span>, <span class="string">"Gnu"</span>, <span class="string">"Rat"</span>), <span class="number">2</span>)</div><div class="line">c.collect</div><div class="line">res29: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>(<span class="type">Gnu</span>, <span class="type">Cat</span>, <span class="type">Rat</span>, <span class="type">Dog</span>, <span class="type">Gnu</span>, <span class="type">Rat</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9023.png" alt=""><br></center>


<p><strong>5）collectAsMap</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>), <span class="number">1</span>)</div><div class="line"><span class="keyword">val</span> b = a.zip(a)</div><div class="line">b.collectAsMap</div><div class="line">res1: scala.collection.<span class="type">Map</span>[<span class="type">Int</span>,<span class="type">Int</span>] = <span class="type">Map</span>(<span class="number">2</span> -&gt; <span class="number">2</span>, <span class="number">1</span> -&gt; <span class="number">1</span>, <span class="number">3</span> -&gt; <span class="number">3</span>)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9024.png" alt=""><br></center>

<p><strong>6）reduceByKeyLocally</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"cat"</span>, <span class="string">"owl"</span>, <span class="string">"gnu"</span>, <span class="string">"ant"</span>), <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> b = a.map(x =&gt; (x.length, x))</div><div class="line">b.reduceByKey(_ + _).collect</div><div class="line">res86: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">Array</span>((<span class="number">3</span>,dogcatowlgnuant))</div></pre></td></tr></table></figure></p>
<p><strong>7）lookup</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="string">"dog"</span>, <span class="string">"tiger"</span>, <span class="string">"lion"</span>, <span class="string">"cat"</span>, <span class="string">"panther"</span>, <span class="string">"eagle"</span>), <span class="number">2</span>)</div><div class="line"><span class="keyword">val</span> b = a.map(x =&gt; (x.length, x))</div><div class="line">b.lookup(<span class="number">5</span>)</div><div class="line">res0: <span class="type">Seq</span>[<span class="type">String</span>] = <span class="type">WrappedArray</span>(tiger, eagle)</div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9025.png" alt=""><br></center>

<p><strong>8）count</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">List</span>(<span class="string">"Gnu"</span>, <span class="string">"Cat"</span>, <span class="string">"Rat"</span>, <span class="string">"Dog"</span>), <span class="number">2</span>)</div><div class="line">c.count</div><div class="line">res2: <span class="type">Long</span> = <span class="number">4</span></div></pre></td></tr></table></figure></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9026.png" alt=""><br></center>


<p><strong>9）top</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> c = sc.parallelize(<span class="type">Array</span>(<span class="number">6</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">8</span>), <span class="number">2</span>)</div><div class="line">c.top(<span class="number">2</span>)</div><div class="line">res28: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">9</span>, <span class="number">8</span>)</div></pre></td></tr></table></figure></p>
<p><strong>10）reduce</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="number">1</span> to <span class="number">100</span>, <span class="number">3</span>)</div><div class="line">a.reduce(_ + _)</div><div class="line">res41: <span class="type">Int</span> = <span class="number">5050</span></div></pre></td></tr></table></figure>
<p><strong>11）fold</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> a = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>), <span class="number">3</span>)</div><div class="line">a.fold(<span class="number">0</span>)(_ + _)</div><div class="line">res59: <span class="type">Int</span> = <span class="number">6</span></div></pre></td></tr></table></figure>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/spark%E7%AE%97%E5%AD%9027.png" alt=""><br></center>


<p><strong>12）aggregate</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">val</span> z = sc.parallelize(<span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>), <span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment">// lets first print out the contents of the RDD with partition labels</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc</span></span>(index: <span class="type">Int</span>, iter: <span class="type">Iterator</span>[(<span class="type">Int</span>)]) : <span class="type">Iterator</span>[<span class="type">String</span>] = &#123;</div><div class="line">  iter.toList.map(x =&gt; <span class="string">"[partID:"</span> +  index + <span class="string">", val: "</span> + x + <span class="string">"]"</span>).iterator</div><div class="line">&#125;</div><div class="line"></div><div class="line">z.mapPartitionsWithIndex(myfunc).collect</div><div class="line">res28: <span class="type">Array</span>[<span class="type">String</span>] = <span class="type">Array</span>([partID:<span class="number">0</span>, <span class="keyword">val</span>: <span class="number">1</span>], [partID:<span class="number">0</span>, <span class="keyword">val</span>: <span class="number">2</span>], [partID:<span class="number">0</span>, <span class="keyword">val</span>: <span class="number">3</span>], [partID:<span class="number">1</span>, <span class="keyword">val</span>: <span class="number">4</span>], [partID:<span class="number">1</span>, <span class="keyword">val</span>: <span class="number">5</span>], [partID:<span class="number">1</span>, <span class="keyword">val</span>: <span class="number">6</span>])</div><div class="line"></div><div class="line">z.aggregate(<span class="number">0</span>)(math.max(_, _), _ + _)</div><div class="line">res40: <span class="type">Int</span> = <span class="number">9</span></div></pre></td></tr></table></figure>
<p>参考：<a href="http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html" target="_blank" rel="external">http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html</a></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java虚拟机之JVM运行时数据区]]></title>
      <url>http://Melodylican.github.io/2017/08/09/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B9%8BJVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/</url>
      <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Java虚拟机在执行Java程序时会将其所管理的内存区域分成几个不同的部分，这几个部分的生命周期以及作用都各自不同，这些区域分别为：方法区（Method Area）、堆（Heap）、虚拟栈（VM Stack）、本地方法栈（Native Method Stack）、程序计数器（Program Counter Register），下面分别详细介绍一下。<br><a id="more"></a></p>
<h2 id="运行时线程之间相互隔离的数据区域"><a href="#运行时线程之间相互隔离的数据区域" class="headerlink" title="运行时线程之间相互隔离的数据区域"></a>运行时线程之间相互隔离的数据区域</h2><ul>
<li>虚拟机栈</li>
<li>本地方法栈</li>
<li>程序计数器</li>
</ul>
<h3 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h3><p>虚拟机栈属于线程私有，其生命周期与线程保持一致。VM Stack描述的是一个Java方法执行 时的内存模型。每个方法在执行时都会创建一个栈帧，这个栈帧会存储方法的局部变量表、操作数栈、方法出口等信息。一个Java方法从运行到结束，对应于一个栈帧从虚拟机栈入栈到出栈的过程。这里的局部变量表存放了各种基本类型（比如int、float等）、还有对象引用。Java方法运行时，局部变量表是不会改变的，因为VM Stack中需要对正要运行的方法创建多大空间的栈帧是确定的。但如果线程请求的栈帧空间大于VM Stack时就会抛出OOM异常。</p>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p>本地方法栈与VM Stack的作用基本相同，部分虚拟机并没有按照Java虚拟机规范分开两者，像HotSpot虚拟机就将二者合起来。</p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>程序计数器属于线程私有空间，可以认为程序计数器就是一个当前正在执行的字节码的行号指示器，虚拟机的字节码解释器就是通过改变这个计数器的值来选择吓一条需要执行的指令，比如分支语句、循环语句、跳转语句、异常等等都需要依赖程序计数器完成。不同于操作系统的多线程模型，JVM的多线程是依赖于抢占CPU执行时间来完成，也就是说任何时刻，一个CPU核心只会执行一个线程中的指令，因此，为了线程切换之后程序能回到正确的指令处理位置，每个线程都需要一个独立的程序计数器。如果程序正在执行的是一个Java方法，则程序计数器记录的是正在执行的字节码的指令地址，如果正在执行的是一个native方法呢，其值为空（Undefined）。Java虚拟机规范里面，程序计数器是唯一一个不会有OOM的区域。</p>
<h2 id="运行时线程之间共享的数据区域"><a href="#运行时线程之间共享的数据区域" class="headerlink" title="运行时线程之间共享的数据区域"></a>运行时线程之间共享的数据区域</h2><ul>
<li>方法区</li>
<li>堆</li>
</ul>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>用于存储已经被虚拟机加载的类信息、常量、静态变量等。</p>
<h3 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h3><p>Java Heap 是虚拟机管理的内存区域中最大的一块了。Java堆在虚拟机启动时创建，并被所有线程所共享。这个Java堆呢，只用于存放对象实例，理论上所有的对象实例都在这里分配内存。因为堆区是垃圾收集器所关注的主要区域，而现在的很多垃圾收集器都采用分代收集算法，所有Java堆还可以细分为新生代和老年代。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[集中式内存缓存Guava Cache]]></title>
      <url>http://Melodylican.github.io/2017/08/08/%E9%9B%86%E4%B8%AD%E5%BC%8F%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98Guava_Cache/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>缓存的主要作用是暂时在内存中保存业务系统的数据处理结果，并且等待下次访问使用。在日长开发有很多场合，有一些数据量不是很大，不会经常改动，并且访问非常频繁。但是由于受限于硬盘IO的性能或者远程网络等原因获取可能非常的费时。会导致我们的程序非常缓慢，这在某些业务上是不能忍的！而缓存正是解决这类问题的神器！<br><a id="more"></a></p>
<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/guava_cache.png" alt=""><br></center><br>当然也并不是说你用了缓存你的系统就一定会变快，建议在用之前看一下<a href="http://kb.cnblogs.com/page/138696/" target="_blank" rel="external">使用缓存的9大误区(上)</a> <a href="http://kb.cnblogs.com/page/144396/" target="_blank" rel="external">使用缓存的9大误区(下)</a></p>
<p>缓存在很多系统和架构中都用广泛的应用,例如：</p>
<ul>
<li>CPU缓存</li>
<li>操作系统缓存</li>
<li>HTTP缓存</li>
<li>数据库缓存</li>
<li>静态文件缓存</li>
<li>本地缓存</li>
<li>分布式缓存</li>
</ul>
<p>可以说在计算机和网络领域，缓存是无处不在的。可以这么说，只要有硬件性能不对等，涉及到网络传输的地方都会有缓存的身影。</p>
<p>缓存总体可分为两种 集中式缓存 和 分布式缓存</p>
<p>“集中式缓存”与”分布式缓存”的区别其实就在于“集中”与”非集中”的概念，其对象可能是服务器、内存条、硬盘等。比如：</p>
<h3 id="1-服务器版本："><a href="#1-服务器版本：" class="headerlink" title="1.服务器版本："></a>1.服务器版本：</h3><ul>
<li>缓存集中在一台服务器上，为集中式缓存。</li>
<li>缓存分散在不同的服务器上，为分布式缓存。</li>
</ul>
<h3 id="2-内存条版本："><a href="#2-内存条版本：" class="headerlink" title="2.内存条版本："></a>2.内存条版本：</h3><ul>
<li>缓存集中在一台服务器的一条内存条上，为集中式缓存。</li>
<li>缓存分散在一台服务器的不同内存条上，为分布式缓存。</li>
</ul>
<h3 id="3-硬盘版本："><a href="#3-硬盘版本：" class="headerlink" title="3.硬盘版本："></a>3.硬盘版本：</h3><ul>
<li>缓存集中在一台服务器的一个硬盘上，为集中式缓存。</li>
<li>缓存分散在一台服务器的不同硬盘上，为分布式缓存。<br>想了解分布式缓存可以看一下<a href="http://os.51cto.com/art/201306/397999.htm" target="_blank" rel="external">浅谈分布式缓存那些事儿</a>。</li>
</ul>
<p>这是几个当前比较流行的java 分布式缓存框架<a href="http://developer.51cto.com/art/201411/457423.htm" target="_blank" rel="external">5个强大的Java分布式缓存框架推荐</a>。</p>
<p>而我们今天要讲的是集中式内存缓存guava cache,这是当前我们项目正在用的缓存工具，研究一下感觉还蛮好用的。当然也有很多其他工具，还是看个人喜欢。oschina上面也有很多类似开源的<a href="http://www.oschina.net/project/tag/132/cachesystem?sort=view&amp;lang=19&amp;os=0" target="_blank" rel="external">java缓存框架</a></p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>Guava Cache与ConcurrentMap很相似，但也不完全一样。最基本的区别是ConcurrentMap会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache为了限制内存占用，通常都设定为自动回收元素。在某些场景下，尽管LoadingCache 不回收元素，它也是很有用的，因为它会自动加载缓存。</p>
<p>guava cache 加载缓存主要有两种方式:</p>
<ol>
<li>cacheLoader</li>
<li>callable callback</li>
</ol>
<h3 id="cacheLoader"><a href="#cacheLoader" class="headerlink" title="cacheLoader"></a>cacheLoader</h3><p>创建自己的CacheLoader通常只需要简单地实现V load(K key) throws Exception方法.</p>
<p>cacheLoader方式实现实例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">LoadingCache&lt;Key, Value&gt; cache = CacheBuilder.newBuilder()</div><div class="line">       .build(</div><div class="line">           <span class="keyword">new</span> CacheLoader&lt;Key, Value&gt;() &#123;</div><div class="line">             <span class="function"><span class="keyword">public</span> Value <span class="title">load</span><span class="params">(Key key)</span> <span class="keyword">throws</span> AnyException </span>&#123;</div><div class="line">               <span class="keyword">return</span> createValue(key);</div><div class="line">             &#125;</div><div class="line">           &#125;);</div><div class="line">...</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="keyword">return</span> cache.get(key);</div><div class="line">&#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> OtherException(e.getCause());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从LoadingCache查询的正规方式是使用get(K)方法。这个方法要么返回已经缓存的值，要么使用CacheLoader向缓存原子地加载新值（通过load(String key) 方法加载）。由于CacheLoader可能抛出异常，LoadingCache.get(K)也声明抛出ExecutionException异常。如果你定义的CacheLoader没有声明任何检查型异常，则可以通过getUnchecked(K)查找缓存；但必须注意，一旦CacheLoader声明了检查型异常，就不可以调用getUnchecked(K)。</p>
<h3 id="Callable"><a href="#Callable" class="headerlink" title="Callable"></a>Callable</h3><p>这种方式不需要在创建的时候指定load方法，但是需要在get的时候实现一个Callable匿名内部类。</p>
<p>Callable方式实现实例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Cache&lt;Key, Value&gt; cache = CacheBuilder.newBuilder()</div><div class="line">    .build(); <span class="comment">// look Ma, no CacheLoader</span></div><div class="line">...</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">  <span class="comment">// If the key wasn't in the "easy to compute" group, we need to</span></div><div class="line">  <span class="comment">// do things the hard way.</span></div><div class="line">  cache.get(key, <span class="keyword">new</span> Callable&lt;Value&gt;() &#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> Value <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> AnyException </span>&#123;</div><div class="line">      <span class="keyword">return</span> doThingsTheHardWay(key);</div><div class="line">    &#125;</div><div class="line">  &#125;);</div><div class="line">&#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> OtherException(e.getCause());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>而如果加上现在java8里面的Lambda表达式会看起来舒服很多<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">   cache.get(key,()-&gt;&#123;</div><div class="line">     <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">   &#125;);</div><div class="line"> &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</div><div class="line">   e.printStackTrace();</div><div class="line"> &#125;</div></pre></td></tr></table></figure></p>
<p>所有类型的Guava Cache，不管有没有自动加载功能，都支持get(K, Callable<v>)方法。这个方法返回缓存中相应的值，或者用给定的Callable运算并把结果加入到缓存中。在整个加载方法完成前，缓存项相关的可观察状态都不会更改。这个方法简便地实现了模式”如果有缓存则返回；否则运算、缓存、然后返回”。</v></p>
<p>当然除了上面那种被动的加载，它还提供了主动加载的方法cache.put(key, value)，这会直接覆盖掉给定键之前映射的值。使用Cache.asMap()视图提供的任何方法也能修改缓存。但请注意，asMap视图的任何方法都不能保证缓存项被原子地加载到缓存中。进一步说，asMap视图的原子运算在Guava Cache的原子加载范畴之外，所以相比于Cache.asMap().putIfAbsent(K,V)，Cache.get(K, Callable<v>) 应该总是优先使用。</v></p>
<h2 id="缓存回收"><a href="#缓存回收" class="headerlink" title="缓存回收"></a>缓存回收</h2><p>上面有提到 Guava Cache与ConcurrentMap 不一样的地方在于 guava cache可以自动回收元素，这在某种情况下可以更好优化资源被浪费的情况。</p>
<h3 id="基于容量的回收"><a href="#基于容量的回收" class="headerlink" title="基于容量的回收"></a>基于容量的回收</h3><p>当缓存设置CacheBuilder.maximumSize(size)。这个size是指具体缓存项目的数量而不是内存的大小。而且并不是说数量大于size才会回收，而是接近size就回收。</p>
<h3 id="定时回收"><a href="#定时回收" class="headerlink" title="定时回收"></a>定时回收</h3><ul>
<li>expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。</li>
<li>expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回 收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。</li>
</ul>
<p>guava cache 还提供一个Ticker方法来设置缓存失效的具体时间精度为纳秒级。</p>
<h3 id="基于引用的回收"><a href="#基于引用的回收" class="headerlink" title="基于引用的回收"></a>基于引用的回收</h3><p>通过使用弱引用的键、或弱引用的值、或软引用的值，Guava Cache可以把缓存设置为允许垃圾回收：</p>
<ul>
<li>CacheBuilder.weakKeys()：使用弱引用存储键。当键没有其它（强或软）引用时，缓存项可以被垃圾回收。因为垃圾回收仅依赖恒等式（==），使用弱引用键的缓存用==而不是equals比较键。</li>
<li>CacheBuilder.weakValues()：使用弱引用存储值。当值没有其它（强或软）引用时，缓存项可以被垃圾回收。因为垃圾回收仅依赖恒等式（==），使用弱引用值的缓存用==而不是equals比较值。</li>
<li>CacheBuilder.softValues()：使用软引用存储值。软引用只有在响应内存需要时，才按照全局最近最少使用的顺序回收。考虑到使用软引用的性能影响，我们通常建议使用更有性能预测性的缓存大小限定（见上文，基于容量回收）。使用软引用值的缓存同样用==而不是equals比较值。</li>
</ul>
<h3 id="显式清除"><a href="#显式清除" class="headerlink" title="显式清除"></a>显式清除</h3><p>任何时候，你都可以显式地清除缓存项，而不是等到它被回收：</p>
<ul>
<li>个别清除：Cache.invalidate(key)</li>
<li>批量清除：Cache.invalidateAll(keys)</li>
<li>清除所有缓存项：Cache.invalidateAll()</li>
</ul>
<p>这里说一个小技巧，由于guava cache是存在就取不存在就加载的机制，我们可以对缓存数据有修改的地方显示的把它清除掉，然后再有任务去取的时候就会去数据源重新加载，这样就可以最大程度上保证获取缓存的数据跟数据源是一致的。</p>
<h3 id="移除监听器"><a href="#移除监听器" class="headerlink" title="移除监听器"></a>移除监听器</h3><p>不要被名字所迷惑，这里指的是移除缓存的时候所触发的监听器。</p>
<p>请注意，RemovalListener抛出的任何异常都会在记录到日志后被丢弃[swallowed]。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">LoadingCache&lt;K , V&gt; cache = CacheBuilder</div><div class="line">   .newBuilder()</div><div class="line">   .removalListener(<span class="keyword">new</span> RemovalListener&lt;K, V&gt;()&#123;</div><div class="line">      <span class="meta">@Override</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onRemoval</span><span class="params">(RemovalNotification&lt;K, V&gt; notification)</span> </span>&#123;</div><div class="line">       System.out.println(notification.getKey()+<span class="string">"被移除"</span>);</div><div class="line">     &#125;</div><div class="line">   &#125;)</div></pre></td></tr></table></figure></p>
<p><strong>Lambda的写法</strong>：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">LoadingCache&lt;K , V&gt; cache = CacheBuilder</div><div class="line">   .newBuilder()</div><div class="line">   .removalListener((notification)-&gt;&#123;</div><div class="line">     System.out.println(notification.getKey()+<span class="string">"已移除"</span>);</div><div class="line">   &#125;)</div></pre></td></tr></table></figure></p>
<p><strong>警告</strong>：默认情况下，监听器方法是在移除缓存时同步调用的。因为缓存的维护和请求响应通常是同时进行的，代价高昂的监听器方法在同步模式下会拖慢正常的缓存请求。在这种情况下，你可以使用RemovalListeners.asynchronous(RemovalListener, Executor)把监听器装饰为异步操作。</p>
<p>这里提一下guava cache的自动回收，并不是缓存项过期起马上清理掉，而是在读或写的时候做少量的维护工作，这样做的原因在于：如果要自动地持续清理缓存，就必须有一个线程，这个线程会和用户操作竞争共享锁。此外，某些环境下线程创建可能受限制，这样CacheBuilder就不可用了。</p>
<p>相反，我们把选择权交到你手里。如果你的缓存是高吞吐的，那就无需担心缓存的维护和清理等工作。如果你的缓存只会偶尔有写操作，而你又不想清理工作阻碍了读操作，那么可以创建自己的维护线程，以固定的时间间隔调用Cache.cleanUp()。ScheduledExecutorService可以帮助你很好地实现这样的定时调度。</p>
<h3 id="刷新"><a href="#刷新" class="headerlink" title="刷新"></a>刷新</h3><p>guava cache 除了回收还提供一种刷新机制LoadingCache.refresh(K)，他们的的区别在于，guava cache 在刷新时，其他线程可以继续获取它的旧值。这在某些情况是非常友好的。而回收的话就必须等新值加载完成以后才能继续读取。而且刷新是可以异步进行的。</p>
<p>如果刷新过程抛出异常，缓存将保留旧值，而异常会在记录到日志后被丢弃[swallowed]。<br>重载CacheLoader.reload(K, V)可以扩展刷新时的行为，这个方法允许开发者在计算新值时使用旧的值。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">   <span class="comment">//有些键不需要刷新，并且我们希望刷新是异步完成的</span></div><div class="line">LoadingCache&lt;Key, Value&gt; graphs = CacheBuilder.newBuilder()</div><div class="line">       .maximumSize(<span class="number">1000</span>)</div><div class="line">       .refreshAfterWrite(<span class="number">1</span>, TimeUnit.MINUTES)</div><div class="line">       .build(</div><div class="line">           <span class="keyword">new</span> CacheLoader&lt;Key, Value&gt;() &#123;</div><div class="line">             <span class="function"><span class="keyword">public</span> Graph <span class="title">load</span><span class="params">(Key key)</span> </span>&#123; <span class="comment">// no checked exception</span></div><div class="line">               <span class="keyword">return</span> getValue(key);</div><div class="line">             &#125;</div><div class="line"></div><div class="line">             <span class="function"><span class="keyword">public</span> ListenableFuture&lt;Value&gt; <span class="title">reload</span><span class="params">(<span class="keyword">final</span> Key key, Value value)</span> </span>&#123;</div><div class="line">               <span class="keyword">if</span> (neverNeedsRefresh(key)) &#123;</div><div class="line">                 <span class="keyword">return</span> Futures.immediateFuture(value);</div><div class="line">               &#125; <span class="keyword">else</span> &#123;</div><div class="line">                 <span class="comment">// asynchronous!</span></div><div class="line">                 ListenableFutureTask&lt;Value&gt; task = ListenableFutureTask.create(<span class="keyword">new</span> Callable&lt;Value&gt;() &#123;</div><div class="line">                   <span class="function"><span class="keyword">public</span> Graph <span class="title">call</span><span class="params">()</span> </span>&#123;</div><div class="line">                     <span class="keyword">return</span> getValue(key);</div><div class="line">                   &#125;</div><div class="line">                 &#125;);</div><div class="line">                 executor.execute(task);</div><div class="line">                 <span class="keyword">return</span> task;</div><div class="line">               &#125;</div><div class="line">             &#125;</div><div class="line">           &#125;);</div></pre></td></tr></table></figure></p>
<p>CacheBuilder.refreshAfterWrite(long, TimeUnit)可以为缓存增加自动定时刷新功能。和expireAfterWrite相反，refreshAfterWrite通过定时刷新可以让缓存项保持可用，但请注意：缓存项只有在被检索时才会真正刷新（如果CacheLoader.refresh实现为异步，那么检索不会被刷新拖慢）。因此，如果你在缓存上同时声明expireAfterWrite和refreshAfterWrite，缓存并不会因为刷新盲目地定时重置，如果缓存项没有被检索，那刷新就不会真的发生，缓存项在过期时间后也变得可以回收。</p>
<h2 id="asMap视图"><a href="#asMap视图" class="headerlink" title="asMap视图"></a>asMap视图</h2><p>asMap视图提供了缓存的ConcurrentMap形式，但asMap视图与缓存的交互需要注意：</p>
<ul>
<li>cache.asMap()包含当前所有加载到缓存的项。因此相应地，cache.asMap().keySet()包含当前所有已加载键;</li>
<li>asMap().get(key)实质上等同于cache.getIfPresent(key)，而且不会引起缓存项的加载。这和Map的语义约定一致。</li>
<li>所有读写操作都会重置相关缓存项的访问时间，包括Cache.asMap().get(Object)方法和Cache.asMap().put(K, V)方法，但不包括Cache.asMap().containsKey(Object)方法，也不包括在Cache.asMap()的集合视图上的操作。比如，遍历Cache.asMap().entrySet()不会重置缓存项的读取时间。</li>
</ul>
<h2 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h2><p>guava cache为我们实现统计功能，这在其它缓存工具里面还是很少有的。</p>
<ul>
<li>CacheBuilder.recordStats()用来开启Guava Cache的统计功能。统计打开后， Cache.stats()方法会返回CacheStats对象以提供如下统计信息： </li>
<li>hitRate()：缓存命中率；</li>
<li>averageLoadPenalty()：加载新值的平均时间，单位为纳秒；</li>
<li>evictionCount()：缓存项被回收的总数，不包括显式清除。</li>
</ul>
<p>此外，还有其他很多统计信息。这些统计信息对于调整缓存设置是至关重要的，在性能要求高的应用中我们建议密切关注这些数据， 这里我们就不一一介绍了。</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>缓存虽然是个好东西，但是一定不能滥用，一定要根据自己系统的需求来妥善抉择。<br>当然 guava 除了cache这块还有很多其它非常有用的工具。</p>
<font color="grey" size="1">注：本文参考：<a href="https://github.com/google/guava/wiki/CachesExplained" target="_blank" rel="external">https://github.com/google/guava/wiki/CachesExplained</a></font>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Guava </tag>
            
            <tag> Cache </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[那些忽略的jdk特性]]></title>
      <url>http://Melodylican.github.io/2017/08/07/%E4%BD%BF%E7%94%A8java8%E5%90%8E%E9%82%A3%E4%BA%9B%E8%A2%AB%E6%9B%BE%E7%BB%8F%E8%A2%AB%E5%BF%BD%E7%95%A5%E7%9A%84%E7%89%B9%E6%80%A7/</url>
      <content type="html"><![CDATA[<p>虽然我们开始了Java8的旅程，但是很多人直接从java6上手了java8，也许有一些JDK7的特性你还不知道，在本章节中带你回顾一下我们忘记了的那些特性。<br>尽管我们不能将所有特性都讲一遍，挑出常用的核心特性拎出来一起学习。<br><a id="more"></a></p>
<h2 id="异常改进"><a href="#异常改进" class="headerlink" title="异常改进"></a>异常改进</h2><h3 id="try-with-resources"><a href="#try-with-resources" class="headerlink" title="try-with-resources"></a>try-with-resources</h3><p>这个特性是在JDK7种出现的，我们在之前操作一个流对象的时候大概是这样的：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">// 使用流对象</span></div><div class="line">    stream.read();</div><div class="line">    stream.write();</div><div class="line">&#125; <span class="keyword">catch</span>(Exception e)&#123;</div><div class="line">    <span class="comment">// 处理异常</span></div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">    <span class="comment">// 关闭流资源</span></div><div class="line">    <span class="keyword">if</span>(stream != <span class="keyword">null</span>)&#123;</div><div class="line">        stream.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这样无疑有些繁琐，而且finally块还有可能抛出异常。在JDK7种提出了try-with-resources机制，<br>它规定你操作的类只要是实现了AutoCloseable接口就可以在try语句块退出的时候自动调用close方法关闭流资源。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">tryWithResources</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">    <span class="keyword">try</span>( InputStream ins = <span class="keyword">new</span> FileInputStream(<span class="string">"/home/biezhi/a.txt"</span>) )&#123;</div><div class="line">        <span class="keyword">char</span> charStr = (<span class="keyword">char</span>) ins.read();</div><div class="line">        System.out.print(charStr);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>使用多个资源<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> ( InputStream is  = <span class="keyword">new</span> FileInputStream(<span class="string">"/home/biezhi/a.txt"</span>);</div><div class="line">      OutputStream os = <span class="keyword">new</span> FileOutputStream(<span class="string">"/home/biezhi/b.txt"</span>)</div><div class="line">) &#123;</div><div class="line">    <span class="keyword">char</span> charStr = (<span class="keyword">char</span>) is.read();</div><div class="line">    os.write(charStr);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当然如果你使用的是非标准库的类也可以自定义AutoCloseable，只要实现其close方法即可。</p>
<h3 id="捕获多个Exception"><a href="#捕获多个Exception" class="headerlink" title="捕获多个Exception"></a>捕获多个Exception</h3><p>当我们在操作一个对象的时候，有时候它会抛出多个异常，像这样：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    Thread.sleep(<span class="number">20000</span>);</div><div class="line">    FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="string">"/a/b.txt"</span>);</div><div class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这样代码写起来要捕获很多异常，不是很优雅，JDK7种允许你捕获多个异常:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    Thread.sleep(<span class="number">20000</span>);</div><div class="line">    FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="string">"/a/b.txt"</span>);</div><div class="line">&#125; <span class="keyword">catch</span> (InterruptedException | IOException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>并且<strong>catch</strong>语句后面的异常参数是<strong>final</strong>的，不可以再修改/复制。</p>
<h3 id="处理反射异常"><a href="#处理反射异常" class="headerlink" title="处理反射异常"></a>处理反射异常</h3><p>使用过反射的同学可能知道我们有时候操作反射方法的时候会抛出很多不相关的检查异常，例如：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    Class&lt;?&gt; clazz = Class.forName(<span class="string">"com.biezhi.apple.User"</span>);</div><div class="line">    clazz.getMethods()[<span class="number">0</span>].invoke(object);</div><div class="line">&#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>尽管你可以使用catch多个异常的方法将上述异常都捕获，但这也让人感到痛苦。<br>JDK7修复了这个缺陷，引入了一个新类ReflectiveOperationException可以帮你捕获这些反射异常:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    Class&lt;?&gt; clazz = Class.forName(<span class="string">"com.biezhi.apple.User"</span>);</div><div class="line">    clazz.getMethods()[<span class="number">0</span>].invoke(object);</div><div class="line">&#125; <span class="keyword">catch</span> (ReflectiveOperationException e)&#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><p>我们知道在JDK6甚至之前的时候，我们想要读取一个文本文件也是非常麻烦的一件事，而现在他们都变得简单了，<br>这要归功于NIO2，我们先看看之前的做法:</p>
<p><strong>读取一个文本文件</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">BufferedReader br = <span class="keyword">null</span>;</div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(<span class="string">"file.txt"</span>));</div><div class="line">    StringBuilder sb = <span class="keyword">new</span> StringBuilder();</div><div class="line">    String line      = br.readLine();</div><div class="line">    <span class="keyword">while</span> (line != <span class="keyword">null</span>) &#123;</div><div class="line">        sb.append(line);</div><div class="line">        sb.append(System.lineSeparator());</div><div class="line">        line = br.readLine();</div><div class="line">    &#125;</div><div class="line">    String everything = sb.toString();</div><div class="line">&#125; <span class="keyword">catch</span> (Exception e)&#123;</div><div class="line">    e.printStackTrace();</div><div class="line">&#125; <span class="keyword">finally</span> &#123;</div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        br.close();</div><div class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">        e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>大家对这样的一段代码一定不陌生，但这样太繁琐了，我只想读取一个文本文件，要写这么多代码还要<br>处理让人头大的一堆异常，怪不得别人吐槽Java臃肿，是在下输了。。。</p>
<p>下面我要介绍在JDK7中是如何改善这些问题的。</p>
<h3 id="Path"><a href="#Path" class="headerlink" title="Path"></a>Path</h3><p>Path用于来表示文件路径和文件，和File对象类似，Path对象并不一定要对应一个实际存在的文件，<br>它只是一个路径的抽象序列。</p>
<p>要创建一个Path对象有多种方法，首先是final类Paths的两个static方法，如何从一个路径字符串来构造Path对象：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Path path1   = Paths.get(<span class="string">"/home/biezhi"</span>, <span class="string">"a.txt"</span>);</div><div class="line">Path path2   = Paths.get(<span class="string">"/home/biezhi/a.txt"</span>);</div><div class="line">URI  u       = URI.create(<span class="string">"file:////home/biezhi/a.txt"</span>);</div><div class="line">Path pathURI = Paths.get(u);</div></pre></td></tr></table></figure></p>
<p>通过<strong>FileSystems</strong>构造<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Path filePath = FileSystems.getDefault().getPath(<span class="string">"/home/biezhi"</span>, <span class="string">"a.txt"</span>);</div></pre></td></tr></table></figure></p>
<p><strong>Path、URI、File</strong>之间的转换<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">File file  = new File(&quot;/home/biezhi/a.txt&quot;);</div><div class="line">Path p1    = file.toPath();</div><div class="line">p1.toFile();</div><div class="line">file.toURI();</div></pre></td></tr></table></figure></p>
<h3 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h3><p>你可以使用<strong>Files</strong>类快速实现文件操作，例如读取文件内容:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">byte</span>[] data    = Files.readAllBytes(Paths.get(<span class="string">"/home/biezhi/a.txt"</span>));</div><div class="line">String content = <span class="keyword">new</span> String(data, StandardCharsets.UTF_8);</div></pre></td></tr></table></figure></p>
<p>如果希望按照行读取文件，可以调用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">List&lt;String&gt; lines = Files.readAllLines(Paths.get(<span class="string">"/home/biezhi/a.txt"</span>));</div></pre></td></tr></table></figure></p>
<p>反之你想将字符串写入到文件可以调用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Files.write(Paths.get(<span class="string">"/home/biezhi/b.txt"</span>), <span class="string">"Hello JDK7!"</span>.getBytes());</div></pre></td></tr></table></figure></p>
<p>你也可以按照行写入文件，Files.write方法的参数中支持传递一个实现Iterable接口的类实例。<br>将内容追加到指定文件可以使用write方法的第三个参数OpenOption:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Files.write(Paths.get(&quot;/home/biezhi/b.txt&quot;), &quot;Hello JDK7!&quot;.getBytes(),</div><div class="line"> StandardOpenOption.APPEND);</div></pre></td></tr></table></figure></p>
<blockquote>
<p>默认情况Files类中的所有方法都会使用UTF-8编码进行操作，当你不愿意这么干的时候可以传递Charset参数进去变更。<br>当然Files还有一些其他的常用方法:</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">InputStream ins  = Files.newInputStream(path);</div><div class="line">OutputStream ops = Files.newOutputStream(path);</div><div class="line">Reader reader    = Files.newBufferedReader(path);</div><div class="line">Writer writer    = Files.newBufferedWriter(path);</div></pre></td></tr></table></figure>
<h3 id="创建、移动、删除"><a href="#创建、移动、删除" class="headerlink" title="创建、移动、删除"></a>创建、移动、删除</h3><p>创建文件、目录<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (!Files.exists(path)) &#123;</div><div class="line">    Files.createFile(path);</div><div class="line">    Files.createDirectory(path);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>Files还提供了一些方法让我们创建临时文件/临时目录:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Files.createTempFile(dir, prefix, suffix);</div><div class="line">Files.createTempFile(prefix, suffix);</div><div class="line">Files.createTempDirectory(dir, prefix);</div><div class="line">Files.createTempDirectory(prefix);</div></pre></td></tr></table></figure></p>
<p>这里的dir是一个Path对象，并且字符串prefix和suffix都可能为null。<br>例如调用<strong>Files.createTempFile(null, “.txt”)</strong>会返回一个类似<strong>/tmp/21238719283331124678.txt</strong>的文件</p>
<blockquote>
<p>读取一个目录下的文件请使用Files.list和Files.walk方法</p>
</blockquote>
<p>复制、移动一个文件内容到某个路径<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Files.copy(in, path);</div><div class="line">Files.move(path, path);</div></pre></td></tr></table></figure></p>
<p>删除一个文件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Files.delete(path);</div></pre></td></tr></table></figure></p>
<h2 id="小的改进"><a href="#小的改进" class="headerlink" title="小的改进"></a>小的改进</h2><p>Java8是一个较大改变的版本，包含了API和库方面的修正，它还对我们常用的API进行很多微小的调整，下面我会带你了解字符串、集合、注解等新方法。</p>
<h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>使用过JavaScript语言的人可能会知道当我们将一个数组中的元素组合起来变成字符串有一个方法join，<br>例如我们经常用到将数组中的字符串拼接成用逗号分隔的一长串，这在Java中是要写for循环来完成的。</p>
<p>Java8种添加了<strong>join</strong>方法帮你搞定这一切:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">String str = String.join(<span class="string">","</span>, <span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>);</div></pre></td></tr></table></figure></p>
<p>第一个参数是分隔符，后面接收一个CharSequence类型的可变参数数组或一个Iterable。</p>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><p>集合改变中最大的当属前面章节中提到的Stream API，除此之外还有一些小的改动。</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/jdk%E6%96%B0%E7%89%B9%E6%80%A71.png" alt=""><br></center>


<ul>
<li>Map中的很多方法对并发访问十分重要，我们将在后面的章节中介绍</li>
<li>Iterator提供forEachRemaining将剩余的元素传递给一个函数</li>
<li>BitSet可以产生一个Stream对象<br><strong>通用目标类型判断</strong></li>
</ul>
<p>Java8对泛型参数的推断进行了增强。相信你对Java8之前版本中的类型推断已经比较熟悉了。<br>比如，Collections中的方法emptyList方法定义如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> &lt;T&gt; <span class="function">List&lt;T&gt; <span class="title">emptyList</span><span class="params">()</span></span>;</div></pre></td></tr></table></figure></p>
<p><strong>emptyList</strong>方法使用了泛型类型<strong>T</strong>进行参数化。你可以像下面这样为该类型参数提供一个显式的类型进行函数调用：</p>
<p>List<person> persons = Collections.<person>emptyList();<br>不过编译器也可以推断泛型参数的类型，上面的代码和下面这段代码是等价的：</person></person></p>
<p>List<person> persons = Collections.emptyList();<br>我还是习惯于这样书写。</person></p>
<h3 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h3><p>Java 8在两个方面对注解机制进行了改进，分别为：</p>
<ul>
<li>可以定义重复注解</li>
<li>可以为任何类型添加注解</li>
</ul>
<h3 id="重复注解"><a href="#重复注解" class="headerlink" title="重复注解"></a>重复注解</h3><p>之前版本的Java禁止对同样的注解类型声明多次。由于这个原因，下面的第二句代码是无效的：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@interface</span> Basic &#123;</div><div class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="meta">@Basic</span>(name=<span class="string">"fix"</span>)</div><div class="line"><span class="meta">@Basic</span>(name=<span class="string">"todo"</span>)</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123; &#125;</div><div class="line">我们之前可能会通过数组的做法绕过这一限制:</div><div class="line"></div><div class="line"><span class="meta">@interface</span> Basic &#123;</div><div class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="meta">@interface</span> Basics &#123;</div><div class="line">    Basic[] value();</div><div class="line">&#125;</div><div class="line"><span class="meta">@Basics</span>( &#123; <span class="meta">@Basic</span>(name=<span class="string">"fix"</span>) , <span class="meta">@Basic</span>(name=<span class="string">"todo"</span>) &#125; )</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123; &#125;</div></pre></td></tr></table></figure></p>
<p>Book类的嵌套注解相当难看。这就是Java8想要从根本上移除这一限制的原因，去掉这一限制后，<br>代码的可读性会好很多。现在，如果你的配置允许重复注解，你可以毫无顾虑地一次声明多个同一种类型的注解。<br>它目前还不是默认行为，你需要显式地要求进行重复注解。</p>
<p><strong>创建一个重复注解</strong></p>
<p>如果一个注解在设计之初就是可重复的，你可以直接使用它。但是，如果你提供的注解是为用户提供的，<br>那么就需要做一些工作，说明该注解可以重复。下面是你需要执行的两个步骤：</p>
<ol>
<li>将注解标记为@Repeatable</li>
<li>提供一个注解的容器下面的例子展示了如何将@Basic注解修改为可重复注解<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Repeatable</span>(Basics.class)</div><div class="line"><span class="meta">@interface</span> Basic &#123;</div><div class="line">    <span class="function">String <span class="title">name</span><span class="params">()</span></span>;</div><div class="line">&#125;</div><div class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</div><div class="line"><span class="meta">@interface</span> Basics &#123;</div><div class="line">    Basic[] value();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>完成了这样的定义之后，Person类可以通过多个@Basic注解进行注释，如下所示：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Basic</span>(name=<span class="string">"fix"</span>)</div><div class="line"><span class="meta">@Basic</span>(name=<span class="string">"todo"</span>)</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123; &#125;</div></pre></td></tr></table></figure></p>
<p>编译时， Person 会被认为使用了<strong> @Basics( { @Basic(name=”fix”) , @Basic(name=”todo”)} )</strong><br>这样的形式进行了注解，所以，你可以把这种新的机制看成是一种语法糖，<br>它提供了程序员之前利用的惯用法类似的功能。为了确保与反射方法在行为上的一致性，<br>注解会被封装到一个容器中。 Java API中的getAnnotation(Class<t> annotationClass)方法会为注解元素返回类型为T的注解。<br>如果实际情况有多个类型为T的注解，该方法的返回到底是哪一个呢？</t></p>
<p>我们不希望一下子就陷入细节的魔咒，类Class提供了一个新的getAnnotationsByType方法，<br>它可以帮助我们更好地使用重复注解。比如，你可以像下面这样打印输出Person类的所有Basic注解：</p>
<p>返回一个由重复注解Basic组成的数组<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">    Basic[] basics = Person.class.getAnnotationsByType(Basic.class);</div><div class="line">    Arrays.asList(basics).forEach(a -&gt; &#123; </div><div class="line">        System.out.println(a.name()); </div><div class="line">    &#125;); </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="Null检查"><a href="#Null检查" class="headerlink" title="Null检查"></a>Null检查</h3><p>Objects类添加了两个静态方法isNull和nonNull，在使用流的时候非常有用。</p>
<p>例如获取一个流的所有不为null的对象:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Stream.of(<span class="string">"a"</span>, <span class="string">"c"</span>, <span class="keyword">null</span>, <span class="string">"d"</span>)</div><div class="line">        .filter(Objects::nonNull)</div><div class="line">        .forEach(System.out::println);</div></pre></td></tr></table></figure></p>
<h3 id="Optional"><a href="#Optional" class="headerlink" title="Optional"></a>Optional</h3><p>空指针异常一直是困扰Java程序员的问题，也是我们必须要考虑的。当业务代码中充满了if else判断null<br>的时候程序变得不再优雅，在Java8中提供了Optional类为我们解决NullPointerException。</p>
<p>我们先来看看这段代码有什么问题?<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</div><div class="line">    String name;</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> name;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getUserName</span><span class="params">(User user)</span></span>&#123;</div><div class="line">    <span class="keyword">return</span> user.getName();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这段代码看起来很正常，每个User都会有一个名字。所以调用getUserName方法会发生什么呢？<br>实际这是不健壮的程序代码，当User对象为null的时候会抛出一个空指针异常。</p>
<p>我们普遍的做法是通过判断 user != null 然后获取名称<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getUserName</span><span class="params">(User user)</span></span>&#123;</div><div class="line">    <span class="keyword">if</span>(user != <span class="keyword">null</span>)&#123;</div><div class="line">        <span class="keyword">return</span> user.getName();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>但是如果对象嵌套的层次比较深的时候这样的判断我们需要编写多少次呢？难以想象</p>
<h3 id="处理空指针"><a href="#处理空指针" class="headerlink" title="处理空指针"></a>处理空指针</h3><p>使用Optional优化代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getUserNameByOptional</span><span class="params">(User user)</span> </span>&#123;</div><div class="line">    Optional&lt;String&gt; userName = Optional.ofNullable(user).map(User::getName);</div><div class="line">    <span class="keyword">return</span> userName.orElse(<span class="keyword">null</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当user为null的时候我们设置UserName的值为null，否则返回getName的返回值，但此时不会抛出空指针。</p>
<p>在之前的代码片段中是我们最熟悉的命令式编程思维，写下的代码可以描述程序的执行逻辑，得到什么样的结果。<br>后面的这种方式是函数式思维方式，在函数式的思维方式里，结果比过程更重要，不需要关注执行的细节。程序的具体执行由编译器来决定。<br>这种情况下提高程序的性能是一个不容易的事情。</p>
<p>我们再次了解下Optional中的一些使用方法</p>
<h3 id="Optional方法"><a href="#Optional方法" class="headerlink" title="Optional方法"></a>Optional方法</h3><p><strong>创建 Optional 对象</strong></p>
<p>你可以通过静态工厂方法Optional.empty，创建一个空的Optional对象：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Optional&lt;User&gt; emptyUser = Optional.empty();</div></pre></td></tr></table></figure></p>
<p>创建一个非空值的Optional<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Optional&lt;User&gt; userOptional = Optional.of(user);</div></pre></td></tr></table></figure></p>
<p>如果user是一个null，这段代码会立即抛出一个NullPointerException，而不是等到你试图访问user的属性值时才返回一个错误。</p>
<p>可接受null的Optional<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Optional&lt;User&gt; ofNullOptional = Optional.ofNullable(user);</div></pre></td></tr></table></figure></p>
<p>使用静态工厂方法<strong>Optional.ofNullable</strong>，你可以创建一个允许null值的Optional对象。</p>
<p>如果user是null，那么得到的Optional对象就是个空对象，但不会让你导致空指针。</p>
<p>使用map从Optional对象中提取和转换值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Optional&lt;User&gt; ofNullOptional = Optional.ofNullable(user);</div><div class="line">Optional&lt;String&gt; userName = ofNullOptional.map(User::getName);</div></pre></td></tr></table></figure></p>
<p>这种操作就像我们之前在操作Stream是一样的，获取的只是User中的一个属性。</p>
<p><strong>默认行为及解引用Optional对象</strong></p>
<p>我们决定采用orElse方法读取这个变量的值，使用这种方式你还可以定义一个默认值，<br>遭遇空的Optional变量时，默认值会作为该方法的调用返回值。<br>Optional类提供了多种方法读取 Optional实例中的变量值。</p>
<ul>
<li>get()是这些方法中最简单但又最不安全的方法。如果变量存在，它直接返回封装的变量 值，否则就抛出一个NoSuchElementException异常。所以，除非你非常确定Optional 变量一定包含值，否则使用这个方法是个相当糟糕的主意。此外，这种方式即便相对于 嵌套式的null检查，也并未体现出多大的改进。</li>
<li>orElse(T other)是我们在代码清单10-5中使用的方法，正如之前提到的，它允许你在 Optional对象不包含值时提供一个默认值。</li>
<li>orElseGet(Supplier&lt;? extends T&gt; other)是orElse方法的延迟调用版，Supplier方法只有在Optional对象不含值时才执行调用。如果创建默认值是件耗时费力的工作， 你应该考虑采用这种方式（借此提升程序的性能），或者你需要非常确定某个方法仅在 Optional为空时才进行调用，也可以考虑该方式（这种情况有严格的限制条件）。</li>
<li>orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)和get方法非常类似， 它们遭遇Optional对象为空时都会抛出一个异常，但是使用orElseThrow你可以定制希 望抛出的异常类型。</li>
<li>ifPresent(Consumer&lt;? super T&gt;)让你能在变量值存在时执行一个作为参数传入的 方法，否则就不进行任何操作。<br>当前除了这些Optional类也具备一些和Stream类似的API，我们先看看Optional类方法:<center><br><img src="http://ojwkevhas.bkt.clouddn.com/jdk%E6%96%B0%E7%89%B9%E6%80%A72.png" alt=""><br></center>

</li>
</ul>
<p><strong>用Optional封装可能为null的值</strong></p>
<p>目前我们写的大部分Java代码都会使用返回NULL的方式来表示不存在值，比如Map中通过Key获取值，<br>当不存在该值会返回一个null。<br>但是，正如我们之前介绍的，大多数情况下，你可能希望这些方法能返回一个Optional对象。<br>你无法修改这些方法的签名，但是你很容易用Optional对这些方法的返回值进行封装。</p>
<p>我们接着用Map做例子，假设你有一个Map<string, object="">类型的map，访问由key的值时，<br>如果map中没有与key关联的值，该次调用就会返回一个null。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Object value = map.get(<span class="string">"key"</span>);</div></pre></td></tr></table></figure></string,></p>
<p>使用Optional封装map的返回值，你可以对这段代码进行优化。要达到这个目的有两种方式：<br>你可以使用笨拙的if-then-else判断语句，毫无疑问这种方式会增加代码的复杂度；<br>或者你可以采用Optional.ofNullable方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Optional&lt;Object&gt; value = Optional.ofNullable(map.get(<span class="string">"key"</span>));</div></pre></td></tr></table></figure></p>
<p>每次你希望安全地对潜在为null的对象进行转换，将其替换为Optional对象时，都可以考虑使用这种方法。</p>
<p>参考资料：Java文件IO操作应该抛弃File拥抱Paths和Files</p>
<font color="grey" size="1">注：此博客为博主学习时所收集资料仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> jdk特性 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[java8日期和时间使用技巧]]></title>
      <url>http://Melodylican.github.io/2017/08/05/java8%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
      <content type="html"><![CDATA[<p>当你开始使用Java操作日期和时间的时候，会有一些棘手。你也许会通过System.currentTimeMillis()<br>来返回1970年1月1日到今天的毫秒数。或者使用Date类来操作日期；当遇到加减月份、天数的时候<br>你又需要用到Calendar类；当需要格式化日期的时候需要使用java.text.DateFormat类。<br>总而言之在Java中操作日期不是很方便，以至于很多开发者不得不使用第三方库，比如: <a href="http://link.zhihu.com/?target=http%3A//joda-time.sourceforge.net/" target="_blank" rel="external">joda-time</a><br><a id="more"></a></p>
<h2 id="现有API存在的问题"><a href="#现有API存在的问题" class="headerlink" title="现有API存在的问题"></a>现有API存在的问题</h2><ul>
<li>线程安全: Date和Calendar不是线程安全的，你需要编写额外的代码处理线程安全问题</li>
<li>API设计和易用性: 由于Date和Calendar的设计不当你无法完成日常的日期操作</li>
<li>ZonedDate和Time: 你必须编写额外的逻辑处理时区和那些旧的逻辑</li>
</ul>
<p>好在<a href="http://link.zhihu.com/?target=http%3A//jcp.org/en/jsr/detail%3Fid%3D310" target="_blank" rel="external">JSR 310</a>规范中为Java8添加了新的API，在java.time包中，新的API纠正了过去的缺陷，</p>
<h2 id="新的日期API"><a href="#新的日期API" class="headerlink" title="新的日期API"></a>新的日期API</h2><ul>
<li>ZoneId: 时区ID，用来确定Instant和LocalDateTime互相转换的规则</li>
<li>Instant: 用来表示时间线上的一个点</li>
<li>LocalDate: 表示没有时区的日期, LocalDate是不可变并且线程安全的</li>
<li>LocalTime: 表示没有时区的时间, LocalTime是不可变并且线程安全的</li>
<li>LocalDateTime: 表示没有时区的日期时间, LocalDateTime是不可变并且线程安全的</li>
<li>Clock: 用于访问当前时刻、日期、时间，用到时区</li>
<li>Duration: 用秒和纳秒表示时间的数量</li>
</ul>
<p>最常用的就是LocalDate、LocalTime、LocalDateTime了，从它们的名字就可以看出是操作日期<br>和时间的。这些类是主要用于当时区不需要显式地指定的上下文。在本章节中我们将讨论最常用的api。</p>
<h3 id="LocalDate"><a href="#LocalDate" class="headerlink" title="LocalDate"></a>LocalDate</h3><p>LocalDate代表一个IOS格式(yyyy-MM-dd)的日期，可以存储 生日、纪念日等日期。<br>获取当前的日期：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalDate localDate = LocalDate.now();</div><div class="line">System.out.println(<span class="string">"localDate: "</span> + localDate);</div></pre></td></tr></table></figure></p>
<p>输出<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">localDate: <span class="number">2017</span>-<span class="number">07</span>-<span class="number">20</span></div></pre></td></tr></table></figure></p>
<p>LocalDate可以指定特定的日期，调用of或parse方法返回该实例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalDate.of(2017, 07, 20);</div><div class="line">LocalDate.parse(&quot;2017-07-20&quot;);</div></pre></td></tr></table></figure></p>
<p>当然它还有一些其他方法，我们一起来看看：</p>
<p><strong>为今天添加一天，也就是获取明天</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LocalDate tomorrow = LocalDate.now().plusDays(<span class="number">1</span>);</div></pre></td></tr></table></figure></p>
<p><strong>从今天减去一个月</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LocalDate prevMonth = LocalDate.now().minus(<span class="number">1</span>, ChronoUnit.MONTHS);</div></pre></td></tr></table></figure></p>
<p>下面写两个例子，分别解析日期 2017-07-20，获取每周中的星期和每月中的日：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">DayOfWeek thursday = LocalDate.parse(<span class="string">"2017-07-20"</span>).getDayOfWeek();</div><div class="line">System.out.println(<span class="string">"周四: "</span> + thursday);</div><div class="line"><span class="keyword">int</span> twenty = LocalDate.parse(<span class="string">"2017-07-20"</span>).getDayOfMonth();</div><div class="line">System.out.println(<span class="string">"twenty: "</span> + twenty);</div></pre></td></tr></table></figure></p>
<p>试试今年是不是闰年:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> leapYear = LocalDate.now().isLeapYear();</div><div class="line">System.out.println(<span class="string">"是否闰年: "</span> + leapYear);</div></pre></td></tr></table></figure></p>
<p>判断是否在日期之前或之后:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> notBefore = LocalDate.parse(<span class="string">"2017-07-20"</span>)</div><div class="line">                .isBefore(LocalDate.parse(<span class="string">"2017-07-22"</span>));</div><div class="line">System.out.println(<span class="string">"notBefore: "</span> + notBefore);</div><div class="line"><span class="keyword">boolean</span> isAfter = LocalDate.parse(<span class="string">"2017-07-20"</span>).isAfter(LocalDate.parse(<span class="string">"2017-07-22"</span>));</div><div class="line">System.out.println(<span class="string">"isAfter: "</span> + isAfter);</div></pre></td></tr></table></figure></p>
<p>获取这个月的第一天:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">LocalDate firstDayOfMonth = LocalDate.parse(<span class="string">"2017-07-20"</span>)</div><div class="line">                .with(TemporalAdjusters.firstDayOfMonth());</div><div class="line">System.out.println(<span class="string">"这个月的第一天: "</span> + firstDayOfMonth);</div><div class="line">firstDayOfMonth = firstDayOfMonth.withDayOfMonth(<span class="number">1</span>);</div><div class="line">System.out.println(<span class="string">"这个月的第一天: "</span> + firstDayOfMonth);</div></pre></td></tr></table></figure></p>
<p>判断今天是否是我的生日，例如我的生日是 2017-07-20<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">LocalDate birthday = LocalDate.of(<span class="number">2009</span>, <span class="number">07</span>, <span class="number">20</span>);</div><div class="line">MonthDay birthdayMd = MonthDay.of(birthday.getMonth(), birthday.getDayOfMonth());</div><div class="line">MonthDay today = MonthDay.from(LocalDate.now());</div><div class="line">System.out.println(<span class="string">"今天是否是我的生日: "</span> + today.equals(birthdayMd));</div></pre></td></tr></table></figure></p>
<h3 id="LocalTime"><a href="#LocalTime" class="headerlink" title="LocalTime"></a>LocalTime</h3><p>LocalTime表示一个时间，而不是日期，下面介绍一下它的使用方法。</p>
<p>获取现在的时间，输出<strong>15:01:22.144</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalTime now = LocalTime.now();</div><div class="line">System.out.println(<span class="string">"现在的时间: "</span> + now);</div></pre></td></tr></table></figure></p>
<p>将一个字符串时间解析为LocalTime，输出15:02<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalTime nowTime = LocalTime.parse(<span class="string">"15:02"</span>);</div><div class="line">System.out.println(<span class="string">"时间是: "</span> + nowTime);</div></pre></td></tr></table></figure></p>
<p>使用静态方法of创建一个时间<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalTime nowTime = LocalTime.of(<span class="number">15</span>, <span class="number">02</span>);</div><div class="line">System.out.println(<span class="string">"时间是: "</span> + nowTime);</div></pre></td></tr></table></figure></p>
<p>使用解析字符串的方式并添加一小时，输出16:02<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalTime nextHour = LocalTime.parse(<span class="string">"15:02"</span>).plus(<span class="number">1</span>, ChronoUnit.HOURS);</div><div class="line">System.out.println(<span class="string">"下一个小时: "</span> + nextHour);</div></pre></td></tr></table></figure></p>
<p>获取时间的小时、分钟<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> hour = LocalTime.parse(<span class="string">"15:02"</span>).getHour();</div><div class="line">System.out.println(<span class="string">"小时: "</span> + hour);</div><div class="line"><span class="keyword">int</span> minute = LocalTime.parse(<span class="string">"15:02"</span>).getMinute();</div><div class="line">System.out.println(<span class="string">"分钟: "</span> + minute);</div></pre></td></tr></table></figure></p>
<p>我们也可以通过之前类似的API检查一个时间是否在另一个时间之前、之后<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">boolean</span> isBefore = LocalTime.parse(<span class="string">"15:02"</span>).isBefore(LocalTime.parse(<span class="string">"16:02"</span>));</div><div class="line"><span class="keyword">boolean</span> isAfter = LocalTime.parse(<span class="string">"15:02"</span>).isAfter(LocalTime.parse(<span class="string">"16:02"</span>));</div><div class="line">System.out.println(<span class="string">"isBefore: "</span> + isBefore);</div><div class="line">System.out.println(<span class="string">"isAfter: "</span> + isAfter);</div></pre></td></tr></table></figure></p>
<p>输出 <strong>isBefore: true, isAfter: false</strong>。</p>
<p>在LocalTime类中也将每天的开始和结束作为常量供我们使用:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">System.out.println(LocalTime.MAX);</div><div class="line">System.out.println(LocalTime.MIN);</div></pre></td></tr></table></figure></p>
<p>输出:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">23:59:59.999999999</div><div class="line">00:00</div></pre></td></tr></table></figure></p>
<p>LocalTime就这些了，下面我们来了解一下LocalDateTime</p>
<h3 id="LocalDateTime"><a href="#LocalDateTime" class="headerlink" title="LocalDateTime"></a>LocalDateTime</h3><p>LocalDateTime是用来表示日期和时间的，这是一个最常用的类之一。</p>
<p>获取当前的日期和时间:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalDateTime now = LocalDateTime.now();</div><div class="line">System.out.println(<span class="string">"现在: "</span> + now);</div></pre></td></tr></table></figure></p>
<p>输出<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">现在: <span class="number">2017</span>-<span class="number">07</span>-<span class="number">20</span>T15:<span class="number">17</span>:<span class="number">19.926</span></div></pre></td></tr></table></figure></p>
<p>下面使用静态方法和字符串的方式分别创建 LocalDateTime 对象<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalDateTime.of(<span class="number">2017</span>, Month.JULY, <span class="number">20</span>, <span class="number">15</span>, <span class="number">18</span>);</div><div class="line">LocalDateTime.parse(<span class="string">"2017-07-20T15:18:00"</span>);</div></pre></td></tr></table></figure></p>
<p>同时<code>LocalDateTime</code>也提供了相关API来对日期和时间进行增减操作:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">LocalDateTime tomorrow = now.plusDays(<span class="number">1</span>);</div><div class="line">System.out.println(<span class="string">"明天的这个时间: "</span> + tomorrow);</div><div class="line">LocalDateTime minusTowHour = now.minusHours(<span class="number">2</span>);</div><div class="line">System.out.println(<span class="string">"两小时前: "</span> + minusTowHour);</div></pre></td></tr></table></figure></p>
<p>这个类也提供一系列的get方法来获取特定单位:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Month month = now.getMonth();</div><div class="line">System.out.println(<span class="string">"当前月份: "</span> + month);</div></pre></td></tr></table></figure></p>
<h2 id="日期格式化"><a href="#日期格式化" class="headerlink" title="日期格式化"></a>日期格式化</h2><p>在日常开发中我们用到最多的也许就是日期、时间的格式化了，那在Java8种该如何操作呢？<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">LocalDateTime now = LocalDateTime.now();</div><div class="line">DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</div><div class="line">System.out.println(<span class="string">"默认格式化: "</span> + now);</div><div class="line">System.out.println(<span class="string">"自定义格式化: "</span> + now.format(dateTimeFormatter));</div><div class="line">LocalDateTime localDateTime = LocalDateTime.parse(<span class="string">"2017-07-20 15:27:44"</span>, dateTimeFormatter);</div><div class="line">System.out.println(<span class="string">"字符串转LocalDateTime: "</span> + localDateTime);</div></pre></td></tr></table></figure></p>
<p>也可以使用<strong>DateTimeFormatter</strong>的<strong>format</strong>方法将日期、时间格式化为字符串<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(<span class="string">"yyyy-MM-dd"</span>);</div><div class="line">String dateString = dateTimeFormatter.format(LocalDate.now());</div><div class="line">System.out.println(<span class="string">"日期转字符串: "</span> + dateString);</div></pre></td></tr></table></figure></p>
<h2 id="日期周期"><a href="#日期周期" class="headerlink" title="日期周期"></a>日期周期</h2><p><strong>Period</strong>类用于修改给定日期或获得的两个日期之间的区别。</p>
<p>给初始化的日期添加5天:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">LocalDate initialDate = LocalDate.parse(<span class="string">"2017-07-20"</span>);</div><div class="line">LocalDate finalDate   = initialDate.plus(Period.ofDays(<span class="number">5</span>));</div><div class="line">System.out.println(<span class="string">"初始化日期: "</span> + initialDate);</div><div class="line">System.out.println(<span class="string">"加日期之后: "</span> + finalDate);</div></pre></td></tr></table></figure></p>
<p>周期API中提供给我们可以比较两个日期的差别，像下面这样获取差距天数:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">long</span> between = ChronoUnit.DAYS.between(initialDate, finalDate);</div><div class="line">System.out.println(<span class="string">"差距天数: "</span> + between);</div></pre></td></tr></table></figure></p>
<p>上面的代码会返回5，当然你想获取两个日期相差多少小时也是简单的。</p>
<h2 id="与遗留代码转换"><a href="#与遗留代码转换" class="headerlink" title="与遗留代码转换"></a>与遗留代码转换</h2><p>在之前的代码中你可能出现了大量的Date类，如何将它转换为Java8种的时间类呢？</p>
<p><strong>Date</strong>和<strong>Instant</strong>互相转换<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Date date = Date.from(Instant.now());</div><div class="line">Instant instant = date.toInstant();</div></pre></td></tr></table></figure></p>
<p><strong>Date</strong>转换为<strong>LocalDateTime</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LocalDateTime localDateTime = LocalDateTime.from(<span class="keyword">new</span> Date());</div><div class="line">System.out.println(localDateTime);</div></pre></td></tr></table></figure></p>
<p><strong>LocalDateTime</strong>转<strong>Date</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Date date =</div><div class="line">    Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant());</div></pre></td></tr></table></figure></p>
<p>LocalDate转Date<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Date date =</div><div class="line">    Date.from(LocalDate.now().atStartOfDay().atZone(ZoneId.systemDefault()).toInstant());</div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客为博主学习时所收集资料仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> java8日期和时间时间技巧 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[高并发系统数据幂等性]]></title>
      <url>http://Melodylican.github.io/2017/07/25/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%B9%82%E7%AD%89%E6%80%A7/</url>
      <content type="html"><![CDATA[<p>在系统开发过程中，经常遇到数据重复插入、重复更新、消息重发发送等等问题，因为应用系统的复杂逻辑以及网络交互存在的不确定性，会导致这一重复现象，但是有些逻辑是需要有幂等特性的，否则造成的后果会比较严重，例如订单重复创建，这时候带来的问题可是非同一般啊。<br><a id="more"></a></p>
<h2 id="系统的幂等性"><a href="#系统的幂等性" class="headerlink" title="系统的幂等性"></a>系统的幂等性</h2><p> 幂等是数据中得一个概念，表示N次变换和1次变换的结果相同。</p>
<h2 id="高并发的系统如何保证幂等性"><a href="#高并发的系统如何保证幂等性" class="headerlink" title="高并发的系统如何保证幂等性"></a>高并发的系统如何保证幂等性</h2><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p> 查询的API，可以说是天然的幂等性，因为你查询一次和查询两次，对于系统来讲，没有任何数据的变更，所以，查询一次和查询多次一样的；</p>
<h3 id="MVCC方案"><a href="#MVCC方案" class="headerlink" title="MVCC方案"></a>MVCC方案</h3><p> 多版本并发控制，update with condition更新带条件，这也是在系统设计的时候，合理的选择乐观锁，通过version或者其他条件，来做乐观锁，这样保证更新及时在并发的情况下，也不会有太大的问题。<br> 例如update table_xxx set name=#name#,version=version+1 where version=#version# ,或者是 update table_xxx set quality=quality-#subQuality# where quality-#subQuality# &gt;= 0</p>
<h3 id="单独的去重表"><a href="#单独的去重表" class="headerlink" title="单独的去重表"></a>单独的去重表</h3><p> 如果涉及到的去重的地方特别多，例如ERP系统中有各种各样的业务单据，每一种业务单据都需要去重，这时候，可以单独搞一张去重表，在插入数据的时候，插入去重表，利用数据库的唯一索引特性，保证唯一的逻辑；</p>
<h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p> 还是拿插入数据的例子，如果是分布式系统，构建唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多个系统，也就是分布式系统中得解决思路；</p>
<h3 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h3><p> 删除数据，仅仅第一次删除是真正的操作数据，第二次甚至第三次删除，直接返回成功，这样保证了幂等；</p>
<h3 id="插入数据的唯一索引"><a href="#插入数据的唯一索引" class="headerlink" title="插入数据的唯一索引"></a>插入数据的唯一索引</h3><p> 插入数据的唯一性，可以通过业务主键来进行约束，例如一个特定的业务场景，三个字段肯定确定唯一性，那么，可以在数据库表添加唯一索引来进行标示。<br> 这里有一个场景，API层面的幂等，例如提交数据，如何控制重复提交，这里可以在提交数据的form表单或者客户端软件，增加一个唯一标示，然后服务端，根据这个UUID来进行去重，这样就能比较好的做到API层面的唯一标示</p>
<h3 id="状态机幂等"><a href="#状态机幂等" class="headerlink" title="状态机幂等"></a>状态机幂等</h3><p> 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 幂等性 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[如何使用MongoDB+SpringBoot实现分布式ID?]]></title>
      <url>http://Melodylican.github.io/2017/07/13/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8SpringBoot%E5%92%8CMongoDB%E7%94%9F%E6%88%90%E5%88%86%E5%B8%83%E5%BC%8FID/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>如何实现分布式id，搜索相关的资料，一般会给出这几种方案：</p>
<ul>
<li>使用数据库自增Id</li>
<li>使用reids的incr命令</li>
<li>使用UUID</li>
<li>Twitter的snowflake算法</li>
<li>利用zookeeper生成唯一ID</li>
<li>MongoDB的ObjectId<br>另外，在我通过爬取知乎用户id发现，知乎的用户id是32位的，初步断定知乎采用的是md5加密，然后全部转换成小写。至于如何爬取知乎用户信息，见我之前分享的文章。本文采取的技术方案采取的是mogoodb的objectId。<a id="more"></a>
</li>
</ul>
<h2 id="Mongodb如何实现分布式ID"><a href="#Mongodb如何实现分布式ID" class="headerlink" title="Mongodb如何实现分布式ID"></a>Mongodb如何实现分布式ID</h2><p>MongoDB的ObjectId设计成轻量型的，不同的机器都能用全局唯一的同种方法方便地生成它。mongodb 从一开始就设计用来作为分布式数据库，处理多个节点是一个核心要求。使其在分片环境中要容易生成得多。</p>
<p>它的格式： </p>
<center><br><img src="http://upload-images.jianshu.io/upload_images/2279594-fa59770ee4c176cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600" alt=""><br></center>

<p>前4 个字节是从标准纪元开始的时间戳，单位为秒。时间戳，与随后的5 个字节组合起来，提供了秒级别的唯一性。由于时间戳在前，这意味着ObjectId 大致会按照插入的顺序排列。这对于某些方面很有用，如将其作为索引提高效率。这4 个字节也隐含了文档创建的时间。绝大多数客户端类库都会公开一个方法从ObjectId 获取这个信息。</p>
<p>接下来的3 字节是所在主机的唯一标识符。通常是机器主机名的散列值。这样就可以确保不同主机生成不同的ObjectId，不产生冲突。<br>为了确保在同一台机器上并发的多个进程产生的ObjectId 是唯一的，接下来的两字节来自产生ObjectId 的进程标识符（PID）。</p>
<p>前9 字节保证了同一秒钟不同机器不同进程产生的ObjectId 是唯一的。<br>后3 字节就是一个自动增加的计数器，确保相同进程同一秒产生的ObjectId 也是不一样的。同一秒钟最多允许每个进程拥有2563（16 777 216）个不同的ObjectId。</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>在springboot中引入mongodb:<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">     &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">     &lt;scope&gt;test&lt;/scope&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"></div><div class="line"> &lt;!-- 开启web--&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">     &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"></div><div class="line"></div><div class="line">&lt;!--mongodb --&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">     &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<p>创建一个实体类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Customer</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@Id</span></div><div class="line">    <span class="keyword">public</span> String id;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> String firstName;</div><div class="line">    <span class="keyword">public</span> String lastName;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">()</span> </span>&#123;&#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Customer</span><span class="params">(String firstName, String lastName)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.firstName = firstName;</div><div class="line">        <span class="keyword">this</span>.lastName = lastName;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> String.format(</div><div class="line">                <span class="string">"Customer[id=%s, firstName='%s', lastName='%s']"</span>,</div><div class="line">                id, firstName, lastName);</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getId</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> id;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(String id)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.id = id;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getFirstName</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> firstName;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFirstName</span><span class="params">(String firstName)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.firstName = firstName;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getLastName</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> lastName;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setLastName</span><span class="params">(String lastName)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.lastName = lastName;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>创建mongodb 接口类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">CustomerRepository</span> <span class="keyword">extends</span> <span class="title">MongoRepository</span>&lt;<span class="title">Customer</span>, <span class="title">String</span>&gt; </span>&#123;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> Customer <span class="title">findByFirstName</span><span class="params">(String firstName)</span></span>;</div><div class="line">    <span class="function"><span class="keyword">public</span> List&lt;Customer&gt; <span class="title">findByLastName</span><span class="params">(String lastName)</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>测试类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Autowired</span></div><div class="line">CustomerRepository customerRepository;</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">@Test</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mongodbIdTest</span><span class="params">()</span></span>&#123;</div><div class="line">Customer customer=<span class="keyword">new</span> Customer(<span class="string">"lxdxil"</span>,<span class="string">"dd"</span>);</div><div class="line">        customer=customerRepository.save(customer);</div><div class="line">        logger.info( <span class="string">"mongodbId:"</span>+customer.getId());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客参考自 方志朋博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> MongoDB </tag>
            
            <tag> 分布式ID </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[统计网卡流量]]></title>
      <url>http://Melodylican.github.io/2017/06/06/%E7%BD%91%E5%8D%A1%E6%B5%81%E9%87%8F%E7%BB%9F%E8%AE%A1/</url>
      <content type="html"><![CDATA[<blockquote>
<p>显示网卡流量的方法蛮多，一般我们可以通过dstat来查看，但dstat不一定所有的机器都有安装。而我们知道，通过ifconfig可以看到某一网卡发送与接收的字节数，所以我们可以写一个脚本来统计一下。<br><a id="more"></a></p>
</blockquote>
<p>先看ifconfig:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ ifconfig eth0  </div><div class="line">eth0      Link encap:Ethernet  HWaddr A4:BA:DB:<span class="number">43</span>:BA:B1  </div><div class="line">          inet addr:<span class="number">10.232</span>.4.34  Bcast:<span class="number">10.232</span>.4.255  Mask:<span class="number">255.255</span>.255.0  </div><div class="line">          inet6 addr: fe80::a6ba:dbff:fe43:bab1/<span class="number">64</span> Scope:Link  </div><div class="line">          UP BROADCAST RUNNING MULTICAST  MTU:<span class="number">1500</span>  Metric:<span class="number">1</span>  </div><div class="line">          RX packets:<span class="number">301707081</span> errors:<span class="number">0</span> dropped:<span class="number">1346358</span> overruns:<span class="number">0</span> frame:<span class="number">0</span>  </div><div class="line">          TX packets:<span class="number">296718885</span> errors:<span class="number">0</span> dropped:<span class="number">0</span> overruns:<span class="number">0</span> carrier:<span class="number">0</span>  </div><div class="line">          collisions:<span class="number">0</span> txqueuelen:<span class="number">1000</span>  </div><div class="line">          RX bytes:<span class="number">28485042645</span> (<span class="number">26.5</span> GiB)  TX bytes:<span class="number">35887266717</span> (<span class="number">33.4</span> GiB)  </div><div class="line">          Interrupt:<span class="number">98</span> Memory:d6000000-d6012800</div></pre></td></tr></table></figure></p>
<blockquote>
<p>我们可以看到rx与tx两个数据，于是我们的脚本出来了：</p>
</blockquote>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line">alias ifconfig="/sbin/ifconfig"</div><div class="line">eth=eth0</div><div class="line">while true; do</div><div class="line">RXpre=$(ifconfig $&#123;eth&#125; | grep bytes | awk '&#123;print $2&#125;'| awk -F":" '&#123;print $2&#125;')</div><div class="line">TXpre=$(ifconfig $&#123;eth&#125; | grep bytes | awk '&#123;print $6&#125;' | awk -F":" '&#123;print $2&#125;')</div><div class="line">sleep 1</div><div class="line">RXnext=$(ifconfig $&#123;eth&#125; | grep bytes | awk '&#123;print $2&#125;'| awk -F":" '&#123;print $2&#125;')</div><div class="line">TXnext=$(ifconfig $&#123;eth&#125; | grep bytes | awk '&#123;print $6&#125;' | awk -F":" '&#123;print $2&#125;')</div><div class="line">echo RX ----- TX</div><div class="line">echo "$(((($&#123;RXnext&#125;-$&#123;RXpre&#125;)/1024)/1024))MB/s $(((($&#123;TXnext&#125;-$&#123;TXpre&#125;)/1024/1024)))MB/s"</div><div class="line">done</div></pre></td></tr></table></figure>
<p>脚本暂时比较简单，可以添加一些参数判断，比如多长时间显示一次等等，先看看执行结果:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ ./a  </div><div class="line">RX ----- TX  </div><div class="line"><span class="number">5</span>MB/s <span class="number">7</span>MB/s  </div><div class="line">RX ----- TX  </div><div class="line"><span class="number">5</span>MB/s <span class="number">7</span>MB/s  </div><div class="line">RX ----- TX  </div><div class="line"><span class="number">4</span>MB/s <span class="number">6</span>MB/s  </div><div class="line">RX ----- TX  </div><div class="line"><span class="number">4</span>MB/s <span class="number">6</span>MB/s  </div><div class="line">RX ----- TX</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 小技巧 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java线上应用故障排查之一：高CPU占用]]></title>
      <url>http://Melodylican.github.io/2017/05/26/%E9%AB%98CPU%E5%8D%A0%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>问题分析：<br>1，程序属于CPU密集型，和开发沟通过，排除此类情况。<br>2，程序代码有问题，出现死循环，可能性极大。</p>
<p>问题解决：<br>1，开发那边无法排查代码某个模块有问题，从日志上也无法分析得出。<br>2，记得原来通过strace跟踪的方法解决了一台PHP服务器CPU占用高的问题，但是通过这种方法无效，经过google搜索，发现可以通过下面的方法进行解决，那就尝试下吧。<br><a id="more"></a><br>解决过程：<br>1，根据top命令，发现PID为2633的Java进程占用CPU高达300%，出现故障。</p>
<p>2，找到该进程后，如何定位具体线程或代码呢，首先显示线程列表,并按照CPU占用高的线程排序：<br>[root@localhost logs]# ps -mp 2633 -o THREAD,tid,time | sort -rn</p>
<p>显示结果如下：<br>USER     %CPU PRI SCNT WCHAN  USER SYSTEM   TID     TIME<br>root     10.5  19    - -         -      -  3626 00:12:48<br>root     10.1  19    - -         -      -  3593 00:12:16</p>
<p>找到了耗时最高的线程3626，占用CPU时间有12分钟了！</p>
<p>将需要的线程ID转换为16进制格式：<br>[root@localhost logs]# printf “%x\n” 3626<br>e18</p>
<p>最后打印线程的堆栈信息：<br>[root@localhost logs]# jstack 2633 |grep e18 -A 30</p>
<p>将输出的信息发给开发部进行确认，这样就能找出有问题的代码。<br>通过最近几天的监控，CPU已经安静下来了</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 高CPU占用 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LinkedBlockingQueue介绍]]></title>
      <url>http://Melodylican.github.io/2017/05/24/LinkedBlockingQueue/</url>
      <content type="html"><![CDATA[<h2 id="LinkedBlockingQueue介绍"><a href="#LinkedBlockingQueue介绍" class="headerlink" title="LinkedBlockingQueue介绍"></a>LinkedBlockingQueue介绍</h2><p>LinkedBlockingQueue是一个单向链表实现的阻塞队列。该队列按 FIFO（先进先出）排序元素，新元素插入到队列的尾部，并且队列获取操作会获得位于队列头部的元素。链接队列的吞吐量通常要高于基于数组的队列，但是在大多数并发应用程序中，其可预知的性能要低。<br><a id="more"></a><br>此外，LinkedBlockingQueue还是可选容量的(防止过度膨胀)，即可以指定队列的容量。如果不指定，默认容量大小等于Integer.MAX_VALUE。</p>
<h3 id="LinkedBlockingQueue原理和数据结构"><a href="#LinkedBlockingQueue原理和数据结构" class="headerlink" title="LinkedBlockingQueue原理和数据结构"></a>LinkedBlockingQueue原理和数据结构</h3><p><img src="http://img.blog.csdn.net/20150405013516409" alt=""><br><strong>说明：</strong></p>
<ol>
<li>LinkedBlockingQueue继承于AbstractQueue，它本质上是一个FIFO(先进先出)的队列。</li>
<li>LinkedBlockingQueue实现了BlockingQueue接口，它支持多线程并发。当多线程竞争同一个资源时，某线程获取到该资源之后，其它线程需要阻塞等待。</li>
<li>LinkedBlockingQueue是通过单链表实现的。<br>(01) head是链表的表头。取出数据时，都是从表头head处插入。<br>(02) last是链表的表尾。新增数据时，都是从表尾last处插入。<br>(03) count是链表的实际大小，即当前链表中包含的节点个数。<br>(04) capacity是列表的容量，它是在创建链表时指定的。<br>(05) putLock是插入锁，takeLock是取出锁；notEmpty是“非空条件”，notFull是“未满条件”。通过它们对链表进行并发控制。<pre><code>LinkedBlockingQueue在实现“多线程对竞争资源的互斥访问”时，对于“插入”和“取出(删除)”操作分别使用了不同的锁。对于插入操作，通过“插入锁putLock”进行同步；对于取出操作，通过“取出锁takeLock”进行同步。
此外，插入锁putLock和“非满条件notFull”相关联，取出锁takeLock和“非空条件notEmpty”相关联。通过notFull和notEmpty更细腻的控制锁。
</code></pre></li>
</ol>
<blockquote>
<p>– 若某线程(线程A)要取出数据时，队列正好为空，则该线程会执行notEmpty.await()进行等待；当其它某个线程(线程B)向队列中插入了数据之后，会调用notEmpty.signal()唤醒“notEmpty上的等待线程”。&gt;此时，线程A会被唤醒从而得以继续运行。 此外，线程A在执行取操作前，会获取takeLock，在取操作执行完毕再释放takeLock。<br>– 若某线程(线程H)要插入数据时，队列已满，则该线程会它执行notFull.await()进行等待；当其它某个线程(线程I)取出数据之后，会调用notFull.signal()唤醒“notFull上的等待线程”。此时，线程H就会被唤醒从而得以继续运行。 此外，线程H在执行插入操作前，会获取putLock，在插入操作执行完毕才释放putLock。</p>
</blockquote>
<h3 id="LinkedBlockingQueue函数列表"><a href="#LinkedBlockingQueue函数列表" class="headerlink" title="LinkedBlockingQueue函数列表"></a>LinkedBlockingQueue函数列表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 创建一个容量为 Integer.MAX_VALUE 的 LinkedBlockingQueue。  </span></div><div class="line">LinkedBlockingQueue()  </div><div class="line"><span class="comment">// 创建一个容量是 Integer.MAX_VALUE 的 LinkedBlockingQueue，最初包含给定 collection 的元素，元素按该 collection 迭代器的遍历顺序添加。  </span></div><div class="line">LinkedBlockingQueue(Collection&lt;? extends E&gt; c)  </div><div class="line"><span class="comment">// 创建一个具有给定（固定）容量的 LinkedBlockingQueue。  </span></div><div class="line">LinkedBlockingQueue(<span class="keyword">int</span> capacity)  </div><div class="line">  </div><div class="line"><span class="comment">// 从队列彻底移除所有元素。  </span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span>  </span></div><div class="line"><span class="comment">// 移除此队列中所有可用的元素，并将它们添加到给定 collection 中。  </span></div><div class="line"><span class="keyword">int</span> <span class="title">drainTo</span><span class="params">(Collection&lt;? <span class="keyword">super</span> E&gt; c)</span>  </div><div class="line"><span class="comment">// 最多从此队列中移除给定数量的可用元素，并将这些元素添加到给定 collection 中。  </span></div><div class="line"><span class="keyword">int</span> <span class="title">drainTo</span><span class="params">(Collection&lt;? <span class="keyword">super</span> E&gt; c, <span class="keyword">int</span> maxElements)</span>  </div><div class="line"><span class="comment">// 返回在队列中的元素上按适当顺序进行迭代的迭代器。  </span></div><div class="line">Iterator&lt;E&gt; <span class="title">iterator</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 将指定元素插入到此队列的尾部（如果立即可行且不会超出此队列的容量），在成功时返回 true，如果此队列已满，则返回 false。  </span></div><div class="line"><span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span>  </div><div class="line"><span class="comment">// 将指定元素插入到此队列的尾部，如有必要，则等待指定的时间以使空间变得可用。  </span></div><div class="line"><span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e, <span class="keyword">long</span> timeout, TimeUnit unit)</span>  </div><div class="line"><span class="comment">// 获取但不移除此队列的头；如果此队列为空，则返回 null。  </span></div><div class="line">E <span class="title">peek</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 获取并移除此队列的头，如果此队列为空，则返回 null。  </span></div><div class="line">E <span class="title">poll</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 获取并移除此队列的头部，在指定的等待时间前等待可用的元素（如果有必要）。  </span></div><div class="line">E <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span>  </div><div class="line"><span class="comment">// 将指定元素插入到此队列的尾部，如有必要，则等待空间变得可用。  </span></div><div class="line"><span class="keyword">void</span> <span class="title">put</span><span class="params">(E e)</span>  </div><div class="line"><span class="comment">// 返回理想情况下（没有内存和资源约束）此队列可接受并且不会被阻塞的附加元素数量。  </span></div><div class="line"><span class="keyword">int</span> <span class="title">remainingCapacity</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 从此队列移除指定元素的单个实例（如果存在）。  </span></div><div class="line"><span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span>  </div><div class="line"><span class="comment">// 返回队列中的元素个数。  </span></div><div class="line"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 获取并移除此队列的头部，在元素变得可用之前一直等待（如果有必要）。  </span></div><div class="line">E <span class="title">take</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 返回按适当顺序包含此队列中所有元素的数组。  </span></div><div class="line">Object[] <span class="title">toArray</span><span class="params">()</span>  </div><div class="line"><span class="comment">// 返回按适当顺序包含此队列中所有元素的数组；返回数组的运行时类型是指定数组的运行时类型。  </span></div><div class="line">&lt;T&gt; T[] <span class="title">toArray</span><span class="params">(T[] a)</span>  </div><div class="line"><span class="comment">// 返回此 collection 的字符串表示形式。  </span></div><div class="line">String <span class="title">toString</span><span class="params">()</span></div></pre></td></tr></table></figure>
<h2 id="LinkedBlockingQueue源码分析-JDK1-7-0-40版本"><a href="#LinkedBlockingQueue源码分析-JDK1-7-0-40版本" class="headerlink" title="LinkedBlockingQueue源码分析(JDK1.7.0_40版本)"></a>LinkedBlockingQueue源码分析(JDK1.7.0_40版本)</h2><p>下面从LinkedBlockingQueue的创建，添加，删除，遍历这几个方面对它进行分析。</p>
<h3 id="1-创建"><a href="#1-创建" class="headerlink" title="1. 创建"></a>1. 创建</h3><p>下面以LinkedBlockingQueue(int capacity)来进行说明。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedBlockingQueue</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;  </div><div class="line">    <span class="keyword">if</span> (capacity &lt;= <span class="number">0</span>) <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();  </div><div class="line">    <span class="keyword">this</span>.capacity = capacity;  </div><div class="line">    last = head = <span class="keyword">new</span> Node&lt;E&gt;(<span class="keyword">null</span>);  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>说明：<br>(01) capacity是“链式阻塞队列”的容量。<br>(02) head和last是“链式阻塞队列”的首节点和尾节点。它们在LinkedBlockingQueue中的声明如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 容量  </span></div><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> capacity;  </div><div class="line"><span class="comment">// 当前数量  </span></div><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);  </div><div class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Node&lt;E&gt; head; <span class="comment">// 链表的表头  </span></div><div class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Node&lt;E&gt; last; <span class="comment">// 链表的表尾  </span></div><div class="line"><span class="comment">// 用于控制“删除元素”的互斥锁takeLock 和 锁对应的“非空条件”notEmpty  </span></div><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock takeLock = <span class="keyword">new</span> ReentrantLock();  </div><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> Condition notEmpty = takeLock.newCondition();  </div><div class="line"><span class="comment">// 用于控制“添加元素”的互斥锁putLock 和 锁对应的“非满条件”notFull  </span></div><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock putLock = <span class="keyword">new</span> ReentrantLock();  </div><div class="line"><span class="keyword">private</span> <span class="keyword">final</span> Condition notFull = putLock.newCondition();</div></pre></td></tr></table></figure></p>
<p><strong>链表的节点定义如下：</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">E</span>&gt; </span>&#123;  </div><div class="line">    E item;         <span class="comment">// 数据  </span></div><div class="line">    Node&lt;E&gt; next;   <span class="comment">// 下一个节点的指针  </span></div><div class="line">  </div><div class="line">    Node(E x) &#123; item = x; &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-添加"><a href="#2-添加" class="headerlink" title="2. 添加"></a>2. 添加</h3><p>下面以offer(E e)为例，对LinkedBlockingQueue的添加方法进行说明。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span> </span>&#123;  </div><div class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();  </div><div class="line">    <span class="comment">// 如果“队列已满”，则返回false，表示插入失败。  </span></div><div class="line">    <span class="keyword">final</span> AtomicInteger count = <span class="keyword">this</span>.count;  </div><div class="line">    <span class="keyword">if</span> (count.get() == capacity)  </div><div class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;  </div><div class="line">    <span class="keyword">int</span> c = -<span class="number">1</span>;  </div><div class="line">    <span class="comment">// 新建“节点e”  </span></div><div class="line">    Node&lt;E&gt; node = <span class="keyword">new</span> Node(e);  </div><div class="line">    <span class="keyword">final</span> ReentrantLock putLock = <span class="keyword">this</span>.putLock;  </div><div class="line">    <span class="comment">// 获取“插入锁putLock”  </span></div><div class="line">    putLock.lock();  </div><div class="line">    <span class="keyword">try</span> &#123;  </div><div class="line">        <span class="comment">// 再次对“队列是不是满”的进行判断。  </span></div><div class="line">        <span class="comment">// 若“队列未满”，则插入节点。  </span></div><div class="line">        <span class="keyword">if</span> (count.get() &lt; capacity) &#123;  </div><div class="line">            <span class="comment">// 插入节点  </span></div><div class="line">            enqueue(node);  </div><div class="line">            <span class="comment">// 将“当前节点数量”+1，并返回“原始的数量”  </span></div><div class="line">            c = count.getAndIncrement();  </div><div class="line">            <span class="comment">// 如果在插入元素之后，队列仍然未满，则唤醒notFull上的等待线程。  </span></div><div class="line">            <span class="keyword">if</span> (c + <span class="number">1</span> &lt; capacity)  </div><div class="line">                notFull.signal();  </div><div class="line">        &#125;  </div><div class="line">    &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">        <span class="comment">// 释放“插入锁putLock”  </span></div><div class="line">        putLock.unlock();  </div><div class="line">    &#125;  </div><div class="line">    <span class="comment">// 如果在插入节点前，队列为空；则插入节点后，唤醒notEmpty上的等待线程  </span></div><div class="line">    <span class="keyword">if</span> (c == <span class="number">0</span>)  </div><div class="line">        signalNotEmpty();  </div><div class="line">    <span class="keyword">return</span> c &gt;= <span class="number">0</span>;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>说明</strong>：offer()的作用很简单，就是将元素E添加到队列的末尾。</p>
<p>enqueue()的源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">enqueue</span><span class="params">(Node&lt;E&gt; node)</span> </span>&#123;  </div><div class="line">    <span class="comment">// assert putLock.isHeldByCurrentThread();  </span></div><div class="line">    <span class="comment">// assert last.next == null;  </span></div><div class="line">    last = last.next = node;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>enqueue()的作用是将node添加到队列末尾，并设置node为新的尾节点！</p>
<p>signalNotEmpty()的源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">signalNotEmpty</span><span class="params">()</span> </span>&#123;  </div><div class="line">    <span class="keyword">final</span> ReentrantLock takeLock = <span class="keyword">this</span>.takeLock;  </div><div class="line">    takeLock.lock();  </div><div class="line">    <span class="keyword">try</span> &#123;  </div><div class="line">        notEmpty.signal();  </div><div class="line">    &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">        takeLock.unlock();  </div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>signalNotEmpty()的作用是唤醒notEmpty上的等待线程。</p>
<h2 id="3-取出"><a href="#3-取出" class="headerlink" title="3. 取出"></a>3. 取出</h2><p>下面以take()为例，对LinkedBlockingQueue的取出方法进行说明。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> E <span class="title">take</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;  </div><div class="line">    E x;  </div><div class="line">    <span class="keyword">int</span> c = -<span class="number">1</span>;  </div><div class="line">    <span class="keyword">final</span> AtomicInteger count = <span class="keyword">this</span>.count;  </div><div class="line">    <span class="keyword">final</span> ReentrantLock takeLock = <span class="keyword">this</span>.takeLock;  </div><div class="line">    <span class="comment">// 获取“取出锁”，若当前线程是中断状态，则抛出InterruptedException异常  </span></div><div class="line">    takeLock.lockInterruptibly();  </div><div class="line">    <span class="keyword">try</span> &#123;  </div><div class="line">        <span class="comment">// 若“队列为空”，则一直等待。  </span></div><div class="line">        <span class="keyword">while</span> (count.get() == <span class="number">0</span>) &#123;  </div><div class="line">            notEmpty.await();  </div><div class="line">        &#125;  </div><div class="line">        <span class="comment">// 取出元素  </span></div><div class="line">        x = dequeue();  </div><div class="line">        <span class="comment">// 取出元素之后，将“节点数量”-1；并返回“原始的节点数量”。  </span></div><div class="line">        c = count.getAndDecrement();  </div><div class="line">        <span class="keyword">if</span> (c &gt; <span class="number">1</span>)  </div><div class="line">            notEmpty.signal();  </div><div class="line">    &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">        <span class="comment">// 释放“取出锁”  </span></div><div class="line">        takeLock.unlock();  </div><div class="line">    &#125;  </div><div class="line">    <span class="comment">// 如果在“取出元素之前”，队列是满的；则在取出元素之后，唤醒notFull上的等待线程。  </span></div><div class="line">    <span class="keyword">if</span> (c == capacity)  </div><div class="line">        signalNotFull();  </div><div class="line">    <span class="keyword">return</span> x;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>说明：take()的作用是取出并返回队列的头。若队列为空，则一直等待。</p>
<p>dequeue()的源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> E <span class="title">dequeue</span><span class="params">()</span> </span>&#123;  </div><div class="line">    <span class="comment">// assert takeLock.isHeldByCurrentThread();  </span></div><div class="line">    <span class="comment">// assert head.item == null;  </span></div><div class="line">    Node&lt;E&gt; h = head;  </div><div class="line">    Node&lt;E&gt; first = h.next;  </div><div class="line">    h.next = h; <span class="comment">// help GC  </span></div><div class="line">    head = first;  </div><div class="line">    E x = first.item;  </div><div class="line">    first.item = <span class="keyword">null</span>;  </div><div class="line">    <span class="keyword">return</span> x;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>dequeue()的作用就是删除队列的头节点，并将表头指向“原头节点的下一个节点”。</p>
<p>signalNotFull()的源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">signalNotFull</span><span class="params">()</span> </span>&#123;  </div><div class="line">    <span class="keyword">final</span> ReentrantLock putLock = <span class="keyword">this</span>.putLock;  </div><div class="line">    putLock.lock();  </div><div class="line">    <span class="keyword">try</span> &#123;  </div><div class="line">        notFull.signal();  </div><div class="line">    &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">        putLock.unlock();  </div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>signalNotFull()的作用就是唤醒notFull上的等待线程。</p>
<h2 id="4-遍历"><a href="#4-遍历" class="headerlink" title="4. 遍历"></a>4. 遍历</h2><p>下面对LinkedBlockingQueue的遍历方法进行说明。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title">iterator</span><span class="params">()</span> </span>&#123;  </div><div class="line">  <span class="keyword">return</span> <span class="keyword">new</span> Itr();  </div><div class="line">&#125; </div><div class="line">``` </div><div class="line">iterator()实际上是返回一个Iter对象。</div><div class="line"></div><div class="line">Itr类的定义如下：</div><div class="line"></div><div class="line">``` java</div><div class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Itr</span> <span class="keyword">implements</span> <span class="title">Iterator</span>&lt;<span class="title">E</span>&gt; </span>&#123;  </div><div class="line">    <span class="comment">// 当前节点  </span></div><div class="line">    <span class="keyword">private</span> Node&lt;E&gt; current;  </div><div class="line">    <span class="comment">// 上一次返回的节点  </span></div><div class="line">    <span class="keyword">private</span> Node&lt;E&gt; lastRet;  </div><div class="line">    <span class="comment">// 当前节点对应的值  </span></div><div class="line">    <span class="keyword">private</span> E currentElement;  </div><div class="line">  </div><div class="line">    Itr() &#123;  </div><div class="line">        <span class="comment">// 同时获取“插入锁putLock” 和 “取出锁takeLock”  </span></div><div class="line">        fullyLock();  </div><div class="line">        <span class="keyword">try</span> &#123;  </div><div class="line">            <span class="comment">// 设置“当前元素”为“队列表头的下一节点”，即为队列的第一个有效节点  </span></div><div class="line">            current = head.next;  </div><div class="line">            <span class="keyword">if</span> (current != <span class="keyword">null</span>)  </div><div class="line">                currentElement = current.item;  </div><div class="line">        &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">            <span class="comment">// 释放“插入锁putLock” 和 “取出锁takeLock”  </span></div><div class="line">            fullyUnlock();  </div><div class="line">        &#125;  </div><div class="line">    &#125;  </div><div class="line">  </div><div class="line">    <span class="comment">// 返回“下一个节点是否为null”  </span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;  </div><div class="line">        <span class="keyword">return</span> current != <span class="keyword">null</span>;  </div><div class="line">    &#125;  </div><div class="line">  </div><div class="line">    <span class="function"><span class="keyword">private</span> Node&lt;E&gt; <span class="title">nextNode</span><span class="params">(Node&lt;E&gt; p)</span> </span>&#123;  </div><div class="line">        <span class="keyword">for</span> (;;) &#123;  </div><div class="line">            Node&lt;E&gt; s = p.next;  </div><div class="line">            <span class="keyword">if</span> (s == p)  </div><div class="line">                <span class="keyword">return</span> head.next;  </div><div class="line">            <span class="keyword">if</span> (s == <span class="keyword">null</span> || s.item != <span class="keyword">null</span>)  </div><div class="line">                <span class="keyword">return</span> s;  </div><div class="line">            p = s;  </div><div class="line">        &#125;  </div><div class="line">    &#125;  </div><div class="line">  </div><div class="line">    <span class="comment">// 返回下一个节点  </span></div><div class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">next</span><span class="params">()</span> </span>&#123;  </div><div class="line">        fullyLock();  </div><div class="line">        <span class="keyword">try</span> &#123;  </div><div class="line">            <span class="keyword">if</span> (current == <span class="keyword">null</span>)  </div><div class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();  </div><div class="line">            E x = currentElement;  </div><div class="line">            lastRet = current;  </div><div class="line">            current = nextNode(current);  </div><div class="line">            currentElement = (current == <span class="keyword">null</span>) ? <span class="keyword">null</span> : current.item;  </div><div class="line">            <span class="keyword">return</span> x;  </div><div class="line">        &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">            fullyUnlock();  </div><div class="line">        &#125;  </div><div class="line">    &#125;  </div><div class="line">  </div><div class="line">    <span class="comment">// 删除下一个节点  </span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span> </span>&#123;  </div><div class="line">        <span class="keyword">if</span> (lastRet == <span class="keyword">null</span>)  </div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException();  </div><div class="line">        fullyLock();  </div><div class="line">        <span class="keyword">try</span> &#123;  </div><div class="line">            Node&lt;E&gt; node = lastRet;  </div><div class="line">            lastRet = <span class="keyword">null</span>;  </div><div class="line">            <span class="keyword">for</span> (Node&lt;E&gt; trail = head, p = trail.next;  </div><div class="line">                 p != <span class="keyword">null</span>;  </div><div class="line">                 trail = p, p = p.next) &#123;  </div><div class="line">                <span class="keyword">if</span> (p == node) &#123;  </div><div class="line">                    unlink(p, trail);  </div><div class="line">                    <span class="keyword">break</span>;  </div><div class="line">                &#125;  </div><div class="line">            &#125;  </div><div class="line">        &#125; <span class="keyword">finally</span> &#123;  </div><div class="line">            fullyUnlock();  </div><div class="line">        &#125;  </div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>LinkedBlockingQueue示例</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.*;  </div><div class="line"><span class="keyword">import</span> java.util.concurrent.*;  </div><div class="line">  </div><div class="line"><span class="comment">/* </span></div><div class="line"> *   LinkedBlockingQueue是“线程安全”的队列，而LinkedList是非线程安全的。 </div><div class="line"> * </div><div class="line"> *   下面是“多个线程同时操作并且遍历queue”的示例 </div><div class="line"> *   (01) 当queue是LinkedBlockingQueue对象时，程序能正常运行。 </div><div class="line"> *   (02) 当queue是LinkedList对象时，程序会产生ConcurrentModificationException异常。 </div><div class="line"> * </div><div class="line"> * @author skywang </div><div class="line"> */  </div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedBlockingQueueDemo1</span> </span>&#123;  </div><div class="line">  </div><div class="line">    <span class="comment">// <span class="doctag">TODO:</span> queue是LinkedList对象时，程序会出错。  </span></div><div class="line">    <span class="comment">//private static Queue&lt;String&gt; queue = new LinkedList&lt;String&gt;();  </span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Queue&lt;String&gt; queue = <span class="keyword">new</span> LinkedBlockingQueue&lt;String&gt;();  </div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </div><div class="line">      </div><div class="line">        <span class="comment">// 同时启动两个线程对queue进行操作！  </span></div><div class="line">        <span class="keyword">new</span> MyThread(<span class="string">"ta"</span>).start();  </div><div class="line">        <span class="keyword">new</span> MyThread(<span class="string">"tb"</span>).start();  </div><div class="line">    &#125;  </div><div class="line">  </div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printAll</span><span class="params">()</span> </span>&#123;  </div><div class="line">        String value;  </div><div class="line">        Iterator iter = queue.iterator();  </div><div class="line">        <span class="keyword">while</span>(iter.hasNext()) &#123;  </div><div class="line">            value = (String)iter.next();  </div><div class="line">            System.out.print(value+<span class="string">", "</span>);  </div><div class="line">        &#125;  </div><div class="line">        System.out.println();  </div><div class="line">    &#125;  </div><div class="line">  </div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;  </div><div class="line">        MyThread(String name) &#123;  </div><div class="line">            <span class="keyword">super</span>(name);  </div><div class="line">        &#125;  </div><div class="line">        <span class="meta">@Override</span>  </div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;  </div><div class="line">                <span class="keyword">int</span> i = <span class="number">0</span>;  </div><div class="line">            <span class="keyword">while</span> (i++ &lt; <span class="number">6</span>) &#123;  </div><div class="line">                <span class="comment">// “线程名” + "-" + "序号"  </span></div><div class="line">                String val = Thread.currentThread().getName()+i;  </div><div class="line">                queue.add(val);  </div><div class="line">                <span class="comment">// 通过“Iterator”遍历queue。  </span></div><div class="line">                printAll();  </div><div class="line">            &#125;  </div><div class="line">        &#125;  </div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>(某一次)运行结果：</p>
<blockquote>
<p>tb1, ta1,<br>tb1, ta1, ta2,<br>tb1, ta1, ta2, ta3,<br>tb1, ta1, ta2, ta3, ta4,<br>tb1, ta1, tb1, ta2, ta1, ta3, ta2, ta4, ta3, ta5,<br>ta4, tb1, ta5, ta1, ta6,<br>ta2, tb1, ta3, ta1, ta4, ta2, ta5, ta3, ta6, ta4, tb2,<br>ta5, ta6, tb2,<br>tb1, ta1, ta2, ta3, ta4, ta5, ta6, tb2, tb3,<br>tb1, ta1, ta2, ta3, ta4, ta5, ta6, tb2, tb3, tb4,<br>tb1, ta1, ta2, ta3, ta4, ta5, ta6, tb2, tb3, tb4, tb5,<br>tb1, ta1, ta2, ta3, ta4, ta5, ta6, tb2, tb3, tb4, tb5, tb6,  </p>
</blockquote>
<p><strong>结果说明：</strong><br>示例程序中，启动两个线程(线程ta和线程tb)分别对LinkedBlockingQueue进行操作。以线程ta而言，它会先获取“线程名”+“序号”，然后将该字符串添加到LinkedBlockingQueue中；接着，遍历并输出LinkedBlockingQueue中的全部元素。 线程tb的操作和线程ta一样，只不过线程tb的名字和线程ta的名字不同。<br>当queue是LinkedBlockingQueue对象时，程序能正常运行。如果将queue改为LinkedList时，程序会产生ConcurrentModificationException异常。</p>
<p>转载自：<a href="http://www.cnblogs.com/skywang12345/p/3503458.html" target="_blank" rel="external">http://www.cnblogs.com/skywang12345/p/3503458.html</a></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> LinkedBlockingQueue </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[从一个故障说说Java的三个BlockingQueue]]></title>
      <url>http://Melodylican.github.io/2017/05/24/BlockingQueue/</url>
      <content type="html"><![CDATA[<p>最近出了个故障，排查的时候耗费了很长的时间，回顾整个排查过程，经验主义在这里起了不好的作用，直接导致了整个故障排查的时间非常长，这个故障的根本原因在于BlockingQueue用的有问题，顺带展开说说Java中常用的几个BlockingQueue：ArrayBlockingQueue、LinkedBlockingQueue和SynchronousQueue。<br><a id="more"></a><br>当时故障的现象是应用处理请求的线程池满了，导致请求处理不了，于是dump线程，看线程都在做什么，结果发现线程都Block在写日志的地方，以前出现过很多次问题，去线程dump的时候看到也是一堆的block在写日志，但通常是别的原因引发的，所以这次也是按照这样的经验，认为肯定不会是写日志这个地方的问题，于是各种排查…折腾了N久后，回过头看发现持有那把日志锁的地方是自己人写的代码，那段代码在拿到了这个日志锁后，从线程堆栈上看，block在了ArrayBlockingQueue.put这个地方，于是翻看这段代码，结果发现这是个1024长度的BlockingQueue，那就意味着如果这个Queue被放了1024个对象的话，put就一定会被block住，而且其实翻代码的时候能看出写代码的同学是考虑到了BlockingQueue如果满了应该要处理的，代码里写着：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">if</span> (blockingQueue.remainingCapacity() &lt; <span class="number">1</span>) &#123;</div><div class="line">  <span class="comment">//todo</span></div><div class="line">&#125;</div><div class="line">blockingQueue.put</div></pre></td></tr></table></figure></p>
<p>这里两个悲催的问题，一是这个if判断完还是直接会走到put，而不是else，二是竟然关键的满了后的处理逻辑还在//todo…</p>
<p>另外我觉得这段代码还反应了同学对BlockingQueue的接口不太熟，要达到这个效果，不需要这样先去判断，更合适的做法是用blockingQueue.offer，返回false再做相应的异常处理。</p>
<p>BlockingQueue是在生产/消费者模式下经常会用到的数据结构，通常常用的主要会是ArrayBlockingQueue、LinkedBlockingQueue和SynchronousQueue。</p>
<p>ArrayBlockingQeue/LinkedBlockingQueue两者的最大不同主要在于存放Queue中对象方式，一个是数组，一个是链表，代码注释里也写到了两者的不同：Linked queues typically have higher throughput than array-based queues but less predictable performance in most concurrent applications.</p>
<p>SynchronousQueue是一个非常特殊的BlockingQueue，它的模式是在offer的时候，如果没有另外一个线程正在take或poll的话，那么offer就会失败；在take的时候，如果没有另外的线程正好并发在offer，也会失败，这种特殊的模式非常适合用来做要求高响应并且线程出不固定的线程池的Queue。</p>
<p>对于在线业务场景而言，所有的并发，外部访问阻塞的地方的一个真理就是一定要有超时机制，我不知道见过多少次由于没有超时造成的在线业务的严重故障，在线业务最强调的是快速处理掉一次请求，所以fail fast是在线业务系统设计，代码编写中的最重要原则，按照这个原则上面的代码最起码明显犯的错误就是用put而不是带超时机制的offer，或者说如果是不重要的场景，完全就应该直接用offer，false了直接抛异常或记录下异常即可。</p>
<p>对于BlockingQueue这种场景呢，除了超时机制外，还有一个是队列长度一定要做限制，否则默认的是Integer.MAX_VALUE，万一代码出点bug的话，内存就被玩挂了。</p>
<p>说到BlockingQueue，就还是要提下BlockingQueue被用的最多的地方：线程池，Java的ThreadPoolExecutor中有个参数是BlockingQueue，如果这个地方用的是ArrayBlockingQueue或LinkedBlockingQueue，而线程池的coreSize和poolSize不一样的话，在coreSize线程满了后，这个时候线程池首先会做的是offer到BlockingQueue，成功的话就结束，这种场景同样不符合在线业务的需求，在线业务更希望的是快速处理，而不是先排队，而且其实在线业务最好是不要让请求堆在排队队列里，在线业务这样做很容易引发雪崩，超出处理能力范围直接拒绝抛错是相对比较好的做法，至于在前面页面上排队什么这个是可以的，那是另外一种限流机制。</p>
<p>所以说在写高并发、分布式的代码时，除了系统设计外，代码细节的功力是非常非常重要的。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> BlockingQueue </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第六章 第三节 Spark - MLlib基本数据类型2]]></title>
      <url>http://Melodylican.github.io/2017/04/22/Spark-MLlib%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B2/</url>
      <content type="html"><![CDATA[<div class="note success"><h2 id="分布式矩阵（Distributed-Matrix）"><a href="#分布式矩阵（Distributed-Matrix）" class="headerlink" title="分布式矩阵（Distributed Matrix）"></a>分布式矩阵（Distributed Matrix）</h2></div>
<p>分布式矩阵由长整型的行列索引值和双精度浮点型的元素值组成。它可以分布式地存储在一个或多个RDD上，MLlib提供了三种分布式矩阵的存储方案：<strong>行矩阵</strong>RowMatrix，<strong>索引行矩阵</strong>IndexedRowMatrix、<strong>坐标矩阵</strong>CoordinateMatrix和<strong>分块矩阵</strong>Block Matrix。它们都属于org.apache.spark.mllib.linalg.distributed包。<br><a id="more"></a><br><div class="note success"><h3 id="（一）行矩阵（RowMatrix）"><a href="#（一）行矩阵（RowMatrix）" class="headerlink" title="（一）行矩阵（RowMatrix）"></a>（一）行矩阵（RowMatrix）</h3></div><br><strong>行矩阵</strong>RowMatrix是最基础的分布式矩阵类型。每行是一个本地向量，行索引无实际意义（即无法直接使用）。数据存储在一个由行组成的RDD中，其中每一行都使用一个本地向量来进行存储。由于行是通过本地向量来实现的，故列数（即行的维度）被限制在普通整型（integer）的范围内。在实际使用时，由于单机处理本地向量的存储和通信代价，行维度更是需要被控制在一个更小的范围之内。RowMatrix可通过一个RDD[Vector]的实例来创建，如下代码所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Vector</span>,<span class="type">Vectors</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Vector</span>,<span class="type">Vectors</span>&#125;</div><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.<span class="type">RowMatrix</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.<span class="type">RowMatrix</span></div><div class="line"> </div><div class="line"><span class="comment">// 创建两个本地向量dv1 dv2</span></div><div class="line">scala&gt; <span class="keyword">val</span> dv1 : <span class="type">Vector</span> = <span class="type">Vectors</span>.dense(<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>)</div><div class="line">dv1: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>]</div><div class="line">scala&gt; <span class="keyword">val</span> dv2 : <span class="type">Vector</span> = <span class="type">Vectors</span>.dense(<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>)</div><div class="line">dv2: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>]</div><div class="line"><span class="comment">// 使用两个本地向量创建一个RDD[Vector]</span></div><div class="line">scala&gt; <span class="keyword">val</span> rows : <span class="type">RDD</span>[<span class="type">Vector</span>] = sc.parallelize(<span class="type">Array</span>(dv1,dv2))</div><div class="line">rows: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.mllib.linalg.<span class="type">Vector</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">13</span>] at parallelize at &lt;console&gt;:<span class="number">38</span></div><div class="line"> </div><div class="line"><span class="comment">// 通过RDD[Vector]创建一个行矩阵</span></div><div class="line">scala&gt; <span class="keyword">val</span> mat : <span class="type">RowMatrix</span> = <span class="keyword">new</span> <span class="type">RowMatrix</span>(rows)</div><div class="line">mat: org.apache.spark.mllib.linalg.distributed.<span class="type">RowMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">RowMatrix</span>@<span class="number">76</span>fc0fa</div><div class="line"><span class="comment">//可以使用numRows()和numCols()方法得到行数和列数</span></div><div class="line">scala&gt; mat.numRows()</div><div class="line">res0: <span class="type">Long</span> = <span class="number">2</span></div><div class="line">scala&gt; mat.numCols()</div><div class="line">res1: <span class="type">Long</span> = <span class="number">3</span></div><div class="line">scala&gt; mat.rows.foreach(println)</div><div class="line">[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>]</div><div class="line">[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>]</div></pre></td></tr></table></figure></p>
<p>在获得RowMatrix的实例后，我们可以通过其自带的computeColumnSummaryStatistics()方法获取该矩阵的一些统计摘要信息，并可以对其进行QR分解，SVD分解和PCA分解，这一部分内容将在特征降维的章节详细解说，这里不再叙述。<br>统计摘要信息的获取如下代码段所示（接上代码段）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 通过computeColumnSummaryStatistics()方法获取统计摘要</span></div><div class="line">scala&gt; <span class="keyword">val</span> summary = mat.computeColumnSummaryStatistics()</div><div class="line"><span class="comment">// 可以通过summary实例来获取矩阵的相关统计信息，例如行数</span></div><div class="line">scala&gt; summary.count</div><div class="line">res2: <span class="type">Long</span> = <span class="number">2</span></div><div class="line"><span class="comment">// 最大向量</span></div><div class="line">scala&gt; summary.max</div><div class="line">res3: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>]</div><div class="line"><span class="comment">// 方差向量</span></div><div class="line">scala&gt; summary.variance</div><div class="line">res4: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>]</div><div class="line"><span class="comment">// 平均向量</span></div><div class="line">scala&gt; summary.mean</div><div class="line">res5: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">1.5</span>,<span class="number">2.5</span>,<span class="number">3.5</span>]</div><div class="line"><span class="comment">// L1范数向量</span></div><div class="line">scala&gt; summary.normL1</div><div class="line">res6: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">3.0</span>,<span class="number">5.0</span>,<span class="number">7.0</span>]</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="（二）索引行矩阵（IndexedRowMatrix）"><a href="#（二）索引行矩阵（IndexedRowMatrix）" class="headerlink" title="（二）索引行矩阵（IndexedRowMatrix）"></a>（二）索引行矩阵（IndexedRowMatrix）</h3></div>
<p>索引行矩阵IndexedRowMatrix与RowMatrix相似，但它的每一行都带有一个有意义的行索引值，这个索引值可以被用来识别不同行，或是进行诸如join之类的操作。其数据存储在一个由IndexedRow组成的RDD里，即每一行都是一个带长整型索引的本地向量。</p>
<p>与RowMatrix类似，IndexedRowMatrix的实例可以通过RDD[IndexedRow]实例来创建。如下代码段所示（接上例）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">scala&gt;<span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.&#123;<span class="type">IndexedRow</span>, <span class="type">IndexedRowMatrix</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.&#123;<span class="type">IndexedRow</span>, <span class="type">IndexedRowMatrix</span>&#125;</div><div class="line"> </div><div class="line"> </div><div class="line"><span class="comment">// 通过本地向量dv1 dv2来创建对应的IndexedRow</span></div><div class="line"><span class="comment">// 在创建时可以给定行的索引值，如这里给dv1的向量赋索引值1，dv2赋索引值2</span></div><div class="line">scala&gt; <span class="keyword">val</span> idxr1 = <span class="type">IndexedRow</span>(<span class="number">1</span>,dv1)</div><div class="line">idxr1: org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRow</span> = <span class="type">IndexedRow</span>(<span class="number">1</span>,[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>])</div><div class="line">scala&gt; <span class="keyword">val</span> idxr2 = <span class="type">IndexedRow</span>(<span class="number">2</span>,dv2)</div><div class="line">idxr2: org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRow</span> = <span class="type">IndexedRow</span>(<span class="number">2</span>,[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>])</div><div class="line"> </div><div class="line"><span class="comment">// 通过IndexedRow创建RDD[IndexedRow]</span></div><div class="line">scala&gt; <span class="keyword">val</span> idxrows = sc.parallelize(<span class="type">Array</span>(idxr1,idxr2))</div><div class="line">idxrows: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRow</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">14</span>] at parallelize at &lt;console&gt;:<span class="number">45</span></div><div class="line"> </div><div class="line"><span class="comment">// 通过RDD[IndexedRow]创建一个索引行矩阵</span></div><div class="line">scala&gt; <span class="keyword">val</span> idxmat: <span class="type">IndexedRowMatrix</span> = <span class="keyword">new</span> <span class="type">IndexedRowMatrix</span>(idxrows)</div><div class="line">idxmat: org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRowMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRowMatrix</span>@<span class="number">532887</span>bc</div><div class="line"><span class="comment">//打印</span></div><div class="line">scala&gt; idxmat.rows.foreach(println)</div><div class="line">  <span class="type">IndexedRow</span>(<span class="number">1</span>,[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>])</div><div class="line">  <span class="type">IndexedRow</span>(<span class="number">2</span>,[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>])</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="（三）坐标矩阵（Coordinate-Matrix）"><a href="#（三）坐标矩阵（Coordinate-Matrix）" class="headerlink" title="（三）坐标矩阵（Coordinate Matrix）"></a>（三）坐标矩阵（Coordinate Matrix）</h3></div>
<p>坐标矩阵CoordinateMatrix是一个基于矩阵项构成的RDD的分布式矩阵。每一个矩阵项MatrixEntry都是一个三元组：(i: Long, j: Long, value: Double)，其中i是行索引，j是列索引，value是该位置的值。坐标矩阵一般在矩阵的两个维度都很大，且矩阵非常稀疏的时候使用。</p>
<p>CoordinateMatrix实例可通过RDD[MatrixEntry]实例来创建，其中每一个矩阵项都是一个(rowIndex, colIndex, elem)的三元组：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.&#123;<span class="type">CoordinateMatrix</span>, <span class="type">MatrixEntry</span>&#125;</div><div class="line"> </div><div class="line"><span class="comment">// 创建两个矩阵项ent1和ent2，每一个矩阵项都是由索引和值构成的三元组</span></div><div class="line">scala&gt; <span class="keyword">val</span> ent1 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.5</span>)</div><div class="line">ent1: org.apache.spark.mllib.linalg.distributed.<span class="type">MatrixEntry</span> = <span class="type">MatrixEntry</span>(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.5</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> ent2 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1.8</span>)</div><div class="line">ent2: org.apache.spark.mllib.linalg.distributed.<span class="type">MatrixEntry</span> = <span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1.8</span>)</div><div class="line"><span class="comment">// 创建RDD[MatrixEntry]</span></div><div class="line">scala&gt; <span class="keyword">val</span> entries : <span class="type">RDD</span>[<span class="type">MatrixEntry</span>] = sc.parallelize(<span class="type">Array</span>(ent1,ent2))</div><div class="line">entries: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.mllib.linalg.distributed.<span class="type">MatrixEntry</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">15</span>] at parallelize at &lt;console&gt;:<span class="number">42</span></div><div class="line"><span class="comment">// 通过RDD[MatrixEntry]创建一个坐标矩阵</span></div><div class="line">scala&gt; <span class="keyword">val</span> coordMat: <span class="type">CoordinateMatrix</span> = <span class="keyword">new</span> <span class="type">CoordinateMatrix</span>(entries)</div><div class="line">coordMat: org.apache.spark.mllib.linalg.distributed.<span class="type">CoordinateMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">CoordinateMatrix</span>@<span class="number">25</span>b2d465</div><div class="line"><span class="comment">//打印</span></div><div class="line">scala&gt; coordMat.entries.foreach(println)</div><div class="line"><span class="type">MatrixEntry</span>(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.5</span>)</div><div class="line"><span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1.8</span>)</div></pre></td></tr></table></figure></p>
<p>坐标矩阵可以通过transpose()方法对矩阵进行转置操作，并可以通过自带的toIndexedRowMatrix()方法转换成索引行矩阵IndexedRowMatrix。但目前暂不支持CoordinateMatrix的其他计算操作。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 将coordMat进行转置</span></div><div class="line">scala&gt; <span class="keyword">val</span> transMat: <span class="type">CoordinateMatrix</span> = coordMat.transpose()</div><div class="line">transMat: org.apache.spark.mllib.linalg.distributed.<span class="type">CoordinateMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">CoordinateMatrix</span><span class="meta">@c</span>1ee50</div><div class="line">scala&gt; transMat.entries.foreach(println)</div><div class="line">  <span class="type">MatrixEntry</span>(<span class="number">1</span>,<span class="number">0</span>,<span class="number">0.5</span>)</div><div class="line"><span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1.8</span>)</div><div class="line"><span class="comment">// 将坐标矩阵转换成一个索引行矩阵</span></div><div class="line">scala&gt; <span class="keyword">val</span> indexedRowMatrix = transMat.toIndexedRowMatrix()</div><div class="line">indexedRowMatrix: org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRowMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">IndexedRowMatrix</span>@<span class="number">7</span>ee7e1bb</div><div class="line">scala&gt; indexedRowMatrix.rows.foreach(println)</div><div class="line"><span class="type">IndexedRow</span>(<span class="number">1</span>,(<span class="number">3</span>,[<span class="number">0</span>],[<span class="number">0.5</span>]))</div><div class="line"><span class="type">IndexedRow</span>(<span class="number">2</span>,(<span class="number">3</span>,[<span class="number">2</span>],[<span class="number">1.8</span>]))</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="（四）分块矩阵（Block-Matrix）"><a href="#（四）分块矩阵（Block-Matrix）" class="headerlink" title="（四）分块矩阵（Block Matrix）"></a>（四）分块矩阵（Block Matrix）</h3></div>
<p>分块矩阵是基于矩阵块MatrixBlock构成的RDD的分布式矩阵，其中每一个矩阵块MatrixBlock都是一个元组((Int, Int), Matrix)，其中(Int, Int)是块的索引，而Matrix则是在对应位置的子矩阵（sub-matrix），其尺寸由rowsPerBlock和colsPerBlock决定，默认值均为1024。分块矩阵支持和另一个分块矩阵进行加法操作和乘法操作，并提供了一个支持方法validate()来确认分块矩阵是否创建成功。</p>
<p>分块矩阵可由索引行矩阵IndexedRowMatrix或坐标矩阵CoordinateMatrix调用toBlockMatrix()方法来进行转换，该方法将矩阵划分成尺寸默认为1024x1024的分块，可以在调用toBlockMatrix(rowsPerBlock, colsPerBlock)方法时传入参数来调整分块的尺寸。<br>下面以矩阵A（如图）为例，先利用矩阵项MatrixEntry将其构造成坐标矩阵，再转化成如图所示的4个分块矩阵，最后对矩阵A与其转置进行乘法运算：</p>
<p><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/12/2.png" alt=""><br></center><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.&#123;<span class="type">CoordinateMatrix</span>, <span class="type">MatrixEntry</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.&#123;<span class="type">CoordinateMatrix</span>, <span class="type">MatrixEntry</span>&#125;</div><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.<span class="type">BlockMatrix</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.distributed.<span class="type">BlockMatrix</span></div><div class="line"> </div><div class="line"><span class="comment">// 创建8个矩阵项，每一个矩阵项都是由索引和值构成的三元组</span></div><div class="line">scala&gt; <span class="keyword">val</span> ent1 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent2 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent3 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">0</span>,<span class="number">-1</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent4 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent5 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent6 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">3</span>,<span class="number">0</span>,<span class="number">1</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent7 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">...</div><div class="line">scala&gt; <span class="keyword">val</span> ent8 = <span class="keyword">new</span> <span class="type">MatrixEntry</span>(<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>)</div><div class="line">...</div><div class="line"><span class="comment">// 创建RDD[MatrixEntry]</span></div><div class="line">scala&gt; <span class="keyword">val</span> entries : <span class="type">RDD</span>[<span class="type">MatrixEntry</span>] = sc.parallelize(<span class="type">Array</span>(ent1,ent2,ent3,ent4,ent5,ent6,ent7,ent8))</div><div class="line">entries: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.mllib.linalg.distributed.<span class="type">MatrixEntry</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">21</span>] at parallelize at &lt;console&gt;:<span class="number">57</span></div><div class="line"> </div><div class="line"><span class="comment">// 通过RDD[MatrixEntry]创建一个坐标矩阵</span></div><div class="line">scala&gt; <span class="keyword">val</span> coordMat: <span class="type">CoordinateMatrix</span> = <span class="keyword">new</span> <span class="type">CoordinateMatrix</span>(entries)</div><div class="line">coordMat: org.apache.spark.mllib.linalg.distributed.<span class="type">CoordinateMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">CoordinateMatrix</span>@<span class="number">31</span>c5fb43</div><div class="line"> </div><div class="line">  <span class="comment">// 将坐标矩阵转换成2x2的分块矩阵并存储，尺寸通过参数传入</span></div><div class="line"><span class="keyword">val</span> matA: <span class="type">BlockMatrix</span> = coordMat.toBlockMatrix(<span class="number">2</span>,<span class="number">2</span>).cache()</div><div class="line">  matA: org.apache.spark.mllib.linalg.distributed.<span class="type">BlockMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">BlockMatrix</span>@<span class="number">26</span>b1df2c</div><div class="line"><span class="comment">// 可以用validate()方法判断是否分块成功</span></div><div class="line">matA.validate()</div></pre></td></tr></table></figure></p>
<p>构建成功后，可通过toLocalMatrix转换成本地矩阵，并查看其分块情况：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">scala&gt; matA.toLocalMatrix</div><div class="line">res31: org.apache.spark.mllib.linalg.<span class="type">Matrix</span> =</div><div class="line"><span class="number">1.0</span>   <span class="number">0.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></div><div class="line"><span class="number">0.0</span>   <span class="number">1.0</span>  <span class="number">0.0</span>  <span class="number">0.0</span></div><div class="line"><span class="number">-1.0</span>  <span class="number">2.0</span>  <span class="number">1.0</span>  <span class="number">0.0</span></div><div class="line"><span class="number">1.0</span>   <span class="number">1.0</span>  <span class="number">0.0</span>  <span class="number">1.0</span></div><div class="line"> </div><div class="line"><span class="comment">// 查看其分块情况</span></div><div class="line">scala&gt; matA.numColBlocks</div><div class="line">res12: <span class="type">Int</span> = <span class="number">2</span></div><div class="line">scala&gt; matA.numRowBlocks</div><div class="line">res13: <span class="type">Int</span> = <span class="number">2</span></div><div class="line"> </div><div class="line"><span class="comment">// 计算矩阵A和其转置矩阵的积矩阵</span></div><div class="line">scala&gt; <span class="keyword">val</span> ata = matA.transpose.multiply(matA)</div><div class="line">  ata: org.apache.spark.mllib.linalg.distributed.<span class="type">BlockMatrix</span> = org.apache.spark.mllib.linalg.distributed.<span class="type">BlockMatrix</span>@<span class="number">3644e451</span></div><div class="line">scala&gt; ata.toLocalMatrix</div><div class="line">res1: org.apache.spark.mllib.linalg.<span class="type">Matrix</span> =</div><div class="line"><span class="number">3.0</span>   <span class="number">-1.0</span>  <span class="number">-1.0</span>  <span class="number">1.0</span></div><div class="line"><span class="number">-1.0</span>  <span class="number">6.0</span>   <span class="number">2.0</span>   <span class="number">1.0</span></div><div class="line"><span class="number">-1.0</span>  <span class="number">2.0</span>   <span class="number">1.0</span>   <span class="number">0.0</span></div><div class="line"><span class="number">1.0</span>   <span class="number">1.0</span>   <span class="number">0.0</span>   <span class="number">1.0</span></div></pre></td></tr></table></figure></p>
<p>分块矩阵BlockMatrix将矩阵分成一系列矩阵块，底层由矩阵块构成的RDD来进行数据存储。值得指出的是，用于生成分布式矩阵的底层RDD必须是已经确定（Deterministic）的，因为矩阵的尺寸将被存储下来，所以使用未确定的RDD将会导致错误。而且，不同类型的分布式矩阵之间的转换需要进行一个全局的shuffle操作，非常耗费资源。所以，根据数据本身的性质和应用需求来选取恰当的分布式矩阵存储类型是非常重要的。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第六章 第二节 Spark - MLlib基本数据类型1]]></title>
      <url>http://Melodylican.github.io/2017/04/18/Spark-MLlib%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
      <content type="html"><![CDATA[<p>MLLib提供了一系列基本数据类型以支持底层的机器学习算法。主要的数据类型包括：本地向量、标注点（Labeled Point）、本地矩阵、分布式矩阵等。单机模式存储的本地向量与矩阵，以及基于一个或多个RDD的分布式矩阵。其中本地向量与本地矩阵作为公共接口提供简单数据模型，底层的线性代数操作由<em>Breeze</em>库和<em>jblas</em>库提供。标注点类型用来表示<em>监督学习（Supervised Learning）</em>中的一个训练样本。<br><a id="more"></a></p>
<p>在正式学习机器学习算法之前，让我们先了解下这些数据类型的用法。</p>
<div class="note success"><h2 id="本地向量（Local-Vector）"><a href="#本地向量（Local-Vector）" class="headerlink" title="本地向量（Local Vector）"></a>本地向量（Local Vector）</h2></div>
<p><strong>本地向量</strong>存储在单机上，其拥有整型、从0开始的索引值以及浮点型的元素值。MLlib提供了两种类型的本地向量，<strong>稠密向量</strong>DenseVector和<strong>稀疏向量</strong>SparseVector。稠密向量使用一个双精度浮点型数组来表示其中每一维元素，而稀疏向量则是基于一个整型索引数组和一个双精度浮点型的值数组。例如，向量(1.0, 0.0, 3.0)的稠密向量表示形式是[1.0,0.0,3.0]，而稀疏向量形式则是(3, [0,2], [1.0, 3.0])，其中，3是向量的长度，[0,2]是向量中非0维度的索引值，表示位置为0、2的两个元素为非零值，而[1.0, 3.0]则是按索引排列的数组元素值。</p>
<p>所有本地向量都以org.apache.spark.mllib.linalg.Vector为基类，DenseVector和SparseVector分别是它的两个实现类，故推荐使用Vectors工具类下定义的工厂方法来创建本地向量，请看如下实例（假设在Spark-shell中运行，下同）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">scala&gt;<span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Vector</span>, <span class="type">Vectors</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Vector</span>, <span class="type">Vectors</span>&#125;</div><div class="line"> </div><div class="line"><span class="comment">// 创建一个稠密本地向量</span></div><div class="line">scala&gt; <span class="keyword">val</span> dv: <span class="type">Vector</span> = <span class="type">Vectors</span>.dense(<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">8.0</span>)</div><div class="line">dv: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = [<span class="number">2.0</span>,<span class="number">0.0</span>,<span class="number">8.0</span>]</div><div class="line"><span class="comment">// 创建一个稀疏本地向量</span></div><div class="line"><span class="comment">// 方法第二个参数数组指定了非零元素的索引，而第三个参数数组则给定了非零元素值</span></div><div class="line">scala&gt; <span class="keyword">val</span> sv1: <span class="type">Vector</span> = <span class="type">Vectors</span>.sparse(<span class="number">3</span>, <span class="type">Array</span>(<span class="number">0</span>, <span class="number">2</span>), <span class="type">Array</span>(<span class="number">2.0</span>, <span class="number">8.0</span>))</div><div class="line">sv1: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = (<span class="number">3</span>,[<span class="number">0</span>,<span class="number">2</span>],[<span class="number">2.0</span>,<span class="number">8.0</span>])</div><div class="line"><span class="comment">// 另一种创建稀疏本地向量的方法</span></div><div class="line"><span class="comment">// 方法的第二个参数是一个序列，其中每个元素都是一个非零值的元组：(index,elem)</span></div><div class="line">scala&gt; <span class="keyword">val</span> sv2: <span class="type">Vector</span> = <span class="type">Vectors</span>.sparse(<span class="number">3</span>, <span class="type">Seq</span>((<span class="number">0</span>, <span class="number">2.0</span>), (<span class="number">2</span>, <span class="number">8.0</span>)))</div><div class="line">sv2: org.apache.spark.mllib.linalg.<span class="type">Vector</span> = (<span class="number">3</span>,[<span class="number">0</span>,<span class="number">2</span>],[<span class="number">2.0</span>,<span class="number">8.0</span>])</div></pre></td></tr></table></figure></p>
<p>这里需要注意的是，Scala会默认引入<strong>scala.collection.immutable.Vector</strong>，我们要显式地引入<strong>org.apache.spark.mllib.linalg.Vector</strong>来使用MLlib提供的向量类型。</p>
<div class="note success"><h2 id="标注点（Labeled-Point）"><a href="#标注点（Labeled-Point）" class="headerlink" title="标注点（Labeled Point）"></a>标注点（Labeled Point）</h2></div>
<p><strong>标注点</strong>LabeledPoint是一种带有标签（Label/Response）的本地向量，它可以是稠密或者是稀疏的。在MLlib中，标注点在监督学习算法中被使用。由于标签是用双精度浮点型来存储的，故标注点类型在<strong>回归</strong>（Regression）和<strong>分类</strong>（Classification）问题上均可使用。例如，对于二分类问题，则正样本的标签为1，负样本的标签为0，而对于多类别的分类问题来说，标签则应是一个以0开始的索引序列:0, 1, 2 …</p>
<p>标注点的实现类是org.apache.spark.mllib.regression.LabeledPoint，请注意它与前面介绍的本地向量不同，并不位于linalg包下，标注点的创建如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></div><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></div><div class="line"><span class="comment">//创建一个标签为1.0（分类中可视为正样本）的稠密向量标注点</span></div><div class="line">scala&gt; <span class="keyword">val</span> pos = <span class="type">LabeledPoint</span>(<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">8.0</span>))</div><div class="line">pos: org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span> = (<span class="number">1.0</span>,[<span class="number">2.0</span>,<span class="number">0.0</span>,<span class="number">8.0</span>])</div><div class="line"><span class="comment">//创建一个标签为0.0（分类中可视为负样本）的稀疏向量标注点</span></div><div class="line">scala&gt; <span class="keyword">val</span> neg = <span class="type">LabeledPoint</span>(<span class="number">0.0</span>, <span class="type">Vectors</span>.sparse(<span class="number">3</span>, <span class="type">Array</span>(<span class="number">0</span>, <span class="number">2</span>), <span class="type">Array</span>(<span class="number">2.0</span>, <span class="number">8.0</span>)))</div><div class="line">neg: org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span> = (<span class="number">0.0</span>,(<span class="number">3</span>,[<span class="number">0</span>,<span class="number">2</span>],[<span class="number">2.0</span>,<span class="number">8.0</span>]))</div></pre></td></tr></table></figure></p>
<p>在实际的机器学习问题中，稀疏向量数据是非常常见的，MLlib提供了读取LIBSVM格式数据的支持，该格式被广泛用于LIBSVM、LIBLINEAR等机器学习库。在该格式下，每一个带标注的样本点由以下格式表示：</p>
<p>label index1:value1 index2:value2 index3:value3 …<br>其中label是该样本点的标签值，一系列index:value对则代表了该样本向量中所有非零元素的索引和元素值。这里需要特别注意的是，index是以1开始并递增的。<br>MLlib在org.apache.spark.mllib.util.MLUtils工具类中提供了读取LIBSVM格式的方法loadLibSVMFile，其使用非常方便。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.util.<span class="type">MLUtils</span></div><div class="line"> </div><div class="line"><span class="comment">// 用loadLibSVMFile方法读入LIBSVM格式数据</span></div><div class="line"><span class="comment">// sample_libsvm_data.txt为spark自带的一个示例，在以下地址可以找到：</span></div><div class="line"><span class="comment">// $SPARK_HOME$/data/mllib/sample_libsvm_data.txt</span></div><div class="line">scala&gt; <span class="keyword">val</span> examples = <span class="type">MLUtils</span>.loadLibSVMFile(sc, <span class="string">"/data/mllib/sample_libsvm_data.txt"</span>)</div><div class="line"><span class="comment">//返回的是组织成RDD的一系列LabeledPoint</span></div><div class="line">examples: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">6</span>] at map at <span class="type">MLUtils</span>.scala:<span class="number">108</span></div></pre></td></tr></table></figure></p>
<p>这里，sc是Spark-shell自动建立的SparkContext。我们可以查看下加载进来的标注点的值：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; examples.collect().head</div><div class="line">res7: org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span> = (<span class="number">0.0</span>,(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129</span>,<span class="number">130</span>,<span class="number">131</span>,<span class="number">154</span>,<span class="number">155</span>,<span class="number">156</span>,<span class="number">157</span>,<span class="number">158</span>,<span class="number">159</span>,<span class="number">181</span>,<span class="number">182</span>,<span class="number">183</span>,<span class="number">184</span>,<span class="number">185</span>,<span class="number">186</span>,<span class="number">187</span>,<span class="number">188</span>,<span class="number">189</span>,<span class="number">207</span>,<span class="number">208</span>,<span class="number">209</span>,<span class="number">210</span>,<span class="number">211</span>,<span class="number">212</span>,<span class="number">213</span>,<span class="number">214</span>,<span class="number">215</span>,<span class="number">216</span>,<span class="number">217</span>,<span class="number">235</span>,<span class="number">236</span>,<span class="number">237</span>,<span class="number">238</span>,<span class="number">239</span>,<span class="number">240</span>,<span class="number">241</span>,<span class="number">242</span>,<span class="number">243</span>,<span class="number">244</span>,<span class="number">245</span>,<span class="number">262</span>,<span class="number">263</span>,<span class="number">264</span>,<span class="number">265</span>,<span class="number">266</span>,<span class="number">267</span>,<span class="number">268</span>,<span class="number">269</span>,<span class="number">270</span>,<span class="number">271</span>,<span class="number">272</span>,<span class="number">273</span>,<span class="number">289</span>,<span class="number">290</span>,<span class="number">291</span>,<span class="number">292</span>,<span class="number">293</span>,<span class="number">294</span>,<span class="number">295</span>,<span class="number">296</span>,<span class="number">297</span>,<span class="number">300</span>,<span class="number">301</span>,<span class="number">302</span>,<span class="number">316</span>,<span class="number">317</span>,<span class="number">318</span>,<span class="number">319</span>,<span class="number">320</span>,<span class="number">321</span>,<span class="number">328</span>,<span class="number">329</span>,<span class="number">330</span>,<span class="number">343</span>,<span class="number">344</span>,<span class="number">345</span>,<span class="number">346</span>,<span class="number">347</span>,<span class="number">348</span>,<span class="number">349</span>,<span class="number">356</span>,<span class="number">357</span>,<span class="number">358</span>,<span class="number">371</span>,<span class="number">372</span>,<span class="number">373</span>,<span class="number">374</span>,<span class="number">384</span>,<span class="number">385</span>,<span class="number">386</span>,<span class="number">399</span>,<span class="number">400</span>,<span class="number">401</span>,<span class="number">412</span>,<span class="number">413</span>,<span class="number">414</span>,<span class="number">426</span>,<span class="number">427</span>,<span class="number">428</span>,<span class="number">429</span>,<span class="number">440</span>,<span class="number">441</span>,<span class="number">442</span>,<span class="number">454</span>,<span class="number">455</span>,<span class="number">456</span>,<span class="number">457</span>,<span class="number">466</span>,<span class="number">467</span>,<span class="number">468</span>,<span class="number">469</span>,<span class="number">470</span>,<span class="number">482</span>,<span class="number">483</span>,<span class="number">484</span>,<span class="number">493</span>,<span class="number">494</span>,<span class="number">495</span>,<span class="number">496</span>,<span class="number">497</span>,<span class="number">510</span>,<span class="number">511</span>,<span class="number">512</span>,<span class="number">520</span>,<span class="number">521</span>,<span class="number">522</span>,<span class="number">523</span>,<span class="number">538</span>,<span class="number">539</span>,<span class="number">540</span>,<span class="number">547</span>,<span class="number">548</span>,<span class="number">549</span>,<span class="number">550</span>,<span class="number">566</span>,<span class="number">567</span>,<span class="number">568</span>,<span class="number">569</span>,<span class="number">570</span>,<span class="number">571</span>,<span class="number">572</span>,<span class="number">573</span>,<span class="number">574</span>,<span class="number">575</span>,<span class="number">576</span>,<span class="number">577</span>,<span class="number">578</span>,<span class="number">594</span>,<span class="number">595</span>,<span class="number">596</span>,<span class="number">597</span>,<span class="number">598</span>,<span class="number">599</span>,<span class="number">600</span>,<span class="number">601</span>,<span class="number">602</span>,<span class="number">603</span>,<span class="number">604</span>,<span class="number">622</span>,<span class="number">623</span>,<span class="number">624</span>,<span class="number">625</span>,<span class="number">626</span>,<span class="number">627</span>,<span class="number">628</span>,<span class="number">629</span>,<span class="number">630</span>,<span class="number">651</span>,<span class="number">652</span>,<span class="number">653</span>,<span class="number">654</span>,<span class="number">655</span>,<span class="number">656</span>,<span class="number">657</span>],[<span class="number">51.0</span>,<span class="number">159.0</span>,<span class="number">253.0</span>,<span class="number">159.0</span>,<span class="number">50.</span>..</div></pre></td></tr></table></figure></p>
<p>这里，examples.collect()把rdd转换为了向量，并取第一个元素的值。每个标注点共有692个维，其中第127列对应的值是51.0，第128列对应的值是159.0，依此类推。</p>
<div class="note success"><h2 id="本地矩阵（Local-Matrix）"><a href="#本地矩阵（Local-Matrix）" class="headerlink" title="本地矩阵（Local Matrix）"></a>本地矩阵（Local Matrix）</h2></div>
<p><strong>本地矩阵</strong>具有整型的行、列索引值和双精度浮点型的元素值，它存储在单机上。MLlib支持<strong>稠密矩阵</strong>DenseMatrix和<strong>稀疏矩阵</strong>Sparse Matrix两种本地矩阵，稠密矩阵将所有元素的值存储在一个列优先（Column-major）的双精度型数组中，而稀疏矩阵则将非零元素以列优先的CSC（Compressed Sparse Column）模式进行存储，关于CSC等稀疏矩阵存储方式的具体实现，可以参看<a href="http://www.cs.colostate.edu/~mcrob/toolbox/c++/sparseMatrix/sparse_matrix_compression.html" target="_blank" rel="external">Sparse Matrix Compression Formats</a>一文。</p>
<p>本地矩阵的基类是org.apache.spark.mllib.linalg.Matrix，DenseMatrix和SparseMatrix均是它的实现类，和本地向量类似，MLlib也为本地矩阵提供了相应的工具类Matrices，调用工厂方法即可创建实例：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">scala&gt;<span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Matrix</span>, <span class="type">Matrices</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.&#123;<span class="type">Matrix</span>, <span class="type">Matrices</span>&#125;</div><div class="line"><span class="comment">// 创建一个3行2列的稠密矩阵[ [1.0,2.0], [3.0,4.0], [5.0,6.0] ]</span></div><div class="line"><span class="comment">// 请注意，这里的数组参数是列先序的！</span></div><div class="line">scala&gt; <span class="keyword">val</span> dm: <span class="type">Matrix</span> = <span class="type">Matrices</span>.dense(<span class="number">3</span>, <span class="number">2</span>, <span class="type">Array</span>(<span class="number">1.0</span>, <span class="number">3.0</span>, <span class="number">5.0</span>, <span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">6.0</span>))</div><div class="line">dm: org.apache.spark.mllib.linalg.<span class="type">Matrix</span> =</div><div class="line"><span class="number">1.0</span>  <span class="number">2.0</span></div><div class="line"><span class="number">3.0</span>  <span class="number">4.0</span></div><div class="line"><span class="number">5.0</span>  <span class="number">6.0</span></div></pre></td></tr></table></figure></p>
<p>这里可以看出列优先的排列方式，即按照列的方式从数组中提取元素。也可以创建稀疏矩阵：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 创建一个3行2列的稀疏矩阵[ [9.0,0.0], [0.0,8.0], [0.0,6.0]]</span></div><div class="line"><span class="comment">// 第一个数组参数表示列指针，即每一列元素的开始索引值</span></div><div class="line"><span class="comment">// 第二个数组参数表示行索引，即对应的元素是属于哪一行</span></div><div class="line"><span class="comment">// 第三个数组即是按列先序排列的所有非零元素，通过列指针和行索引即可判断每个元素所在的位置</span></div><div class="line">scala&gt; <span class="keyword">val</span> sm: <span class="type">Matrix</span> = <span class="type">Matrices</span>.sparse(<span class="number">3</span>, <span class="number">2</span>, <span class="type">Array</span>(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>), <span class="type">Array</span>(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>), <span class="type">Array</span>(<span class="number">9</span>, <span class="number">6</span>, <span class="number">8</span>))</div><div class="line">sm: org.apache.spark.mllib.linalg.<span class="type">Matrix</span> =</div><div class="line"><span class="number">3</span> x <span class="number">2</span> <span class="type">CSCMatrix</span></div><div class="line">(<span class="number">0</span>,<span class="number">0</span>) <span class="number">9.0</span></div><div class="line">(<span class="number">2</span>,<span class="number">1</span>) <span class="number">6.0</span></div><div class="line">(<span class="number">1</span>,<span class="number">1</span>) <span class="number">8.0</span></div></pre></td></tr></table></figure></p>
<p>这里，创建一个3行2列的稀疏矩阵[ [9.0,0.0], [0.0,8.0], [0.0,6.0]]。Matrices.sparse的参数中，3表示行数，2表示列数。第1个数组参数表示列指针，即每一列元素的开始索引值， 第二个数组参数表示行索引，即对应的元素是属于哪一行；第三个数组即是按列先序排列的所有非零元素，通过列指针和行索引即可判断每个元素所在的位置。比如取每个数组的第2个元素为2,1,6，表示第2列第1行的元素值是6.0。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第六章 第一节 Spark - MLib简介]]></title>
      <url>http://Melodylican.github.io/2017/04/15/Spark-MLib%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<div class="note success"><h2 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h2></div>
<p>机器学习可以看做是一门人工智能的科学，该领域的主要研究对象是人工智能。机器学习利用数据或以往的经验，以此优化计算机程序的性能标准。一种经常引用的英文定义是：</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E。</p>
</blockquote>
<p><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/ML.jpg" alt=""><br>机器学习<br></center><br><a id="more"></a><br>机器学习强调三个关键词：算法、经验、性能，其处理过程如上图所示。在数据的基础上，通过算法构建出模型并对模型进行评估。评估的性能如果达到要求，就用该模型来测试其他的数据；如果达不到要求，就要调整算法来重新建立模型，再次进行评估。如此循环往复，最终获得满意的经验来处理其他的数据。机器学习技术和方法已经被成功应用到多个领域，比如个性推荐系统，金融反欺诈，语音识别，自然语言处理和机器翻译，模式识别，智能控制等。</p>
<div class="note success"><h2 id="基于大数据的机器学习"><a href="#基于大数据的机器学习" class="headerlink" title="基于大数据的机器学习"></a>基于大数据的机器学习</h2></div>
<p>传统的机器学习算法，由于技术和单机存储的限制，只能在少量数据上使用。即以前的统计/机器学习依赖于数据抽样。但实际过程中样本往往很难做好随机，导致学习的模型不是很准确，在测试数据上的效果也可能不太好。随着 HDFS(Hadoop Distributed File System) 等分布式文件系统出现，存储海量数据已经成为可能。在全量数据上进行机器学习也成为了可能，这顺便也解决了统计随机性的问题。然而，由于 MapReduce 自身的限制，使得使用 MapReduce 来实现分布式机器学习算法非常耗时和消耗磁盘IO。因为通常情况下机器学习算法参数学习的过程都是迭代计算的，即本次计算的结果要作为下一次迭代的输入，这个过程中，如果使用 MapReduce，我们只能把中间结果存储磁盘，然后在下一次计算的时候从新读取，这对于迭代 频发的算法显然是致命的性能瓶颈。</p>
<p>在大数据上进行机器学习，需要处理全量数据并进行大量的迭代计算，这要求机器学习平台具备强大的处理能力。Spark 立足于内存计算，天然的适应于迭代式计算。即便如此，对于普通开发者来说，实现一个分布式机器学习算法仍然是一件极具挑战的事情。幸运的是，Spark提供了一个基于海量数据的机器学习库，它提供了常用机器学习算法的分布式实现，开发者只需要有 Spark 基础并且了解机器学习算法的原理，以及方法相关参数的含义，就可以轻松的通过调用相应的 API 来实现基于海量数据的机器学习过程。其次，Spark-Shell的即席查询也是一个关键。算法工程师可以边写代码边运行，边看结果。spark提供的各种高效的工具正使得机器学习过程更加直观便捷。比如通过sample函数，可以非常方便的进行抽样。当然，Spark发展到后面，拥有了实时批计算，批处理，算法库，SQL、流计算等模块等，基本可以看做是全平台的系统。把机器学习作为一个模块加入到Spark中，也是大势所趋。</p>
<div class="note success"><h2 id="Spark-机器学习库MLLib"><a href="#Spark-机器学习库MLLib" class="headerlink" title="Spark 机器学习库MLLib"></a>Spark 机器学习库MLLib</h2></div>
<p>MLlib是Spark的机器学习（Machine Learning）库，旨在简化机器学习的工程实践工作，并方便扩展到更大规模。MLlib由一些通用的学习算法和工具组成，包括分类、回归、聚类、协同过滤、降维等，同时还包括底层的优化原语和高层的管道API。具体来说，其主要包括以下几方面的内容：</p>
<p>算法工具：常用的学习算法，如分类、回归、聚类和协同过滤；<br>特征化工具：特征提取、转化、降维，和选择工具；<br>管道(Pipeline)：用于构建、评估和调整机器学习管道的工具;<br>持久性：保存和加载算法，模型和管道;<br>实用工具：线性代数，统计，数据处理等工具。<br>Spark 机器学习库从 1.2 版本以后被分为两个包：</p>
<p>spark.mllib 包含基于RDD的原始算法API。Spark MLlib 历史比较长，在1.0 以前的版本即已经包含了，提供的算法实现都是基于原始的 RDD。<br>spark.ml 则提供了基于DataFrames 高层次的API，可以用来构建机器学习工作流（PipeLine）。ML Pipeline 弥补了原始 MLlib 库的不足，向用户提供了一个基于 DataFrame 的机器学习工作流式 API 套件。<br>使用 ML Pipeline API可以很方便的把数据处理，特征转换，正则化，以及多个机器学习算法联合起来，构建一个单一完整的机器学习流水线。这种方式给我们提供了更灵活的方法，更符合机器学习过程的特点，也更容易从其他语言迁移。Spark官方推荐使用spark.ml。如果新的算法能够适用于机器学习管道的概念，就应该将其放到spark.ml包中，如：特征提取器和转换器。开发者需要注意的是，从Spark2.0开始，基于RDD的API进入维护模式（即不增加任何新的特性），并预期于3.0版本的时候被移除出MLLib。</p>
<p>Spark在机器学习方面的发展非常快，目前已经支持了主流的统计和机器学习算法。纵观所有基于分布式架构的开源机器学习库，MLlib可以算是计算效率最高的。MLlib目前支持4种常见的机器学习问题: 分类、回归、聚类和协同过滤。下表列出了目前MLlib支持的主要的机器学习算法：</p>
<p><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/12/MLTable.png" alt=""><br></center><br>在接下来的几个章节里，我们将从基本的机器学习算法入手，循序渐进的来学习Spark平台下的机器学习。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Http常见状态码]]></title>
      <url>http://Melodylican.github.io/2017/03/28/Http%E5%B8%B8%E8%A7%81%E7%8A%B6%E6%80%81%E7%A0%81/</url>
      <content type="html"><![CDATA[<h2 id="Http常见状态码"><a href="#Http常见状态码" class="headerlink" title="Http常见状态码"></a>Http常见状态码</h2><h3 id="HTTP状态码-HTTP-Status-Code"><a href="#HTTP状态码-HTTP-Status-Code" class="headerlink" title="HTTP状态码(HTTP Status Code)"></a>HTTP状态码(HTTP Status Code)</h3><p>　　一些常见的状态码为：</p>
<h4 id="1xx-临时响应-表示临时响应并需要请求者继续执行操作的状态代码。代码-说明"><a href="#1xx-临时响应-表示临时响应并需要请求者继续执行操作的状态代码。代码-说明" class="headerlink" title="1xx(临时响应)表示临时响应并需要请求者继续执行操作的状态代码。代码 说明"></a>1xx(临时响应)表示临时响应并需要请求者继续执行操作的状态代码。代码 说明</h4><a id="more"></a>
<p>　　100 (继续) 请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。<br>　　101 (切换协议) 请求者已要求服务器切换协议，服务器已确认并准备切换。</p>
<h4 id="2xx-成功-表示成功处理了请求的状态代码。代码-说明"><a href="#2xx-成功-表示成功处理了请求的状态代码。代码-说明" class="headerlink" title="2xx (成功)表示成功处理了请求的状态代码。代码 说明"></a>2xx (成功)表示成功处理了请求的状态代码。代码 说明</h4><p>　　200 (成功) 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。<br>　　201 (已创建) 请求成功并且服务器创建了新的资源。<br>　　202 (已接受) 服务器已接受请求，但尚未处理。<br>　　203 (非授权信息) 服务器已成功处理了请求，但返回的信息可能来自另一来源。<br>　　204 (无内容) 服务器成功处理了请求，但没有返回任何内容。<br>　　205 (重置内容) 服务器成功处理了请求，但没有返回任何内容。<br>　　206 (部分内容) 服务器成功处理了部分 GET 请求。</p>
<h4 id="3xx-重定向-表示要完成请求，需要进一步操作。-通常，这些状态代码用来重定向。代码说明"><a href="#3xx-重定向-表示要完成请求，需要进一步操作。-通常，这些状态代码用来重定向。代码说明" class="headerlink" title="3xx (重定向) 表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。代码说明"></a>3xx (重定向) 表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。代码说明</h4><p>　　300 (多种选择) 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。<br>　　301 (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。<br>　　302 (临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。<br>　　303 (查看其他位置) 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。<br>　　304 (未修改) 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。<br>　　305 (使用代理) 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。<br>　　307 (临时重定向) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。</p>
<h4 id="4xx-请求错误-这些状态代码表示请求可能出错，妨碍了服务器的处理。代码-说明"><a href="#4xx-请求错误-这些状态代码表示请求可能出错，妨碍了服务器的处理。代码-说明" class="headerlink" title="4xx(请求错误) 这些状态代码表示请求可能出错，妨碍了服务器的处理。代码 说明"></a>4xx(请求错误) 这些状态代码表示请求可能出错，妨碍了服务器的处理。代码 说明</h4><p>　　400 (错误请求) 服务器不理解请求的语法。<br>　　401 (未授权) 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。<br>　　403 (禁止) 服务器拒绝请求。<br>　　404 (未找到) 服务器找不到请求的网页。<br>　　405 (方法禁用) 禁用请求中指定的方法。<br>　　406 (不接受) 无法使用请求的内容特性响应请求的网页。<br>　　407 (需要代理授权) 此状态代码与 401(未授权)类似，但指定请求者应当授权使用代理。<br>　　408 (请求超时) 服务器等候请求时发生超时。<br>　　409 (冲突) 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。<br>　　410 (已删除) 如果请求的资源已永久删除，服务器就会返回此响应。<br>　　411 (需要有效长度) 服务器不接受不含有效内容长度标头字段的请求。<br>　　412 (未满足前提条件) 服务器未满足请求者在请求中设置的其中一个前提条件。<br>　　413 (请求实体过大) 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。<br>　　414 (请求的 URI 过长) 请求的 URI(通常为网址)过长，服务器无法处理。<br>　　415 (不支持的媒体类型) 请求的格式不受请求页面的支持。<br>　　416 (请求范围不符合要求) 如果页面无法提供请求的范围，则服务器会返回此状态代码。<br>　　417 (未满足期望值) 服务器未满足”期望”请求标头字段的要求。</p>
<h4 id="5xx-服务器错误-这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。代码-说明"><a href="#5xx-服务器错误-这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。代码-说明" class="headerlink" title="5xx(服务器错误)这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。代码 说明"></a>5xx(服务器错误)这些状态代码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。代码 说明</h4><p>　　500 (服务器内部错误) 服务器遇到错误，无法完成请求。<br>　　501 (尚未实施) 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。<br>　　502 (错误网关) 服务器作为网关或代理，从上游服务器收到无效响应。<br>　　503 (服务不可用) 服务器目前无法使用(由于超载或停机维护)。 通常，这只是暂时状态。<br>　　504 (网关超时) 服务器作为网关或代理，但是没有及时从上游服务器收到请求。<br>　　505 (HTTP 版本不受支持) 服务器不支持请求中所用的 HTTP 协议版本。</p>
]]></content>
      
        <categories>
            
            <category> Http </category>
            
        </categories>
        
        
        <tags>
            
            <tag> http状态码 </tag>
            
            <tag> java网络编程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[西红柿鸡蛋面]]></title>
      <url>http://Melodylican.github.io/2017/03/25/%E7%95%AA%E8%8C%84%E9%B8%A1%E8%9B%8B%E9%9D%A2/</url>
      <content type="html"><![CDATA[<h2 id="鸡蛋面做法小计"><a href="#鸡蛋面做法小计" class="headerlink" title="鸡蛋面做法小计"></a>鸡蛋面做法小计</h2><p>今天天气阴沉沉的，但丝毫没有影响到我的心情，因为从某东上买的铁锅到了，于是马不停蹄地跑到附近的菜市场买了点生猪肉准备炼锅（炼锅教程可查看我的另一篇博客）。<br>炼完锅后于是就准备做一个番茄鸡蛋面来打打牙祭。因为，之前吃过女友做的，味道的确很好，于是这次准备亲自下厨，尝尝自己的手艺。接下来就把自己做的过程记录一下。<br><a id="more"></a><br>西红柿鸡蛋面<br> 材料：<br>     挂面、西红柿、鸡蛋、盐、食用油、姜片、香葱<br> 做法：<br>     1、一个西红柿洗净去皮切片，两个鸡蛋捣碎，蛋液里加盐，一块老姜片切碎；<br>     2、锅内放油，油热将蛋液倒入炒成蛋花，盛出；<br>     3、另放油，油热爆香姜碎，将西红柿倒入翻炒，待西红柿出水了将蛋花倒入同炒一会（可以加一点点白砂糖，如果你嫌西红柿味太酸的话，但是只加一点点）；<br>     4、然后加水煮入味（水可以比做汤的时候稍多一些）。大概可以煮上五分钟吧<br>     5、放入挂面继续煮个3分钟左右即可开锅了，开锅后撒上点切好的香葱叶，香喷喷~~</p>
<h3 id="食材准备"><a href="#食材准备" class="headerlink" title="食材准备"></a>食材准备</h3><p> <img src="http://ojwkevhas.bkt.clouddn.com/egg1.JPG" width="50%" height="50%" alt="番茄鸡蛋面" align="center"></p>
<h3 id="煎鸡蛋"><a href="#煎鸡蛋" class="headerlink" title="煎鸡蛋"></a>煎鸡蛋</h3><p> <img src="http://ojwkevhas.bkt.clouddn.com/egg2.JPG" width="50%" height="50%" alt="番茄鸡蛋面" align="center"></p>
<h3 id="煮面"><a href="#煮面" class="headerlink" title="煮面"></a>煮面</h3><p> <img src="http://ojwkevhas.bkt.clouddn.com/egg3.JPG" width="50%" height="50%" alt="番茄鸡蛋面" align="center"></p>
<h3 id="成品"><a href="#成品" class="headerlink" title="成品"></a>成品</h3><p> <img src="http://ojwkevhas.bkt.clouddn.com/egg4.JPG" width="50%" height="50%" alt="番茄鸡蛋面" align="center"></p>
]]></content>
      
        <categories>
            
            <category> 生活杂记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 鸡蛋面 </tag>
            
            <tag> 番茄 </tag>
            
            <tag> 鸡蛋 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第五章 第四节 Spark - Spark 文件流（Dstream）]]></title>
      <url>http://Melodylican.github.io/2017/03/22/Spark%E6%96%87%E4%BB%B6%E6%B5%81/</url>
      <content type="html"><![CDATA[<p>Spark支持从兼容HDFS API的文件系统中读取数据，创建数据流。<br><a id="more"></a><br>为了能够演示文件流的创建，我们需要首先创建一个日志目录，并在里面放置两个模拟的日志文件。请在Linux系统中打开另一个终端，进入Shell命令提示符状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode</div><div class="line">mkdir streaming</div><div class="line">cd streaming</div><div class="line">mkdir logfile</div><div class="line">cd logfile</div></pre></td></tr></table></figure></p>
<p>然后，在logfile中新建两个日志文件log1.txt和log2.txt，里面可以随便输入一些内容。<br>比如，我们在log1.txt中输入以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">I love Hadoop</div><div class="line">I love Spark</div><div class="line">Spark is fast</div></pre></td></tr></table></figure></p>
<p>下面我们就进入spark-shell创建文件流。请另外打开一个终端窗口，启动进入spark-shell。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.streaming._</div><div class="line">scala&gt; <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">20</span>))</div><div class="line">scala&gt; <span class="keyword">val</span> lines = ssc.textFileStream(<span class="string">"file:///usr/local/spark/mycode/streaming/logfile"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</div><div class="line">scala&gt; <span class="keyword">val</span> wordCounts = words.map(x =&gt; (x, <span class="number">1</span>)).reduceByKey(_ + _) </div><div class="line">scala&gt; wordCounts.print()  </div><div class="line">scala&gt; ssc.start()  <span class="comment">//实际上，当你输入这行回车后，Spark Streaming就开始进行循环监听，下面的ssc.awaitTermination()是无法输入到屏幕上的，但是，为了程序完整性，这里还是给出ssc.awaitTermination()</span></div><div class="line">scala&gt; ssc.awaitTermination()</div></pre></td></tr></table></figure></p>
<p>所以，上面在spark-shell中执行的程序，一旦你输入ssc.start()以后，程序就开始自动进入循环监听状态，屏幕上会显示一堆的信息，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//这里省略若干屏幕信息</span></div><div class="line">-------------------------------------------</div><div class="line"><span class="type">Time</span>: <span class="number">1479431100000</span> ms</div><div class="line">-------------------------------------------</div><div class="line"><span class="comment">//这里省略若干屏幕信息</span></div><div class="line">-------------------------------------------</div><div class="line"><span class="type">Time</span>: <span class="number">1479431120000</span> ms</div><div class="line">-------------------------------------------</div><div class="line"><span class="comment">//这里省略若干屏幕信息</span></div><div class="line">-------------------------------------------</div><div class="line"><span class="type">Time</span>: <span class="number">1479431140000</span> ms</div><div class="line">-------------------------------------------</div></pre></td></tr></table></figure></p>
<p>从上面的屏幕显示信息可以看出，Spark Streaming每隔20秒就监听一次。但是，你这时会感到奇怪，既然启动监听了，为什么程序没有把我们刚才放置在”/usr/local/spark/mycode/streaming/logfile”目录下的log1.txt和log2.txt这两个文件中的内容读取出来呢？原因是，监听程序只监听”/usr/local/spark/mycode/streaming/logfile”目录下在程序启动后新增的文件，不会去处理历史上已经存在的文件。所以，为了能够让程序读取文件内容并显示到屏幕上，让我们能够看到效果，这时，我们需要到”/usr/local/spark/mycode/streaming/logfile”目录下再新建一个log3.txt文件，请打开另外一个终端窗口（我们称为shell窗口），当前正在执行监听工作的spark-shell窗口依然保留。请在shell窗口中执行Linux操作，在”/usr/local/spark/mycode/streaming/logfile”目录下再新建一个log3.txt文件，里面随便输入一些英文单词，创建完成以后，再切换回到spark-shell窗口。请等待20秒（因为我们刚才设置的是每隔20秒就监听一次，如果你创建文件动作很快，可能20秒还没到）。现在你会发现屏幕上不断输出新的信息，导致你无法看清楚单词统计结果是否已经被打印到屏幕上。所以，你现在必须停止这个监听程序，否则它一直在spark-shell窗口中不断循环监听，停止的方法是，按键盘Ctrl+D，或者Ctrl+C。停止以后，就彻底停止，并且退出了spark-shell状态，回到了Shell命令提示符状态。然后，你就可以看到屏幕上，在一大堆输出信息中，你可以找到打印出来的单词统计信息。</p>
<p>好了，上面我们是在spark-shell中直接执行代码，但是，很多时候，我们需要编写独立应用程序进行监听，所以，下面我们介绍如何采用独立应用程序的方式实现上述监听文件夹的功能。<br>我们采用scala语言编写程序，而且要采用sbt打包编译，因此，必须符合sbt打包的规范（<a href="http://dblab.xmu.edu.cn/blog/986-2/" target="_blank" rel="external">可以点击这里参考前面章节内容复习一下如何使用sbt打包编译scala程序</a>）。当然，不复习以前的知识，直接按照我们下面的步骤来，你也可以顺利实现sbt打包编译。<br>请打开一个Linux终端窗口，进入shell命令提示符状态，然后，执行下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode</div><div class="line">mkdir streaming</div><div class="line">cd streaming</div><div class="line">mkdir -p src/main/scala</div><div class="line">cd src/main/scala</div><div class="line">vim TestStreaming.scala</div></pre></td></tr></table></figure></p>
<p>这样就用vim编辑器新建一个TestStreaming.scala代码文件，请在里面输入以下代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark._ </div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming._</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCountStreaming</span> </span>&#123;  </div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;  </div><div class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"WordCountStreaming"</span>).setMaster(<span class="string">"local[2]"</span>)<span class="comment">//设置为本地运行模式，2个线程，一个监听，另一个处理数据    </span></div><div class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">20</span>))<span class="comment">// 时间间隔为20秒    </span></div><div class="line">    <span class="keyword">val</span> lines = ssc.textFileStream(<span class="string">"file:///usr/local/spark/mycode/streaming/logfile"</span>)  <span class="comment">//这里采用本地文件，当然你也可以采用HDFS文件</span></div><div class="line">    <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))  </div><div class="line">    <span class="keyword">val</span> wordCounts = words.map(x =&gt; (x, <span class="number">1</span>)).reduceByKey(_ + _)  </div><div class="line">    wordCounts.print()  </div><div class="line">    ssc.start()  </div><div class="line">    ssc.awaitTermination()  </div><div class="line">  &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>代码文件写好后，就可以保存并退出vim编辑器。然后，执行下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/streaming</div><div class="line">vim simple.sbt //注意，是simple.sbt，不是simple.txt</div></pre></td></tr></table></figure></p>
<p>打开vim编辑器以后，在simple.sbt文件中输入以下代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">name := &quot;Simple Project&quot;</div><div class="line">version := &quot;1.0&quot;</div><div class="line">scalaVersion := &quot;2.11.8&quot;</div><div class="line">libraryDependencies += &quot;org.apache.spark&quot; % &quot;spark-streaming_2.11&quot; % &quot;2.1.0&quot;</div></pre></td></tr></table></figure></p>
<p>创建好simple.sbt文件后，退出vim编辑器。然后，执行下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/streaming</div><div class="line">find .</div></pre></td></tr></table></figure></p>
<p>屏幕上返回的信息，应该是类似下面的文件结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">./src</div><div class="line">./src/main</div><div class="line">./src/main/scala</div><div class="line">./src/main/scala/TestStreaming.scala</div><div class="line">./simple.sbt</div></pre></td></tr></table></figure></p>
<p>然后，就可以执行sbt打包编译了，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/streaming</div><div class="line">/usr/local/sbt/sbt package</div></pre></td></tr></table></figure></p>
<p>打包成功以后，就可以输入以下命令启动这个程序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/streaming</div><div class="line">/usr/local/spark/bin/spark-submit --class &quot;WordCountStreaming&quot; /usr/local/spark/mycode/streaming/target/scala-2.11/simple-project_2.11-1.0.jar</div></pre></td></tr></table></figure></p>
<p>执行上面命令后，就进入了监听状态（我们把运行这个监听程序的窗口称为监听窗口），这时，你就可以像刚才一样，切换到另外一个Shell窗口，在”/usr/local/spark/mycode/streaming/logfile”目录下再新建一个log5.txt文件，文件里面随便输入一些单词，保存好文件退出vim编辑器。然后，再次切换回“监听窗口”，等待20秒以后，按键盘Ctrl+C或者Ctrl+D停止监听程序，就可以看到监听窗口的屏幕上会打印出单词统计信息。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第五章 第三节 Spark - Spark Dstream操作]]></title>
      <url>http://Melodylican.github.io/2017/03/20/SparkDStream%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>DStream是Spark Streaming的编程模型，DStream的操作包括输入、转换和输出。<br><a id="more"></a><br><div class="note success"><h2 id="Spark-Streaming工作原理"><a href="#Spark-Streaming工作原理" class="headerlink" title="Spark Streaming工作原理"></a>Spark Streaming工作原理</h2></div><br>前面在《Spark运行架构》部分，我们已经介绍过，在Spark中，一个应用（Application）由一个任务控制节点（Driver）和若干个作业（Job）构成，一个作业由多个阶段（Stage）构成，一个阶段由多个任务（Task）组成。当执行一个应用时，任务控制节点会向集群管理器（Cluster Manager）申请资源，启动Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行task。在Spark Streaming中，会有一个组件Receiver，作为一个长期运行的task跑在一个Executor上。每个Receiver都会负责一个input DStream（比如从文件中读取数据的文件流，比如套接字流，或者从Kafka中读取的一个输入流等等）。Spark Streaming通过input DStream与外部数据源进行连接，读取相关数据。<br><div class="note success"><h2 id="Spark-Streaming程序基本步骤"><a href="#Spark-Streaming程序基本步骤" class="headerlink" title="Spark Streaming程序基本步骤"></a>Spark Streaming程序基本步骤</h2></div><br>编写Spark Streaming程序的基本步骤是：<br>1.通过创建输入DStream来定义输入源<br>2.通过对DStream应用转换操作和输出操作来定义流计算。<br>3.用streamingContext.start()来开始接收数据和处理流程。<br>4.通过streamingContext.awaitTermination()方法来等待处理结束（手动结束或因为错误而结束）。<br>5.可以通过streamingContext.stop()来手动结束流计算进程。<br><div class="note success"><h2 id="创建StreamingContext对象"><a href="#创建StreamingContext对象" class="headerlink" title="创建StreamingContext对象"></a>创建StreamingContext对象</h2></div><br>如果要运行一个Spark Streaming程序，就需要首先生成一个StreamingContext对象，它是Spark Streaming程序的主入口。因此，在定义输入之前，我们首先介绍如何创建StreamingContext对象。我们可以从一个SparkConf对象创建一个StreamingContext对象。<br>请登录Linux系统，启动spark-shell。进入spark-shell以后，就已经获得了一个默认的SparkConext，也就是sc。因此，可以采用如下方式来创建StreamingContext对象：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.streaming._</div><div class="line">scala&gt; <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">1</span>))</div></pre></td></tr></table></figure></p>
<p>Seconds(1)表示每隔1秒钟就自动执行一次流计算，这个秒数可以自由设定。<br>如果是编写一个独立的Spark Streaming程序，而不是在spark-shell中运行，则需要通过如下方式创建StreamingContext对象：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark._</div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming._</div><div class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"TestDStream"</span>).setMaster(<span class="string">"local[2]"</span>)</div><div class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">1</span>))</div><div class="line">setAppName(<span class="string">"TestDStream"</span>)是用来设置应用程序名称，这里我们取名为“<span class="type">TestDStream</span>”。setMaster(<span class="string">"local[2]"</span>)括号里的参数<span class="string">"local[2]'字符串表示运行在本地模式下，并且启动2个工作线程</span></div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Spark Stream </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第五章 第二节 Spark - Spark Sreaming简介]]></title>
      <url>http://Melodylican.github.io/2017/03/19/SparkStreaming%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>Spark Streaming是构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。Spark Streaming可结合批处理和交互查询，适合一些需要对历史数据和实时数据进行结合分析的应用场景。<br><a id="more"></a><br><div class="note success"><h2 id="Spark-Streaming设计"><a href="#Spark-Streaming设计" class="headerlink" title="Spark Streaming设计"></a>Spark Streaming设计</h2></div><br>Spark Streaming是Spark的核心组件之一，为Spark提供了可拓展、高吞吐、容错的流计算能力。如下图所示，Spark Streaming可整合多种输入数据源，如Kafka、Flume、HDFS，甚至是普通的TCP套接字。经处理后的数据可存储至文件系统、数据库，或显示在仪表盘里。</p>
<center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE10-19-Spark-Streaming%E6%94%AF%E6%8C%81%E7%9A%84%E8%BE%93%E5%85%A5%E3%80%81%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE%E6%BA%90.jpg" alt=""><br>图 Spark-Streaming支持的输入、输出数据源<br></center>

<p>Spark Streaming的基本原理是将实时输入数据流以时间片（秒级）为单位进行拆分，然后经Spark引擎以类似批处理的方式处理每个时间片数据，执行流程如下图所示。</p>
<p><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE10-20-Spark-Streaming%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.jpg" alt=""><br>图 Spark Streaming执行流程<br></center><br>Spark Streaming最主要的抽象是DStream（Discretized Stream，离散化数据流），表示连续不断的数据流。在内部实现上，Spark Streaming的输入数据按照时间片（如1秒）分成一段一段的DStream，每一段数据转换为Spark中的RDD，并且对DStream的操作都最终转变为对相应的RDD的操作。例如，下图展示了进行单词统计时，每个时间片的数据（存储句子的RDD）经flatMap操作，生成了存储单词的RDD。整个流式计算可根据业务的需求对这些中间的结果进一步处理，或者存储到外部设备中。</p>
<p><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE10-21-DStream%E6%93%8D%E4%BD%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt=""><br>图 DStream操作示意图<br></center><br><div class="note success"><h2 id="Spark-Streaming与Storm的对比"><a href="#Spark-Streaming与Storm的对比" class="headerlink" title="Spark Streaming与Storm的对比"></a>Spark Streaming与Storm的对比</h2></div><br>Spark Streaming和Storm最大的区别在于，Spark Streaming无法实现毫秒级的流计算，而Storm可以实现毫秒级响应。<br>Spark Streaming无法实现毫秒级的流计算，是因为其将流数据按批处理窗口大小（通常在0.5~2秒之间）分解为一系列批处理作业，在这个过程中，会产生多个Spark 作业，且每一段数据的处理都会经过Spark DAG图分解、任务调度过程，因此，无法实现毫秒级响应。Spark Streaming难以满足对实时性要求非常高（如高频实时交易）的场景，但足以胜任其他流式准实时计算场景。相比之下，Storm处理的单位为Tuple，只需要极小的延迟。<br>Spark Streaming构建在Spark上，一方面是因为Spark的低延迟执行引擎（100毫秒左右）可以用于实时计算，另一方面，相比于Storm，RDD数据集更容易做高效的容错处理。此外，Spark Streaming采用的小批量处理的方式使得它可以同时兼容批量和实时数据处理的逻辑和算法，因此，方便了一些需要历史数据和实时数据联合分析的特定应用场合。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第五章 第一节 Spark - Spark流计算简介]]></title>
      <url>http://Melodylican.github.io/2017/03/18/Spark%E6%B5%81%E8%AE%A1%E7%AE%97%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>数据总体上可以分为静态数据和流数据。对静态数据和流数据的处理，对应着两种截然不同的计算模式：批量计算和实时计算。批量计算以“静态数据”为对象，可以在很充裕的时间内对海量数据进行批量处理，计算得到有价值的信息。Hadoop就是典型的批处理模型，由HDFS和HBase存放大量的静态数据，由MapReduce负责对海量数据执行批量计算。流数据必须采用实时计算，实时计算最重要的一个需求是能够实时得到计算结果，一般要求响应时间为秒级。当只需要处理少量数据时，实时计算并不是问题；但是，在大数据时代，不仅数据格式复杂、来源众多，而且数据量巨大，这就对实时计算提出了很大的挑战。因此，针对流数据的实时计算——流计算，应运而生。<br><a id="more"></a><br>总的来说，流计算秉承一个基本理念，即数据的价值随着时间的流逝而降低。因此，当事件出现时就应该立即进行处理，而不是缓存起来进行批量处理。为了及时处理流数据，就需要一个低延迟、可扩展、高可靠的处理引擎。对于一个流计算系统来说，它应达到如下需求。</p>
<ul>
<li>• 高性能。处理大数据的基本要求，如每秒处理几十万条数据。</li>
<li>• 海量式。支持TB级甚至是PB级的数据规模。</li>
<li>• 实时性。必须保证一个较低的延迟时间，达到秒级别，甚至是毫秒级别。</li>
<li>• 分布式。支持大数据的基本架构，必须能够平滑扩展。</li>
<li>• 易用性。能够快速进行开发和部署。</li>
<li>• 可靠性。能可靠地处理流数据。<br><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE10-3-%E6%B5%81%E8%AE%A1%E7%AE%97%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt=""><br>图 流计算示意图<br></center><br>目前，市场上有很多流计算框架，比如Twitter Storm和Yahoo! S4等。Twitter Storm是免费、开源的分布式实时计算系统，可简单、高效、可靠地处理大量的流数据；Yahoo! S4开源流计算平台，是通用的、分布式的、可扩展的、分区容错的、可插拔的流式系统。</li>
</ul>
<p>流计算处理过程包括数据实时采集、数据实时计算和实时查询服务。</p>
<ul>
<li>数据实时采集：数据实时采集阶段通常采集多个数据源的海量数据，需要保证实时性、低延迟与稳定可靠。以日志数据为例，由于分布式集群的广泛应用，数据分散存储在不同的机器上，因此需要实时汇总来自不同机器上的日志数据。目前有许多互联网公司发布的开源分布式日志采集系统均可满足每秒数百MB的数据采集和传输需求，如Facebook的Scribe、LinkedIn的Kafka、淘宝的TimeTunnel，以及基于Hadoop的Chukwa和Flume等。</li>
</ul>
<p>数据实时计算：流处理系统接收数据采集系统不断发来的实时数据，实时地进行分析计算，并反馈实时结果。<br>实时查询服务：流计算的第三个阶段是实时查询服务，经由流计算框架得出的结果可供用户进行实时查询、展示或储存。</p>
<center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE10-5-%E6%B5%81%E8%AE%A1%E7%AE%97%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.jpg" alt=""><br>图 流计算的数据处理流程<br></center>


<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第七节 Spark - 读写Hive数据(DataFrame)]]></title>
      <url>http://Melodylican.github.io/2017/03/12/Spark%E8%AF%BB%E5%86%99Hive%E6%95%B0%E6%8D%AE/</url>
      <content type="html"><![CDATA[<div class="note success"><p>该节内容待补充完整</p>
</div>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第六节 Spark - 通过JDBC连接数据库(DataFrame)]]></title>
      <url>http://Melodylican.github.io/2017/03/12/Spark%E9%80%9A%E8%BF%87JDBC%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
      <content type="html"><![CDATA[<p>这里以关系数据库MySQL为例。首先，请参考厦门大学数据库实验室博客教程（Ubuntu安装MySQL），在Linux系统中安装好MySQL数据库。这里假设你已经成功安装了MySQL数据库。下面我们要新建一个测试Spark程序的数据库，数据库名称是“spark”，表的名称是“student”。<br><a id="more"></a><br>请执行下面命令在Linux中启动MySQL数据库，并完成数据库和表的创建，以及样例数据的录入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">service mysql start</div><div class="line">mysql -u root -p</div><div class="line">//屏幕会提示你输入密码</div></pre></td></tr></table></figure></p>
<p>输入密码后，你就可以进入“mysql&gt;”命令提示符状态，然后就可以输入下面的SQL语句完成数据库和表的创建：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">mysql&gt; create database spark;</div><div class="line">mysql&gt; use spark;</div><div class="line">mysql&gt; create table student (id int(4), name char(20), gender char(4), age int(4));</div><div class="line">mysql&gt; insert into student values(1,&apos;Xueqian&apos;,&apos;F&apos;,23);</div><div class="line">mysql&gt; insert into student values(2,&apos;Weiliang&apos;,&apos;M&apos;,24);</div><div class="line">mysql&gt; select * from student;</div></pre></td></tr></table></figure></p>
<p>上面已经创建好了我们所需要的MySQL数据库和表，下面我们编写Spark应用程序连接MySQL数据库并且读写数据。</p>
<p>Spark支持通过JDBC方式连接到其他数据库获取数据生成DataFrame。</p>
<p>首先，请进入Linux系统（本教程统一使用hadoop用户名登录），打开火狐（FireFox）浏览器，下载一个MySQL的JDBC驱动（下载）。在火狐浏览器中下载时，一般默认保存在hadoop用户的当前工作目录的“下载”目录下，所以，可以打开一个终端界面，输入下面命令查看：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~</div><div class="line">cd 下载</div></pre></td></tr></table></figure></p>
<p>就可以看到刚才下载到的MySQL的JDBC驱动程序，文件名称为mysql-connector-java-5.1.40.tar.gz（你下载的版本可能和这个不同）。现在，使用下面命令，把该驱动程序拷贝到spark的安装目录下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxf ~/下载/mysql-connector-java-5.1.40.tar.gz -C /usr/local/spark/jars</div><div class="line">cd /usr/local/spark/jars</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p>这时就可以在/usr/local/spark/jars目录下看到这个驱动程序文件所在的文件夹mysql-connector-java-5.1.40，进入这个文件夹，就可以看到驱动程序文件mysql-connector-java-5.1.40-bin.jar。<br>请输入下面命令启动已经安装在Linux系统中的mysql数据库（如果前面已经启动了MySQL数据库，这里就不用重复启动了）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">service mysql start</div></pre></td></tr></table></figure></p>
<p>下面，我们要启动一个spark-shell，而且启动的时候，要附加一些参数。启动Spark Shell时，必须指定mysql连接驱动jar包。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell \</div><div class="line">--jars /usr/local/spark/jars/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar \</div><div class="line">--driver-class-path /usr/local/spark/jars/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar</div></pre></td></tr></table></figure></p>
<p>上面的命令行中，在一行的末尾加入斜杠\，是为了告诉spark-shell，命令还没有结束。</p>
<p>启动进入spark-shell以后，可以执行以下命令连接数据库，读取数据，并显示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> jdbcDF = spark.read.format(<span class="string">"jdbc"</span>).option(<span class="string">"url"</span>, <span class="string">"jdbc:mysql://localhost:3306/spark"</span>).option(<span class="string">"driver"</span>,<span class="string">"com.mysql.jdbc.Driver"</span>).option(<span class="string">"dbtable"</span>, <span class="string">"student"</span>).option(<span class="string">"user"</span>, <span class="string">"root"</span>).option(<span class="string">"password"</span>, <span class="string">"hadoop"</span>).load()</div><div class="line"><span class="type">Fri</span> <span class="type">Dec</span> <span class="number">02</span> <span class="number">11</span>:<span class="number">56</span>:<span class="number">56</span> <span class="type">CST</span> <span class="number">2016</span> <span class="type">WARN</span>: <span class="type">Establishing</span> <span class="type">SSL</span> connection without server<span class="symbol">'s</span> identity verification is not recommended. <span class="type">According</span> to <span class="type">MySQL</span> <span class="number">5.5</span><span class="number">.45</span>+, <span class="number">5.6</span><span class="number">.26</span>+ and <span class="number">5.7</span><span class="number">.6</span>+ requirements <span class="type">SSL</span> connection must be established by <span class="keyword">default</span> <span class="keyword">if</span> explicit option isn<span class="symbol">'t</span> set. <span class="type">For</span> compliance <span class="keyword">with</span> existing applications not using <span class="type">SSL</span> the verifyServerCertificate property is set to <span class="symbol">'fals</span>e'. <span class="type">You</span> need either to explicitly disable <span class="type">SSL</span> by setting useSSL=<span class="literal">false</span>, or set useSSL=<span class="literal">true</span> and provide truststore <span class="keyword">for</span> server certificate verification.</div><div class="line">jdbcDF: org.apache.spark.sql.<span class="type">DataFrame</span> = [id: int, name: string ... <span class="number">2</span> more fields]</div><div class="line"> </div><div class="line">scala&gt; jdbcDF.show()</div><div class="line"><span class="type">Fri</span> <span class="type">Dec</span> <span class="number">02</span> <span class="number">11</span>:<span class="number">57</span>:<span class="number">30</span> <span class="type">CST</span> <span class="number">2016</span> <span class="type">WARN</span>: <span class="type">Establishing</span> <span class="type">SSL</span> connection without server<span class="symbol">'s</span> identity verification is not recommended. <span class="type">According</span> to <span class="type">MySQL</span> <span class="number">5.5</span><span class="number">.45</span>+, <span class="number">5.6</span><span class="number">.26</span>+ and <span class="number">5.7</span><span class="number">.6</span>+ requirements <span class="type">SSL</span> connection must be established by <span class="keyword">default</span> <span class="keyword">if</span> explicit option isn<span class="symbol">'t</span> set. <span class="type">For</span> compliance <span class="keyword">with</span> existing applications not using <span class="type">SSL</span> the verifyServerCertificate property is set to <span class="symbol">'fals</span>e'. <span class="type">You</span> need either to explicitly disable <span class="type">SSL</span> by setting useSSL=<span class="literal">false</span>, or set useSSL=<span class="literal">true</span> and provide truststore <span class="keyword">for</span> server certificate verification.</div><div class="line">+---+--------+------+---+</div><div class="line">| id|    name|gender|age|</div><div class="line">+---+--------+------+---+</div><div class="line">|  <span class="number">1</span>| <span class="type">Xueqian</span>|     <span class="type">F</span>| <span class="number">23</span>|</div><div class="line">|  <span class="number">2</span>|<span class="type">Weiliang</span>|     <span class="type">M</span>| <span class="number">24</span>|</div><div class="line">+---+--------+------+---+</div></pre></td></tr></table></figure></p>
<p>下面我们再来看一下如何往MySQL中写入数据。<br>为了看到MySQL数据库在Spark程序执行前后发生的变化，我们先在Linux系统中新建一个终端，使用下面命令查看一下MySQL数据库中的数据库spark中的表student的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">service mysql start //如果前面已经启动MySQL数据库，这里不用再执行这条命令</div><div class="line">mysql -u root -p</div></pre></td></tr></table></figure></p>
<p>执行上述命令后，屏幕上会提示你输入MySQL数据库密码，我们这里给数据库设置的用户是root，密码是hadoop。<br>因为之前我们已经在MySQL数据库中创建了一个名称为spark的数据库，并创建了一个名称为student的表，现在查看一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">mysql&gt;  use spark;</div><div class="line">Database changed</div><div class="line"> </div><div class="line">mysql&gt; select * from student;</div><div class="line">//上面命令执行后返回下面结果</div><div class="line">+------+----------+--------+------+</div><div class="line">| id   | name     | gender | age  |</div><div class="line">+------+----------+--------+------+</div><div class="line">|    1 | Xueqian  | F      |   23 |</div><div class="line">|    2 | Weiliang | M      |   24 |</div><div class="line">+------+----------+--------+------+</div><div class="line">2 rows in set (0.00 sec)</div></pre></td></tr></table></figure></p>
<p>现在我们开始在spark-shell中编写程序，往spark.student表中插入两条记录。<br>下面，我们要启动一个spark-shell，而且启动的时候，要附加一些参数。启动Spark Shell时，必须指定mysql连接驱动jar包（如果你前面已经采用下面方式启动了spark-shell，就不需要重复启动了）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell \</div><div class="line">--jars /usr/local/spark/jars/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar \</div><div class="line">--driver-class-path  /usr/local/spark/jars/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar</div></pre></td></tr></table></figure></p>
<p>上面的命令行中，在一行的末尾加入斜杠\，是为了告诉spark-shell，命令还没有结束。</p>
<p>启动进入spark-shell以后，可以执行以下命令连接数据库，写入数据，程序如下（你可以把下面程序一条条拷贝到spark-shell中执行）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></div><div class="line"> </div><div class="line"><span class="comment">//下面我们设置两条数据表示两个学生信息</span></div><div class="line"><span class="keyword">val</span> studentRDD = spark.sparkContext.parallelize(<span class="type">Array</span>(<span class="string">"3 Rongcheng M 26"</span>,<span class="string">"4 Guanhua M 27"</span>)).map(_.split(<span class="string">" "</span>))</div><div class="line"> </div><div class="line"><span class="comment">//下面要设置模式信息</span></div><div class="line"><span class="keyword">val</span> schema = <span class="type">StructType</span>(<span class="type">List</span>(<span class="type">StructField</span>(<span class="string">"id"</span>, <span class="type">IntegerType</span>, <span class="literal">true</span>),<span class="type">StructField</span>(<span class="string">"name"</span>, <span class="type">StringType</span>, <span class="literal">true</span>),<span class="type">StructField</span>(<span class="string">"gender"</span>, <span class="type">StringType</span>, <span class="literal">true</span>),<span class="type">StructField</span>(<span class="string">"age"</span>, <span class="type">IntegerType</span>, <span class="literal">true</span>)))</div><div class="line"> </div><div class="line"><span class="comment">//下面创建Row对象，每个Row对象都是rowRDD中的一行</span></div><div class="line"><span class="keyword">val</span> rowRDD = studentRDD.map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>).toInt, p(<span class="number">1</span>).trim, p(<span class="number">2</span>).trim, p(<span class="number">3</span>).toInt))</div><div class="line"> </div><div class="line"><span class="comment">//建立起Row对象和模式之间的对应关系，也就是把数据和模式对应起来</span></div><div class="line"><span class="keyword">val</span> studentDF = spark.createDataFrame(rowRDD, schema)</div><div class="line"> </div><div class="line"><span class="comment">//下面创建一个prop变量用来保存JDBC连接参数</span></div><div class="line"><span class="keyword">val</span> prop = <span class="keyword">new</span> <span class="type">Properties</span>()</div><div class="line">prop.put(<span class="string">"user"</span>, <span class="string">"root"</span>) <span class="comment">//表示用户名是root</span></div><div class="line">prop.put(<span class="string">"password"</span>, <span class="string">"hadoop"</span>) <span class="comment">//表示密码是hadoop</span></div><div class="line">prop.put(<span class="string">"driver"</span>,<span class="string">"com.mysql.jdbc.Driver"</span>) <span class="comment">//表示驱动程序是com.mysql.jdbc.Driver</span></div><div class="line"> </div><div class="line"><span class="comment">//下面就可以连接数据库，采用append模式，表示追加记录到数据库spark的student表中</span></div><div class="line">studentDF.write.mode(<span class="string">"append"</span>).jdbc(<span class="string">"jdbc:mysql://localhost:3306/spark"</span>, <span class="string">"spark.student"</span>, prop)</div></pre></td></tr></table></figure></p>
<p>在spark-shell中执行完上述程序后，我们可以看一下效果，看看MySQL数据库中的spark.student表发生了什么变化。请在刚才的另外一个窗口的MySQL命令提示符下面继续输入下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">mysql&gt; select * from student;</div><div class="line">+------+-----------+--------+------+</div><div class="line">| id   | name      | gender | age  |</div><div class="line">+------+-----------+--------+------+</div><div class="line">|    1 | Xueqian   | F      |   23 |</div><div class="line">|    2 | Weiliang  | M      |   24 |</div><div class="line">|    3 | Rongcheng | M      |   26 |</div><div class="line">|    4 | Guanhua   | M      |   27 |</div><div class="line">+------+-----------+--------+------+</div><div class="line">4 rows in set (0.00 sec)</div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第五节 Spark - 读写Parquet文件(DataFrame)]]></title>
      <url>http://Melodylican.github.io/2017/03/08/Spark%E8%AF%BB%E5%86%99Parquet%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>Spark SQL可以支持Parquet、JSON、Hive等数据源，并且可以通过JDBC连接外部数据源。前面的介绍中，我们已经涉及到了JSON、文本格式的加载，这里不再赘述。这里介绍Parquet，下一节会介绍JDBC数据库连接。<br><a id="more"></a></p>
<p>Parquet是一种流行的列式存储格式，可以高效地存储具有嵌套字段的记录。Parquet是语言无关的，而且不与任何一种数据处理框架绑定在一起，适配多种语言和组件，能够与Parquet配合的组件有：</p>
<ul>
<li>查询引擎: Hive, Impala, Pig, Presto, Drill, Tajo, HAWQ, IBM Big SQL</li>
<li>计算框架: MapReduce, Spark, Cascading, Crunch, Scalding, Kite</li>
<li>数据模型: Avro, Thrift, Protocol Buffers, POJOs<br>Spark已经为我们提供了parquet样例数据，就保存在“/usr/local/spark/examples/src/main/resources/”这个目录下，有个users.parquet文件，这个文件格式比较特殊，如果你用vim编辑器打开，或者用cat命令查看文件内容，肉眼是一堆乱七八糟的东西，是无法理解的。只有被加载到程序中以后，Spark会对这种格式进行解析，然后我们才能理解其中的数据。<br>下面代码演示了如何从parquet文件中加载数据生成DataFrame。<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> spark.implicits._</div><div class="line"><span class="keyword">import</span> spark.implicits._</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> parquetFileDF = spark.read.parquet(<span class="string">"file:///usr/local/spark/examples/src/main/resources/users.parquet"</span>)</div><div class="line"><span class="type">SLF4J</span>: <span class="type">Failed</span> to load <span class="class"><span class="keyword">class</span> "<span class="title">org</span>.<span class="title">slf4j</span>.<span class="title">impl</span>.<span class="title">StaticLoggerBinder</span>".</span></div><div class="line"><span class="type">SLF4J</span>: <span class="type">Defaulting</span> to no-operation (<span class="type">NOP</span>) logger implementation</div><div class="line"><span class="type">SLF4J</span>: <span class="type">See</span> http:<span class="comment">//www.slf4j.org/codes.html#StaticLoggerBinder for further details.</span></div><div class="line">parquetFileDF: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, favorite_color: string ... <span class="number">1</span> more field]</div><div class="line"> </div><div class="line">scala&gt; parquetFileDF.createOrReplaceTempView(<span class="string">"parquetFile"</span>)</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> namesDF = spark.sql(<span class="string">"SELECT * FROM parquetFile"</span>)</div><div class="line">namesDF: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, favorite_color: string ... <span class="number">1</span> more field]</div><div class="line"> </div><div class="line">scala&gt; namesDF.foreach(attributes =&gt;println(<span class="string">"Name: "</span> + attributes(<span class="number">0</span>)+<span class="string">"  favorite color:"</span>+attributes(<span class="number">1</span>)))</div><div class="line"><span class="number">16</span>/<span class="number">12</span>/<span class="number">02</span> <span class="number">10</span>:<span class="number">18</span>:<span class="number">49</span> <span class="type">WARN</span> hadoop.<span class="type">ParquetRecordReader</span>: <span class="type">Can</span> not initialize counter due to context is not a instance of <span class="type">TaskInputOutputContext</span>, but is org.apache.hadoop.mapreduce.task.<span class="type">TaskAttemptContextImpl</span></div><div class="line"><span class="type">Name</span>: <span class="type">Alyssa</span>  favorite color:<span class="literal">null</span></div><div class="line"><span class="type">Name</span>: <span class="type">Ben</span>  favorite color:red</div></pre></td></tr></table></figure>
</li>
</ul>
<p>下面介绍如何将DataFrame保存成parquet文件。</p>
<p>进入spark-shell执行下面命令：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> spark.implicits._</div><div class="line"><span class="keyword">import</span> spark.implicits._</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> peopleDF = spark.read.json(<span class="string">"file:///usr/local/spark/examples/src/main/resources/people.json"</span>)</div><div class="line">peopleDF: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint, name: string]</div><div class="line"> </div><div class="line">scala&gt; peopleDF.write.parquet(<span class="string">"file:///usr/local/spark/mycode/newpeople.parquet"</span>)</div></pre></td></tr></table></figure></p>
<p>上述过程执行结束后，可以打开第二个终端窗口，在Shell命令提示符下查看新生成的newpeople.parquet：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span>  /usr/<span class="built_in">local</span>/spark/myCode/</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p>上面命令执行后，可以看到”/usr/local/spark/myCode/”这个目录下多了一个newpeople.parquet，不过，注意，这不是一个文件，而是一个目录（不要被newpeople.parquet中的圆点所迷惑，文件夹名称也可以包含圆点），也就是说，peopleDF.write.parquet(“file:///usr/local/spark/myCode/newpeople.parquet”)括号里面的参数是文件夹，不是文件名。下面我们可以进入newpeople.parquet目录，会发现下面2个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">part-r-00000-8d3a120f-b3b5-4582-b26b-f3693df80d45.snappy.parquet </div><div class="line">_SUCCESS</div></pre></td></tr></table></figure></p>
<p>这2个文件都是刚才保存生成的。现在问题来了，如果我们要再次把这个刚生成的数据又加载到DataFrame中，应该加载哪个文件呢？很简单，只要加载newpeople.parquet目录即可，而不是加载这2个文件，语句如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> users = spark.read.parquet(<span class="string">"file:///usr/local/spark/myCode/people.parquet"</span>)</div><div class="line">users: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint, name: string]</div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第四节 Spark - 从RDD转换得到DataFrame]]></title>
      <url>http://Melodylican.github.io/2017/03/07/%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame/</url>
      <content type="html"><![CDATA[<p>Spark官网提供了两种方法来实现从RDD转换得到DataFrame，第一种方法是，利用反射来推断包含特定类型对象的RDD的schema；第二种方法是，使用编程接口，构造一个schema并将其应用在已知的RDD上。<br><a id="more"></a></p>
<div class="note success"><h2 id="利用反射机制推断RDD模式"><a href="#利用反射机制推断RDD模式" class="headerlink" title="利用反射机制推断RDD模式"></a>利用反射机制推断RDD模式</h2></div>
<p>在利用反射机制推断RDD模式时，需要首先定义一个case class，因为，只有case class才能被Spark隐式地转换为DataFrame。<br>下面是在spark-shell中执行命令以及反馈的信息：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line">scala&gt; <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line">scala&gt; <span class="keyword">import</span> sqlContext.implicits._  <span class="comment">//导入包，支持把一个RDD隐式转换为一个DataFrame</span></div><div class="line"><span class="keyword">import</span> sqlContext.implicits._</div><div class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>) <span class="title">//定义一个case</span> <span class="title">class</span></span></div><div class="line">defined <span class="class"><span class="keyword">class</span> <span class="title">Person</span></span></div><div class="line">scala&gt; <span class="keyword">val</span> people = sc.textFile(<span class="string">"file:///usr/local/spark/examples/src/main/resources/people.txt"</span>).map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Person</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim.toInt)).toDF()</div><div class="line"><span class="number">16</span>/<span class="number">11</span>/<span class="number">15</span> <span class="number">11</span>:<span class="number">19</span>:<span class="number">18</span> <span class="type">INFO</span> spark.<span class="type">SparkContext</span>: <span class="type">Created</span> broadcast <span class="number">17</span> from textFile at &lt;console&gt;:<span class="number">37</span></div><div class="line">people: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</div><div class="line">scala&gt; people.registerTempTable(<span class="string">"peopleTempTab"</span>) <span class="comment">//必须注册为临时表才能供下面的查询使用</span></div><div class="line">scala&gt; <span class="keyword">val</span> personsRDD = sqlContext.sql(<span class="string">"select name,age from peopleTempTab where age &gt; 20"</span>).rdd <span class="comment">//最终生成一个RDD</span></div><div class="line">personsRDD: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">43</span>] at rdd at &lt;console&gt;:<span class="number">35</span></div><div class="line"><span class="comment">//从上面的信息可以看出，生成的RDD的每个元素的类型是org.apache.spark.sql.Row</span></div><div class="line">scala&gt; personsRDD.foreach(t =&gt; println(<span class="string">"Name:"</span>+t(<span class="number">0</span>),<span class="string">"Age:"</span>+t(<span class="number">1</span>)))  <span class="comment">//RDD中的每个元素都是一行记录，包含name和age两个字段，分别用t(0)和t(1)来获取值</span></div><div class="line">(<span class="type">Name</span>:<span class="type">Michael</span>,<span class="type">Age</span>:<span class="number">29</span>)</div><div class="line">(<span class="type">Name</span>:<span class="type">Andy</span>,<span class="type">Age</span>:<span class="number">30</span>)</div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="使用编程方式定义RDD模式"><a href="#使用编程方式定义RDD模式" class="headerlink" title="使用编程方式定义RDD模式"></a>使用编程方式定义RDD模式</h2></div>
<p>当无法提前定义case class时，就需要采用编程方式定义RDD模式。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line">sqlContext: org.apache.spark.sql.<span class="type">SQLContext</span> = org.apache.spark.sql.<span class="type">SQLContext</span>@<span class="number">5</span>f7bd970</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> people = sc.textFile(<span class="string">"file:///usr/local/spark/examples/src/main/resources/people.txt"</span>)</div><div class="line">people: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/examples/src/main/resources/people.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:28</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> schemaString = <span class="string">"name age"</span> <span class="comment">//定义一个模式字符串</span></div><div class="line">schemaString: <span class="type">String</span> = name age</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>,<span class="type">StructField</span>,<span class="type">StringType</span>&#125;</div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StructType</span>, <span class="type">StructField</span>, <span class="type">StringType</span>&#125;</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> schema = <span class="type">StructType</span>( schemaString.split(<span class="string">" "</span>).map(fieldName =&gt; <span class="type">StructField</span>(fieldName, <span class="type">StringType</span>, <span class="literal">true</span>))) <span class="comment">//根据模式字符串生成模式</span></div><div class="line">schema: org.apache.spark.sql.types.<span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">StructField</span>(name,<span class="type">StringType</span>,<span class="literal">true</span>), <span class="type">StructField</span>(age,<span class="type">StringType</span>,<span class="literal">true</span>))</div><div class="line"><span class="comment">//从上面信息可以看出，schema描述了模式信息，模式中包含name和age两个字段</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> rowRDD = people.map(_.split(<span class="string">","</span>)).map(p =&gt; <span class="type">Row</span>(p(<span class="number">0</span>), p(<span class="number">1</span>).trim))  <span class="comment">//对people这个RDD中的每一行元素都进行解析</span></div><div class="line">rowRDD: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at map at &lt;console&gt;:<span class="number">32</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> peopleDataFrame = sqlContext.createDataFrame(rowRDD, schema)</div><div class="line">peopleDataFrame: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: string]</div><div class="line"> </div><div class="line">scala&gt; peopleDataFrame.registerTempTable(<span class="string">"peopleTempTab"</span>) <span class="comment">//必须注册为临时表才能供下面查询使用</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> personsRDD = sqlContext.sql(<span class="string">"select name,age from peopleTempTab where age &gt; 20"</span>).rdd</div><div class="line">personsRDD: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">7</span>] at rdd at &lt;console&gt;:<span class="number">32</span></div><div class="line"> </div><div class="line">scala&gt; personsRDD.foreach(t =&gt; println(<span class="string">"Name:"</span>+t(<span class="number">0</span>)+<span class="string">",Age:"</span>+t(<span class="number">1</span>)))</div><div class="line">(<span class="type">Name</span>:<span class="type">Michael</span>,<span class="type">Age</span>:<span class="number">29</span>)</div><div class="line">(<span class="type">Name</span>:<span class="type">Andy</span>,<span class="type">Age</span>:<span class="number">30</span>)</div></pre></td></tr></table></figure></p>
<p>在上面的代码中，people.map(_.split(“,”))实际上和people.map(line =&gt; line.split(“,”))这种表述是等价的，作用是对people这个RDD中的每一行元素都进行解析。比如，people这个RDD的第一行是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Michael, 29</div></pre></td></tr></table></figure></p>
<p>这行内容经过people.map(_.split(“,”))操作后，就得到一个集合{Michael,29}。后面经过map(p =&gt; Row(p(0), p(1).trim))操作时，这时的p就是这个集合{Michael,29}，这时p(0)就是Micheael，p(1)就是29，map(p =&gt; Row(p(0), p(1).trim))就会生成一个Row对象，这个对象里面包含了两个字段的值，这个Row对象就构成了rowRDD中的其中一个元素。因为people有3行文本，所以，最终，rowRDD中会包含3个元素，每个元素都是org.apache.spark.sql.Row类型。实际上，Row对象只是对基本数据类型（比如整型或字符串）的数组的封装，本质就是一个定长的字段数组。<br>peopleDataFrame = sqlContext.createDataFrame(rowRDD, schema)，这条语句就相当于建立了rowRDD数据集和模式之间的对应关系，从而我们就知道对于rowRDD的每行记录，第一个字段的名称是schema中的“name”，第二个字段的名称是schema中的“age”。</p>
<p>把RDD保存成文件<br>这里介绍如何把RDD保存成文本文件，后面还会介绍其他格式的保存。<br>进入spark-shell执行下面命令：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SQLContext</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> sqlContext = <span class="keyword">new</span> <span class="type">SQLContext</span>(sc)</div><div class="line">sqlContext: org.apache.spark.sql.<span class="type">SQLContext</span> = org.apache.spark.sql.<span class="type">SQLContext</span>@<span class="number">4</span>a65c40</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> df = sqlContext.read.json(<span class="string">"file:///usr/local/spark/examples/src/main/resources/people.json"</span>)</div><div class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint, name: string]</div><div class="line"> </div><div class="line">scala&gt; df.rdd.saveAsTextFile(<span class="string">"file:///usr/local/spark/mycode/newpeople.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>可以看出，我们是把DataFrame转换成RDD，然后调用saveAsTextFile()保存成文本文件。在后面小节中，我们还会介绍其他保存方式。<br>上述过程执行结束后，可以打开第二个终端窗口，在Shell命令提示符下查看新生成的newpeople.txt：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd  /usr/local/spark/mycode/</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p>可以看到/usr/local/spark/mycode/这个目录下面有个newpeople.txt文件夹（注意，不是文件），这个文件夹中包含下面两个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">part-00000  </div><div class="line">_SUCCESS</div></pre></td></tr></table></figure></p>
<p>不用理会_SUCCESS这个文件，只要看一下part-00000这个文件，可以用vim编辑器打开这个文件查看它的内容，该文件内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[null,Michael]</div><div class="line">[30,Andy]</div><div class="line">[19,Justin]</div></pre></td></tr></table></figure></p>
<p>如果我们要再次把newpeople.txt中的数据加载到RDD中，可以直接使用newpeople.txt目录名称，而不需要使用part-00000文件，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/newpeople.txt"</span>)</div><div class="line">textFile: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/mycode/newpeople.txt MapPartitionsRDD[11] at textFile at &lt;console&gt;:28</span></div><div class="line"> </div><div class="line">scala&gt; textFile.foreach(println)</div><div class="line">[<span class="literal">null</span>,<span class="type">Michael</span>]</div><div class="line">[<span class="number">30</span>,<span class="type">Andy</span>]</div><div class="line">[<span class="number">19</span>,<span class="type">Justin</span>]</div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第三节 Spark - DataFrame的创建]]></title>
      <url>http://Melodylican.github.io/2017/03/06/SparkDataFrame%E7%9A%84%E5%88%9B%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>从Spark2.0以上版本开始，Spark使用全新的SparkSession接口替代Spark1.6中的SQLContext及HiveContext接口来实现其对数据加载、转换、处理等功能。SparkSession实现了SQLContext及HiveContext所有功能。<br><a id="more"></a></p>
<p>SparkSession支持从不同的数据源加载数据，并把数据转换成DataFrame，并且支持把DataFrame转换成SQLContext自身中的表，然后使用SQL语句来操作数据。SparkSession亦提供了HiveQL以及其他依赖于Hive的功能的支持。</p>
<p>下面我们就介绍如何使用SparkSession来创建DataFrame。<br>请进入Linux系统，打开“终端”，进入Shell命令提示符状态。<br>首先，请找到样例数据。 Spark已经为我们提供了几个样例数据，就保存在“/usr/local/spark/examples/src/main/resources/”这个目录下，这个目录下有两个样例数据people.json和people.txt。<br>people.json文件的内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;name&quot;:&quot;Michael&quot;&#125;</div><div class="line">&#123;&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30&#125;</div><div class="line">&#123;&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19&#125;</div></pre></td></tr></table></figure></p>
<p>people.txt文件的内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Michael, 29</div><div class="line">Andy, 30</div><div class="line">Justin, 19</div></pre></td></tr></table></figure></p>
<p>下面我们就介绍如何从people.json文件中读取数据并生成DataFrame并显示数据（从people.txt文件生成DataFrame需要后面将要介绍的另外一种方式）。<br>请使用如下命令打开spark-shell：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell</div></pre></td></tr></table></figure></p>
<p>进入到spark-shell状态后执行下面命令：</p>
<pre><code class="scala">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span>
<span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span>

scala&gt; <span class="keyword">val</span> spark=<span class="type">SparkSession</span>.builder().getOrCreate()
spark: org.apache.spark.sql.<span class="type">SparkSession</span> = org.apache.spark.sql.<span class="type">SparkSession</span>@<span class="number">2</span>bdab835

<span class="comment">//使支持RDDs转换为DataFrames及后续sql操作</span>
scala&gt; <span class="keyword">import</span> spark.implicits._
<span class="keyword">import</span> spark.implicits._

scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"file:///usr/local/spark/examples/src/main/resources/people.json"</span>)
df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint, name: string]

scala&gt; df.show()
+----+-------+
| age|   name|
+----+-------+
|<span class="literal">null</span>|<span class="type">Michael</span>|
|  <span class="number">30</span>|   <span class="type">Andy</span>|
|  <span class="number">19</span>| <span class="type">Justin</span>|
+----+-------+
</code></pre>
<p>现在，我们可以执行一些常用的DataFrame操作。</p>
<pre><code class="scala"><span class="comment">// 打印模式信息</span>
scala&gt; df.printSchema()
root
 |-- age: long (nullable = <span class="literal">true</span>)
 |-- name: string (nullable = <span class="literal">true</span>)

<span class="comment">// 选择多列</span>
scala&gt; df.select(df(<span class="string">"name"</span>),df(<span class="string">"age"</span>)+<span class="number">1</span>).show()
+-------+---------+
|   name|(age + <span class="number">1</span>)|
+-------+---------+
|<span class="type">Michael</span>|     <span class="literal">null</span>|
|   <span class="type">Andy</span>|       <span class="number">31</span>|
| <span class="type">Justin</span>|       <span class="number">20</span>|
+-------+---------+

<span class="comment">// 条件过滤</span>
scala&gt; df.filter(df(<span class="string">"age"</span>) &gt; <span class="number">20</span> ).show()
+---+----+
|age|name|
+---+----+
| <span class="number">30</span>|<span class="type">Andy</span>|
+---+----+

<span class="comment">// 分组聚合</span>
scala&gt; df.groupBy(<span class="string">"age"</span>).count().show()
+----+-----+
| age|count|
+----+-----+
|  <span class="number">19</span>|    <span class="number">1</span>|
|<span class="literal">null</span>|    <span class="number">1</span>|
|  <span class="number">30</span>|    <span class="number">1</span>|
+----+-----+

<span class="comment">// 排序</span>
scala&gt; df.sort(df(<span class="string">"age"</span>).desc).show()
+----+-------+
| age|   name|
+----+-------+
|  <span class="number">30</span>|   <span class="type">Andy</span>|
|  <span class="number">19</span>| <span class="type">Justin</span>|
|<span class="literal">null</span>|<span class="type">Michael</span>|
+----+-------+

<span class="comment">//多列排序</span>
scala&gt; df.sort(df(<span class="string">"age"</span>).desc, df(<span class="string">"name"</span>).asc).show()
+----+-------+
| age|   name|
+----+-------+
|  <span class="number">30</span>|   <span class="type">Andy</span>|
|  <span class="number">19</span>| <span class="type">Justin</span>|
|<span class="literal">null</span>|<span class="type">Michael</span>|
+----+-------+

<span class="comment">//对列进行重命名</span>
scala&gt; df.select(df(<span class="string">"name"</span>).as(<span class="string">"username"</span>),df(<span class="string">"age"</span>)).show()
+--------+----+
|username| age|
+--------+----+
| <span class="type">Michael</span>|<span class="literal">null</span>|
|    <span class="type">Andy</span>|  <span class="number">30</span>|
|  <span class="type">Justin</span>|  <span class="number">19</span>|
+--------+----+
</code></pre>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第二节 Spark DataFrame与RDD的区别]]></title>
      <url>http://Melodylican.github.io/2017/03/03/SparkDataFrame%E4%B8%8ERDD%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      <content type="html"><![CDATA[<p>DataFrame的推出，让Spark具备了处理大规模结构化数据的能力，不仅比原有的RDD转化方式更加简单易用，而且获得了更高的计算性能。Spark能够轻松实现从MySQL到DataFrame的转化，并且支持SQL查询。</p>
<p><center><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/DataFrame-RDD.jpg" alt=""><br>图 DataFrame与RDD的区别<br></center><br><a id="more"></a><br>从上面的图中可以看出DataFrame和RDD的区别。RDD是分布式的 Java对象的集合，比如，RDD[Person]是以Person为类型参数，但是，Person类的内部结构对于RDD而言却是不可知的。DataFrame是一种以RDD为基础的分布式数据集，也就是分布式的Row对象的集合（每个Row对象代表一行记录），提供了详细的结构信息，也就是我们经常说的模式（schema），Spark SQL可以清楚地知道该数据集中包含哪些列、每列的名称和类型。<br>和RDD一样，DataFrame的各种变换操作也采用惰性机制，只是记录了各种转换的逻辑转换路线图（是一个DAG图），不会发生真正的计算，这个DAG图相当于一个逻辑查询计划，最终，会被翻译成物理查询计划，生成RDD DAG，按照之前介绍的RDD DAG的执行方式去完成最终的计算得到结果。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第四章 第一节 Spark SQL简介]]></title>
      <url>http://Melodylican.github.io/2017/03/02/SparkSql%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>Spark SQL是Spark生态系统中非常重要的组件，其前身为Shark。Shark是Spark上的数据仓库，最初设计成与Hive兼容，但是该项目于2014年开始停止开发，转向Spark SQL。Spark SQL全面继承了Shark，并进行了优化。<br><a id="more"></a></p>
<div class="note success"><h2 id="从Shark说起"><a href="#从Shark说起" class="headerlink" title="从Shark说起"></a>从Shark说起</h2></div>
<p>Shark即Hive on Spark，为了实现与Hive兼容，Shark在HiveQL方面重用了Hive中的HiveQL解析、逻辑执行计划翻译、执行计划优化等逻辑，可以近似认为仅将物理执行计划从MapReduce作业替换成了Spark作业，通过Hive的HiveQL解析，把HiveQL翻译成Spark上的RDD操作。（要想了解更多数据仓库Hive的知识，可以参考厦门大学数据库实验室的Hive授课视频、Hive安装指南）<br>Shark的设计导致了两个问题：一是执行计划优化完全依赖于Hive，不方便添加新的优化策略；二是因为Spark是线程级并行，而MapReduce是进程级并行，因此，Spark在兼容Hive的实现上存在线程安全问题，导致Shark不得不使用另外一套独立维护的打了补丁的Hive源码分支。<br>Shark的实现继承了大量的Hive代码，因而给优化和维护带来了大量的麻烦，特别是基于MapReduce设计的部分，成为整个项目的瓶颈。因此，在2014年的时候，Shark项目中止，并转向Spark SQL的开发。</p>
<div class="note success"><h2 id="Spark-SQL设计"><a href="#Spark-SQL设计" class="headerlink" title="Spark SQL设计"></a>Spark SQL设计</h2></div>
<p>Spark SQL的架构如图16-12所示，在Shark原有的架构上重写了逻辑执行计划的优化部分，解决了Shark存在的问题。Spark SQL在Hive兼容层面仅依赖HiveQL解析和Hive元数据，也就是说，从HQL被解析成抽象语法树（AST）起，就全部由Spark SQL接管了。Spark SQL执行计划生成和优化都由Catalyst（函数式关系查询优化框架）负责。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE16-12-Spark-SQL%E6%9E%B6%E6%9E%84.jpg" alt=""><br>图16-12-Spark-SQL架构</p>
<p>Spark SQL增加了SchemaRDD（即带有Schema信息的RDD），使用户可以在Spark SQL中执行SQL语句，数据既可以来自RDD，也可以来自Hive、HDFS、Cassandra等外部数据源，还可以是JSON格式的数据。Spark SQL目前支持Scala、Java、Python三种语言，支持SQL-92规范。从Spark1.2 升级到Spark1.3以后，Spark SQL中的SchemaRDD变为了DataFrame，DataFrame相对于SchemaRDD有了较大改变,同时提供了更多好用且方便的API，如图16-13所示。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE16-13-Spark-SQL%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E5%92%8C%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.jpg" alt=""><br>图16-13-Spark-SQL支持的数据格式和编程语言</p>
<p>Spark SQL可以很好地支持SQL查询，一方面，可以编写Spark应用程序使用SQL语句进行数据查询，另一方面，也可以使用标准的数据库连接器（比如JDBC或ODBC）连接Spark进行SQL查询，这样，一些市场上现有的商业智能工具（比如Tableau）就可以很好地和Spark SQL组合起来使用，从而使得这些外部工具借助于Spark SQL也能获得大规模数据的处理分析能力。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第三章 第五节 Spark读写HBase数据]]></title>
      <url>http://Melodylican.github.io/2017/03/01/Spark%E8%AF%BB%E5%8F%96HBase%E6%95%B0%E6%8D%AE/</url>
      <content type="html"><![CDATA[<p>Spark处理的数据有很多是存放在HBase数据库中的，所以，我们需要学会如何读写HBase数据库。HBase是针对谷歌BigTable的开源实现，是一个高可靠、高性能、面向列、可伸缩的分布式数据库，主要用来存储非结构化和半结构化的松散数据。HBase可以支持超大规模数据存储，它可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表。如果要了解HBase的技术原理和使用方法，可以参考<a href="http://dblab.xmu.edu.cn/post/bigdata-online-course/#lesson4" target="_blank" rel="external">厦门大学数据库实验室的在线课程《HBase数据库》</a>。<br><a id="more"></a><br><div class="note success"><h2 id="准备工作一：创建一个HBase表"><a href="#准备工作一：创建一个HBase表" class="headerlink" title="准备工作一：创建一个HBase表"></a>准备工作一：创建一个HBase表</h2></div><br>这里依然是以student表为例进行演示。这里假设你已经成功安装了HBase数据库，如果你还没有安装，可以参考厦门大学数据库实验室HBase安装和使用教程，进行安装，安装好以后，不要创建数据库和表，只要跟着本节后面的内容操作即可。HBase安装时有三种模式：单机模式、伪分布式模式和分布式模式。本教程采用伪分布式安装。<br>安装好了伪分布式模式的HBase以后，我们可以在里面创建一个student表。<br>请登录Linux系统，打开一个终端（可以使用快捷方式Ctrl+Alt+T组合键打开终端），因为HBase是伪分布式模式，需要调用HDFS，所以，请首先在终端中输入下面命令启动Hadoop：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/hadoop</div><div class="line">./sbin/start-all.sh</div></pre></td></tr></table></figure></p>
<p>启动完成以后，一定要输入jps命令查看是否启动成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">jps</div></pre></td></tr></table></figure></p>
<p>运行jps命令以后，应该可以看到以下几个进程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">2375 SecondaryNameNode</div><div class="line">2169 DataNode</div><div class="line">2667 NodeManager</div><div class="line">2972 Jps</div><div class="line">2045 NameNode</div><div class="line">2541 ResourceManager</div></pre></td></tr></table></figure></p>
<p>如果少了其中一个进程，说明启动失败。<br>下面就可以启动HBase，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/hbase</div><div class="line">./bin/start-hbase.sh //启动HBase</div><div class="line">./bin/hbase shell  //启动hbase shell</div></pre></td></tr></table></figure></p>
<p>这样就可以进入hbase shell命令提示符状态。下面我们在HBase数据库中创建student表（注意：在关系型数据库MySQL中，需要首先创建数据库，然后再创建表，但是，在HBase数据库中，不需要创建数据库，只要直接创建表就可以）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hbase&gt; list</div></pre></td></tr></table></figure></p>
<p>用list命令可以显示当前HBase数据库中有哪些已经创建好的表，如果里面已经有一个名称为student的表，请使用如下命令删除（如果不存在student表，就不用执行下面的删除命令了）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hbase&gt; disable &apos;student&apos;</div><div class="line">hbase&gt; drop &apos;student&apos;</div></pre></td></tr></table></figure></p>
<p>下面让我们一起来创建一个student表，我们要在这个表中录入如下数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">+------+----------+--------+------+</div><div class="line">| id   | name     | gender | age  |</div><div class="line">+------+----------+--------+------+</div><div class="line">|    1 | Xueqian  | F      |   23 |</div><div class="line">|    2 | Weiliang | M      |   24 |</div><div class="line">+------+----------+--------+------+</div></pre></td></tr></table></figure></p>
<p>我们可以在hbase shell中使用下面命令创建：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hbase&gt;  create &apos;student&apos;,&apos;info&apos;</div></pre></td></tr></table></figure></p>
<p>你可以发现，我们在创建student表的create命令中，命令后面首先跟上表名称’student’，然后，再跟上列族名称’info’，这个列族’info’中包含三个列’name’,’gender’,’age’。你会发现，好像没有’id’字段，这是因为HBase的表中会有一个系统默认的属性作为行键，无需自行创建，默认把put命令操作中跟在表名后的第一个字段作为行健。<br>创建完“student”表后，可通过describe命令查看“student”表的基本信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hbase&gt; describe &apos;student&apos;</div></pre></td></tr></table></figure></p>
<p>下面，我们要把student表的两个样例记录输入到student表中。但是，HBase是列族数据库，原理和关系数据库不同，操作方法也不同。如果要了解HBase的技术原理和使用方法，可以参考<a href="http://dblab.xmu.edu.cn/post/bigdata-online-course/#lesson4" target="_blank" rel="external">厦门大学数据库实验室的在线课程《HBase数据库》</a>。<br>如果没有时间学习HBase数据库细节知识，也可以直接按照下面的内容跟着操作就可以了。<br>HBase中用put命令添加数据，注意：一次只能为一个表的一行数据的一个列（也就是一个单元格，单元格是HBase中的概念）添加一个数据，所以直接用shell命令插入数据效率很低，在实际应用中，一般都是利用编程操作数据。因为这里只要插入两条学生记录，所以，我们可以用shell命令手工插入。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">//首先录入student表的第一个学生记录</div><div class="line">hbase&gt; put &apos;student&apos;,&apos;1&apos;,&apos;info:name&apos;,&apos;Xueqian&apos;</div><div class="line">hbase&gt; put &apos;student&apos;,&apos;1&apos;,&apos;info:gender&apos;,&apos;F&apos;</div><div class="line">hbase&gt; put &apos;student&apos;,&apos;1&apos;,&apos;info:age&apos;,&apos;23&apos;</div><div class="line">//然后录入student表的第二个学生记录</div><div class="line">hbase&gt; put &apos;student&apos;,&apos;2&apos;,&apos;info:name&apos;,&apos;Weiliang&apos;</div><div class="line">hbase&gt; put &apos;student&apos;,&apos;2&apos;,&apos;info:gender&apos;,&apos;M&apos;</div><div class="line">hbase&gt; put &apos;student&apos;,&apos;2&apos;,&apos;info:age&apos;,&apos;24&apos;</div></pre></td></tr></table></figure></p>
<p>数据录入结束后，可以用下面命令查看刚才已经录入的数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">//如果每次只查看一行，就用下面命令</div><div class="line">hbase&gt; get &apos;student&apos;,&apos;1&apos;</div><div class="line">//如果每次查看全部数据，就用下面命令</div><div class="line">hbase&gt; scan &apos;student&apos;</div></pre></td></tr></table></figure></p>
<p>可以得到如下结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ROW                                    COLUMN+CELL                                                                                                   </div><div class="line"> 1                                     column=info:age, timestamp=1479640712163, value=23                                                            </div><div class="line"> 1                                     column=info:gender, timestamp=1479640704522, value=F                                                          </div><div class="line"> 1                                     column=info:name, timestamp=1479640696132, value=Xueqian                                                      </div><div class="line"> 2                                     column=info:age, timestamp=1479640752474, value=24                                                            </div><div class="line"> 2                                     column=info:gender, timestamp=1479640745276, value=M                                                          </div><div class="line"> 2                                     column=info:name, timestamp=1479640732763, value=Weiliang                                                     </div><div class="line">2 row(s) in 0.1610 seconds</div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="准备工作二：配置Spark"><a href="#准备工作二：配置Spark" class="headerlink" title="准备工作二：配置Spark"></a>准备工作二：配置Spark</h2></div>
<p>在开始编程操作HBase数据库之前，需要对做一些准备工作。<br>（1）请新建一个终端，执行下面命令，把HBase的lib目录下的一些jar文件拷贝到Spark中，这些都是编程时需要引入的jar包，需要拷贝的jar文件包括：所有hbase开头的jar文件、guava-12.0.1.jar、htrace-core-3.1.0-incubating.jar和protobuf-java-2.5.0.jar，可以打开一个终端按照以下命令来操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/jars</div><div class="line">mkdir hbase</div><div class="line">cd hbase</div><div class="line">cp /usr/local/hbase/lib/hbase*.jar ./</div><div class="line">cp /usr/local/hbase/lib/guava-12.0.1.jar ./</div><div class="line">cp /usr/local/hbase/lib/htrace-core-3.1.0-incubating.jar ./</div><div class="line">cp /usr/local/hbase/lib/protobuf-java-2.5.0.jar ./</div></pre></td></tr></table></figure></p>
<p>只有这样，后面编译和运行过程才不会出错。<br><div class="note success"><h2 id="编写程序读取HBase数据"><a href="#编写程序读取HBase数据" class="headerlink" title="编写程序读取HBase数据"></a>编写程序读取HBase数据</h2></div><br>如果要让Spark读取HBase，就需要使用SparkContext提供的newAPIHadoopRDD API将表的内容以RDD的形式加载到Spark中。<br>请在Linux系统中打开一个终端，然后执行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode</div><div class="line">mkdir hbase</div><div class="line">cd hbase</div><div class="line">mkdir -p src/main/scala</div><div class="line">cd src/main/scala</div><div class="line">vim SparkOperateHBase.scala</div></pre></td></tr></table></figure></p>
<p>然后，在SparkOperateHBase.scala文件中输入以下代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase._</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client._</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableInputFormat</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkOperateHBase</span> </span>&#123;</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line"></div><div class="line">    <span class="keyword">val</span> conf = <span class="type">HBaseConfiguration</span>.create()</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(<span class="keyword">new</span> <span class="type">SparkConf</span>())</div><div class="line">    <span class="comment">//设置查询的表名</span></div><div class="line">    conf.set(<span class="type">TableInputFormat</span>.<span class="type">INPUT_TABLE</span>, <span class="string">"student"</span>)</div><div class="line">    <span class="keyword">val</span> stuRDD = sc.newAPIHadoopRDD(conf, classOf[<span class="type">TableInputFormat</span>],</div><div class="line">  classOf[org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span>],</div><div class="line">  classOf[org.apache.hadoop.hbase.client.<span class="type">Result</span>])</div><div class="line">    <span class="keyword">val</span> count = stuRDD.count()</div><div class="line">    println(<span class="string">"Students RDD Count:"</span> + count)</div><div class="line">    stuRDD.cache()</div><div class="line"></div><div class="line">    <span class="comment">//遍历输出</span></div><div class="line">    stuRDD.foreach(&#123; <span class="keyword">case</span> (_,result) =&gt;</div><div class="line">        <span class="keyword">val</span> key = <span class="type">Bytes</span>.toString(result.getRow)</div><div class="line">        <span class="keyword">val</span> name = <span class="type">Bytes</span>.toString(result.getValue(<span class="string">"info"</span>.getBytes,<span class="string">"name"</span>.getBytes))</div><div class="line">        <span class="keyword">val</span> gender = <span class="type">Bytes</span>.toString(result.getValue(<span class="string">"info"</span>.getBytes,<span class="string">"gender"</span>.getBytes))</div><div class="line">        <span class="keyword">val</span> age = <span class="type">Bytes</span>.toString(result.getValue(<span class="string">"info"</span>.getBytes,<span class="string">"age"</span>.getBytes))</div><div class="line">        println(<span class="string">"Row key:"</span>+key+<span class="string">" Name:"</span>+name+<span class="string">" Gender:"</span>+gender+<span class="string">" Age:"</span>+age)</div><div class="line">    &#125;)</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>然后就可以用sbt打包编译。不过，在编译之前，需要新建一个simple.sbt文件，在simple.sbt配置文件中，需要知道scalaVersion、spark-core、hbase-client、hbase-common、hbase-server的版本号。在前面章节《Spark的安装和使用》的“编写Scala独立应用程序”部分，我们已经介绍了如何寻找scalaVersion和spark-core的版本号，这里不再赘述。现在介绍如何找到你自己电脑上安装的HBase的hbase-client、hbase-common、hbase-server的版本号。<br>请在Linux系统中打开一个终端，输入下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/hbase //这是笔者电脑的hbase安装目录</div><div class="line">cd lib</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p>ls命令会把“/usr/local/hbase/lib”目录下的所有jar文件全部列出来，其中，就可以看到下面三个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hbase-client-1.1.5.jar  //可以看出版本号是1.1.5</div><div class="line">hbase-common-1.1.5.jar //可以看出版本号是1.1.5</div><div class="line">hbase-server-1.1.5.jar //可以看出版本号是1.1.5</div></pre></td></tr></table></figure></p>
<p>根据上面三个文件，我们就可以得知hbase-client、hbase-common、hbase-server的版本号是1.1.5（当然，你的电脑上可能不是这个版本号，请以你自己的版本号为准）。<br>有了这些版本号信息，我们就可以新建一个simple.sbt文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/hbase</div><div class="line">vim simple.sbt</div></pre></td></tr></table></figure></p>
<p>然后在simple.sbt中录入下面内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">name := &quot;Simple Project&quot;</div><div class="line">version := &quot;1.0&quot;</div><div class="line">scalaVersion := &quot;2.11.8&quot;</div><div class="line">libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;2.1.0&quot;</div><div class="line">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-client&quot; % &quot;1.1.5&quot;</div><div class="line">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-common&quot; % &quot;1.1.5&quot;</div><div class="line">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-server&quot; % &quot;1.1.5&quot;</div></pre></td></tr></table></figure></p>
<p>保存该文件，退出vim编辑器。</p>
<p>然后，输入下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">find .</div></pre></td></tr></table></figure></p>
<p>应该可以看到类似下面的文件结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">./src</div><div class="line">./src/main</div><div class="line">./src/main/scala</div><div class="line">./src/main/scala/SparkOperateHBase.scala</div><div class="line">./simple.sbt</div></pre></td></tr></table></figure></p>
<p>下面就可以运行sbt打包命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/hbase   //一定把这个设置为当前目录</div><div class="line">/usr/local/sbt/sbt package</div></pre></td></tr></table></figure></p>
<p>打包成功以后，生成的 jar 包的位置为 /usr/local/spark/mycode/hbase/target/scala-2.11/simple-project_2.11-1.0.jar。<br>最后，通过 spark-submit 运行程序。我们就可以将生成的 jar 包通过 spark-submit 提交到 Spark 中运行了，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/spark/bin/spark-submit --driver-class-path /usr/local/spark/jars/hbase/*:/usr/local/hbase/conf --class &quot;SparkOperateHBase&quot;  /usr/local/spark/mycode/hbase/target/scala-2.11/simple-project_2.11-1.0.jar</div></pre></td></tr></table></figure></p>
<p>特别强调，上面命令中，必须使用“–driver-class-path”参数指定依赖JAR包的路径，而且必须把”/usr/local/hbase/conf”也加到路径中。<br>执行后得到如下结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Students RDD Count:2</div><div class="line">Row key:1 Name:Xueqian Gender:F Age:23</div><div class="line">Row key:2 Name:Weiliang Gender:M Age:24</div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="编写程序向HBase写入数据"><a href="#编写程序向HBase写入数据" class="headerlink" title="编写程序向HBase写入数据"></a>编写程序向HBase写入数据</h2></div>
<p>下面编写程序向HBase中写入两行数据。<br>请打开一个Linux终端，输入如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/hbase</div><div class="line">vim src/main/scala/SparkWriteHBase.scala</div></pre></td></tr></table></figure></p>
<p>上面命令用vim编辑器新建了一个文件SparkWriteHBase.scala，然后，在SparkWriteHBase.scala文件中输入下面代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span>  </div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableOutputFormat</span>  </div><div class="line"><span class="keyword">import</span> org.apache.spark._  </div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.<span class="type">Job</span>  </div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span>  </div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Result</span>  </div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Put</span>  </div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span>  </div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkWriteHBase</span> </span>&#123;  </div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;  </div><div class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"SparkWriteHBase"</span>).setMaster(<span class="string">"local"</span>)  </div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)        </div><div class="line">    <span class="keyword">val</span> tablename = <span class="string">"student"</span>        </div><div class="line">    sc.hadoopConfiguration.set(<span class="type">TableOutputFormat</span>.<span class="type">OUTPUT_TABLE</span>, tablename)  </div><div class="line"></div><div class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">Job</span>(sc.hadoopConfiguration)  </div><div class="line">    job.setOutputKeyClass(classOf[<span class="type">ImmutableBytesWritable</span>])  </div><div class="line">    job.setOutputValueClass(classOf[<span class="type">Result</span>])    </div><div class="line">    job.setOutputFormatClass(classOf[<span class="type">TableOutputFormat</span>[<span class="type">ImmutableBytesWritable</span>]])    </div><div class="line"></div><div class="line">    <span class="keyword">val</span> indataRDD = sc.makeRDD(<span class="type">Array</span>(<span class="string">"3,Rongcheng,M,26"</span>,<span class="string">"4,Guanhua,M,27"</span>)) <span class="comment">//构建两行记录</span></div><div class="line">    <span class="keyword">val</span> rdd = indataRDD.map(_.split(',')).map&#123;arr=&gt;&#123;  </div><div class="line">      <span class="keyword">val</span> put = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(arr(<span class="number">0</span>))) <span class="comment">//行健的值 </span></div><div class="line">      put.add(<span class="type">Bytes</span>.toBytes(<span class="string">"info"</span>),<span class="type">Bytes</span>.toBytes(<span class="string">"name"</span>),<span class="type">Bytes</span>.toBytes(arr(<span class="number">1</span>)))  <span class="comment">//info:name列的值</span></div><div class="line">      put.add(<span class="type">Bytes</span>.toBytes(<span class="string">"info"</span>),<span class="type">Bytes</span>.toBytes(<span class="string">"gender"</span>),<span class="type">Bytes</span>.toBytes(arr(<span class="number">2</span>)))  <span class="comment">//info:gender列的值</span></div><div class="line">            put.add(<span class="type">Bytes</span>.toBytes(<span class="string">"info"</span>),<span class="type">Bytes</span>.toBytes(<span class="string">"age"</span>),<span class="type">Bytes</span>.toBytes(arr(<span class="number">3</span>).toInt))  <span class="comment">//info:age列的值</span></div><div class="line">      (<span class="keyword">new</span> <span class="type">ImmutableBytesWritable</span>, put)   </div><div class="line">    &#125;&#125;        </div><div class="line">    rdd.saveAsNewAPIHadoopDataset(job.getConfiguration())  </div><div class="line">  &#125;    </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>保存该文件退出vim编辑器，然后，使用sbt打包编译，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/hbase</div><div class="line">/usr/local/sbt/sbt package</div></pre></td></tr></table></figure></p>
<p>打包成功以后，生成的 jar 包的位置为 /usr/local/spark/mycode/hbase/target/scala-2.11/simple-project_2.11-1.0.jar。实际上，由于之前我们已经编写了另外一个代码文件SparkOperateHBase.scala，所以，simple-project_2.11-1.0.jar中实际包含了SparkOperateHBase.scala和SparkWriteHBase.scala两个代码文件的编译结果（class文件），在运行命令时，可以通过–class后面的名称参数来决定运行哪个程序。<br>最后，通过 spark-submit 运行程序。我们就可以将生成的 jar 包通过 spark-submit 提交到 Spark 中运行了，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/spark/bin/spark-submit --driver-class-path /usr/local/spark/jars/hbase/*:/usr/local/hbase/conf --class &quot;SparkWriteHBase&quot;  /usr/local/spark/mycode/hbase/target/scala-2.11/simple-project_2.11-1.0.jar</div></pre></td></tr></table></figure></p>
<p>执行后，我们可以切换到刚才的HBase终端窗口，在HBase shell中输入如下命令查看结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hbase&gt; scan &apos;student&apos;</div></pre></td></tr></table></figure></p>
<p>得到如下结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">ROW                                    COLUMN+CELL                                                                                                   </div><div class="line"> 1                                     column=info:age, timestamp=1479640712163, value=23                                                            </div><div class="line"> 1                                     column=info:gender, timestamp=1479640704522, value=F                                                          </div><div class="line"> 1                                     column=info:name, timestamp=1479640696132, value=Xueqian                                                      </div><div class="line"> 2                                     column=info:age, timestamp=1479640752474, value=24                                                            </div><div class="line"> 2                                     column=info:gender, timestamp=1479640745276, value=M                                                          </div><div class="line"> 2                                     column=info:name, timestamp=1479640732763, value=Weiliang                                                     </div><div class="line"> 3                                     column=info:age, timestamp=1479643273142, value=\x00\x00\x00\x1A                                              </div><div class="line"> 3                                     column=info:gender, timestamp=1479643273142, value=M                                                          </div><div class="line"> 3                                     column=info:name, timestamp=1479643273142, value=Rongcheng                                                    </div><div class="line"> 4                                     column=info:age, timestamp=1479643273142, value=\x00\x00\x00\x1B                                              </div><div class="line"> 4                                     column=info:gender, timestamp=1479643273142, value=M                                                          </div><div class="line"> 4                                     column=info:name, timestamp=1479643273142, value=Guanhua                                                      </div><div class="line">4 row(s) in 0.3240 seconds</div></pre></td></tr></table></figure></p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> HBase </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第三章 第四节 Spark 文件数据读写]]></title>
      <url>http://Melodylican.github.io/2017/02/27/Spark%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/</url>
      <content type="html"><![CDATA[<p>除了可以对本地文件系统进行读写以外，Spark还支持很多其他常见的文件格式（如文本文件、JSON、SequenceFile等）和文件系统（如HDFS、Amazon S3等）和数据库（如MySQL、HBase、Hive等）。数据库的读写我们将在Spark SQL部分介绍，因此，这里只介绍文件系统的读写和不同文件格式的读写。<br><a id="more"></a><br>请进入Linux系统，打开“终端”，进入Shell命令提示符状态，然后，在“/usr/local/spark/mycode”目录下，新建一个wordcount子目录（如果已经存在就不用创建），并在“/usr/local/spark/mycode/wordcount”目录下新建一个包含了一些语句的文本文件word.txt（你可以在文本文件中随意输入一些单词，用空格隔开）。</p>
<p>首先，请登录Linux系统(要注意记住登录采用的用户名，本教程统一采用hadoop用户名进行登录)，打开“终端”（可以在Linux系统中使用Ctrl+Alt+T组合键开启终端），进入shell命令提示符状态，然后执行以下命令进入spark-shell：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell</div><div class="line">....#这里省略启动过程显示的一大堆信息</div><div class="line">scala&gt;</div></pre></td></tr></table></figure></p>
<p>启动进入spark-shell需要一点时间，在进入spark-shell后，我们可能还需要到Linux文件系统中对相关目录下的文件进行编辑和操作（比如要查看spark程序执行过程生成的文件），这个无法在park-shell中完成，因此，这里再打开第二个终端，用来在Linux系统的Shell命令提示符下操作。<br><div class="note success"><h2 id="文件系统的数据读写"><a href="#文件系统的数据读写" class="headerlink" title="文件系统的数据读写"></a>文件系统的数据读写</h2></div><br>下面分别介绍本地文件系统的数据读写和分布式文件系统HDFS的数据读写。<br><div class="note success"><h3 id="本地文件系统的数据读写"><a href="#本地文件系统的数据读写" class="headerlink" title="本地文件系统的数据读写"></a>本地文件系统的数据读写</h3></div><br>首先，请在第二个终端窗口下操作，用下面命令到达“/usr/local/spark/mycode/wordcount”目录，查看一下上面已经建好的word.txt的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/wordcount</div><div class="line">cat word.txt</div></pre></td></tr></table></figure></p>
<p>cat命令会把word.txt文件的内容全部显示到屏幕上。</p>
<p>现有让我们切换回到第一个终端，也就是spark-shell，然后输入下面命令：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>上面代码中，val后面的是变量textFile，而sc.textFile()中的这个textFile是sc的一个方法名称，这个方法用来加载文件数据。这两个textFile不是一个东西，不要混淆。实际上，val后面的是变量textFile，你完全可以换个变量名称，比如,val lines = sc.textFile(“file:///usr/local/spark/mycode/wordcount/word.txt”)。这里使用相同名称，就是有意强调二者的区别。<br>注意，要加载本地文件，必须采用“file:///”开头的这种格式。执行上上面这条命令以后，并不会马上显示结果，因为，Spark采用惰性机制，只有遇到“行动”类型的操作，才会从头到尾执行所有操作。所以，下面我们执行一条“行动”类型的语句，就可以看到结果：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; textFile.first()</div></pre></td></tr></table></figure></p>
<p>first()是一个“行动”（Action）类型的操作，会启动真正的计算过程，从文件中加载数据到变量textFile中，并取出第一行文本。屏幕上会显示很多反馈信息，这里不再给出，你可以从这些结果信息中，找到word.txt文件中的第一行的内容。</p>
<p>正因为Spark采用了惰性机制，在执行转换操作的时候，即使我们输入了错误的语句，spark-shell也不会马上报错，而是等到执行“行动”类型的语句时启动真正的计算，那个时候“转换”操作语句中的错误就会显示出来，比如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word123.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>上面我们使用了一个根本就不存在的word123.txt，执行上面语句时，spark-shell根本不会报错，因为，没有遇到“行动”类型的first()操作之前，这个加载操作时不会真正执行的。然后，我们执行一个“行动”类型的操作first()，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; textFile.first()</div></pre></td></tr></table></figure></p>
<p>执行上面语句后，你会发现，会返回错误信息，其中有四个醒目的中文文字“拒绝连接”，因为，这个word123.txt文件根本就不存在。</p>
<p>好了，现在我们可以练习一下如何把textFile变量中的内容再次写回到另外一个文本文件wordback.txt中：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span>)</div><div class="line">scala&gt; textFile.saveAsTextFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/writeback.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>saveAsTextFile()是一个“行动”（Action）类型的操作，所以，马上会执行真正的计算过程，从word.txt中加载数据到变量textFile中，然后，又把textFile中的数据写回到writeback.txt中。现在我们到/usr/local/spark/mycode/wordcount/目录看一下，会发现，确实多了一个writeback.txt，但是，和我们预期的不一样，它不是一个文件，而是一个文件夹（writeback.txt作为文件夹名称当然是没有问题的，虽然不符合我们平时的习惯）。现在让我们切换到Linux Shell命令提示符窗口中，执行下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/wordcount/writeback.txt/</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p>执行结果中可以看到，writeback.txt这个目录下面包含两个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">part-00000</div><div class="line">_SUCCESS</div></pre></td></tr></table></figure></p>
<p>也就是说，该目录下包含两个文件，我们可以使用cat命令查看一下part-00000文件（注意:part-后面是五个零）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat part-00000</div></pre></td></tr></table></figure></p>
<p>显示结果，是和上面word.txt中的内容一样的。<br>现在的问题是，我们如果想再次把数据加载在RDD中，应该使用哪个文件呢？答案很简单，只要使用writeback.txt这个目录即可，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/writeback.txt"</span>)</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="分布式文件系统HDFS的数据读写"><a href="#分布式文件系统HDFS的数据读写" class="headerlink" title="分布式文件系统HDFS的数据读写"></a>分布式文件系统HDFS的数据读写</h3></div>
<p>为了能够读取HDFS中的文件，请首先启动Hadoop中的HDFS组件。注意，之前我们在“Spark安装”这章内容已经介绍了如何安装Hadoop和Spark，所以，这里我们可以使用以下命令直接启动Hadoop中的HDFS组件（由于用不到MapReduce组件，所以，不需要启动MapReduce或者YARN）。请到第二个终端窗口，使用Linux Shell命令提示符状态，然后输入下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/hadoop</div><div class="line">./sbin/start-dfs.sh</div></pre></td></tr></table></figure></p>
<p>启动结束后，HDFS开始进入可用状态。如果你在HDFS文件系统中，还没有为当前Linux登录用户创建目录(本教程统一使用用户名hadoop登录Linux系统)，请使用下面命令创建：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -mkdir -p /user/hadoop</div></pre></td></tr></table></figure></p>
<p>也就是说，HDFS文件系统为Linux登录用户开辟的默认目录是“/user/用户名”（注意：是user，不是usr），本教程统一使用用户名hadoop登录Linux系统，所以，上面创建了“/user/hadoop”目录，再次强调，这个目录是在HDFS文件系统中，不在本地文件系统中。创建好以后，下面我们使用命令查看一下HDFS文件系统中的目录和文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div></pre></td></tr></table></figure></p>
<p>上面命令中，最后一个点号“.”，表示要查看Linux当前登录用户hadoop在HDFS文件系统中与hadoop对应的目录下的文件，也就是查看HDFS文件系统中“/user/hadoop/”目录下的文件，所以，下面两条命令是等价的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div><div class="line">./bin/hdfs dfs -ls /user/hadoop</div></pre></td></tr></table></figure></p>
<p>如果要查看HDFS文件系统根目录下的内容，需要使用下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls /</div></pre></td></tr></table></figure></p>
<p>下面，我们把本地文件系统中的“/usr/local/spark/mycode/wordcount/word.txt”上传到分布式文件系统HDFS中（放到hadoop用户目录下）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -put /usr/local/spark/mycode/wordcount/word.txt .</div></pre></td></tr></table></figure></p>
<p>然后，用命令查看一下HDFS的hadoop用户目录下是否多了word.txt文件，可以使用下面命令列出hadoop目录下的内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div></pre></td></tr></table></figure></p>
<p>可以看到，确实多了一个word.txt文件，我们使用cat命令查看一个HDFS中的word.txt文件的内容，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -cat ./word.txt</div></pre></td></tr></table></figure></p>
<p>上面命令执行后，就会看到HDFS中word.txt的内容了。</p>
<p>现在，让我们切换回到spark-shell窗口，编写语句从HDFS中加载word.txt文件，并显示第一行文本内容：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"hdfs://localhost:9000/user/hadoop/word.txt"</span>)</div><div class="line">scala&gt; textFile.first()</div></pre></td></tr></table></figure></p>
<p>执行上面语句后，就可以看到HDFS文件系统中（不是本地文件系统）的word.txt的第一行内容了。</p>
<p>需要注意的是，sc.textFile(“hdfs://localhost:9000/user/hadoop/word.txt”)中，“hdfs://localhost:9000/”是前面介绍Hadoop安装内容时确定下来的端口地址9000。实际上，也可以省略不写，如下三条语句都是等价的：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"hdfs://localhost:9000/user/hadoop/word.txt"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"/user/hadoop/word.txt"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"word.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>下面，我们再把textFile的内容写回到HDFS文件系统中（写到hadoop用户目录下）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"word.txt"</span>)</div><div class="line">scala&gt; textFile.saveAsTextFile(<span class="string">"writeback.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>执行上面命令后，文本内容会被写入到HDFS文件系统的“/user/hadoop/writeback.txt”目录下，我们可以切换到Linux Shell命令提示符窗口查看一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div></pre></td></tr></table></figure></p>
<p>执行上述命令后，在执行结果中，可以看到有个writeback.txt目录，下面我们查看该目录下有什么文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls ./writeback.txt</div></pre></td></tr></table></figure></p>
<p>执行结果中，可以看到存在两个文件：part-00000和_SUCCESS。我们使用下面命令输出part-00000文件的内容（注意：part-00000里面有五个零）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -cat ./writeback.txt/part-00000</div></pre></td></tr></table></figure></p>
<p>执行结果中，就可以看到和word.txt文件中一样的文本内容。</p>
<p>当需要再次把writeback.txt中的内容加载到RDD中时，只需要加载writeback.txt目录即可，不需要使用part-00000文件，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"hdfs://localhost:9000/user/hadoop/writeback.txt"</span>)</div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="不同文件格式的读写"><a href="#不同文件格式的读写" class="headerlink" title="不同文件格式的读写"></a>不同文件格式的读写</h2></div>
<div class="note success"><h3 id="文本文件"><a href="#文本文件" class="headerlink" title="文本文件"></a>文本文件</h3></div>
<p>实际上，我们在上面演示的都是文本文件的读写，因此，这里不再赘述，只是简单再总结一下。<br>把本地文件系统中的文本文件加载到RDD中的语句如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> rdd = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>当我们给textFile()函数传递一个“包含完整路径的文件名”时，就会把这个文件加载到RDD中。如果我们给textFile()函数传递的不是文件名，而是一个目录，则该目录下的所有文件内容都会被读取到RDD中。</p>
<p>关于把RDD中的数据保存到文本文件，可以采用采用如下语句：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; rdd.saveAsTextFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/outputFile"</span>)</div></pre></td></tr></table></figure></p>
<p>正像上面我们已经介绍的那样，我们在saveAsTextFile()函数的参数中给出的是目录，不是文件名，RDD中的数据会被保存到给定的目录下。<br><div class="note success"><h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3></div><br>JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。<br>Spark提供了一个JSON样例数据文件，存放在“/usr/local/spark/examples/src/main/resources/people.json”中。people.json文件的内容如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;name&quot;:&quot;Michael&quot;&#125;</div><div class="line">&#123;&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30&#125;</div><div class="line">&#123;&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19&#125;</div></pre></td></tr></table></figure></p>
<p>我们下面可以对这个样例数据文件进行解析。<br>下面请在Linux系统的Shell命令提示符下操作，请进入“/usr/local/spark/mycode”目录，并新建一个json子目录，代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode</div><div class="line">mkdir json</div><div class="line">cd json</div></pre></td></tr></table></figure></p>
<p>在编写解析程序之前，我们首先来看一下把本地文件系统中的people.json文件加载到RDD中以后，数据是什么形式，请在spark-shell中执行如下操作：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> jsonStr = sc.textFile(<span class="string">"file:///usr/local/spark/examples/src/main/resources/people.json"</span>)</div><div class="line">jsonStr: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/examples/src/main/resources/people.json MapPartitionsRDD[3] at textFile at &lt;console&gt;:28</span></div><div class="line">scala&gt; jsonStr.foreach(println)</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"Michael"</span>&#125;</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"Andy"</span>, <span class="string">"age"</span>:<span class="number">30</span>&#125;</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"Justin"</span>, <span class="string">"age"</span>:<span class="number">19</span>&#125;</div></pre></td></tr></table></figure></p>
<p>从上面执行结果可以看出，people.json文件加载到RDD中以后，在RDD中存在三个字符串。我们下面要做的事情，就是把这三个JSON格式的字符串解析出来，比如说，第一个字符串{“name”:”Michael”}，经过解析后，解析得到key是”name”，value是”Michael”。<br>现在我们编写程序完成对上面字符串的解析工作。<br>Scala中有一个自带的JSON库——scala.util.parsing.json.JSON，可以实现对JSON数据的解析。JSON.parseFull(jsonString:String)函数，以一个JSON字符串作为输入并进行解析，如果解析成功则返回一个Some(map: Map[String, Any])，如果解析失败则返回None。<br>因此，我们可以使用模式匹配来处理解析结果（备注：关于模式匹配，请参考前面的教程：模式匹配）：</p>
<p>请执行以下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/json</div><div class="line">mkdir -p src/main/scala</div><div class="line">cd src/main/scala</div><div class="line">vim testjson.scala</div></pre></td></tr></table></figure></p>
<p>在testjson.scala代码文件中输入以下内容：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"><span class="keyword">import</span> scala.util.parsing.json.<span class="type">JSON</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">JSONApp</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">        <span class="keyword">val</span> inputFile =  <span class="string">"file:///usr/local/spark/examples/src/main/resources/people.json"</span></div><div class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"JSONApp"</span>)</div><div class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">        <span class="keyword">val</span> jsonStrs = sc.textFile(inputFile)</div><div class="line">        <span class="keyword">val</span> result = jsonStrs.map(s =&gt; <span class="type">JSON</span>.parseFull(s))</div><div class="line">        result.foreach( &#123;r =&gt; r <span class="keyword">match</span> &#123;</div><div class="line">                        <span class="keyword">case</span> <span class="type">Some</span>(map: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">Any</span>]) =&gt; println(map)</div><div class="line">                        <span class="keyword">case</span> <span class="type">None</span> =&gt; println(<span class="string">"Parsing failed"</span>)</div><div class="line">                        <span class="keyword">case</span> other =&gt; println(<span class="string">"Unknown data structure: "</span> + other)</div><div class="line">                &#125;</div><div class="line">        &#125;</div><div class="line">        )</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>保存退出vim编辑器。这样就生成了一个testjson.scala代码文件。<br>如果testjson.scala没有调用SparkAPI，那么，只要使用scalac命令编译后执行即可。但是，这个testjson.scala程序依赖Spark API，因此我们需要通过sbt进行编译打包（前面的“Spark的安装和使用”这个章节已经介绍过如何使用sbt进行编译打包）。下面我们再演示一次。</p>
<p>请执行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/json</div><div class="line">vim simple.sbt</div></pre></td></tr></table></figure></p>
<p>通过上面代码，新建一个simple.sbt文件，请在该文件中输入下面代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">name := &quot;JSON Project&quot;</div><div class="line"></div><div class="line">version := &quot;1.0&quot;</div><div class="line"></div><div class="line">scalaVersion := &quot;2.11.8&quot;</div></pre></td></tr></table></figure></p>
<p>libraryDependencies += “org.apache.spark” %% “spark-core” % “2.1.0”<br>下面我们使用 sbt 打包 Scala 程序。为保证 sbt 能正常运行，先执行如下命令检查整个应用程序的文件结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/json/</div><div class="line">find .</div></pre></td></tr></table></figure></p>
<p>应该是类似下面的文件结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">./src</div><div class="line">./src/main</div><div class="line">./src/main/scala</div><div class="line">./src/main/scala/testjson.scala</div><div class="line">./simple.sbt</div></pre></td></tr></table></figure></p>
<p>接着，我们就可以通过如下代码将整个应用程序打包成 JAR（首次运行同样需要下载依赖包 ）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark/mycode/json/  //请一定把这目录设置为当前目录</div><div class="line">/usr/local/sbt/sbt package</div></pre></td></tr></table></figure></p>
<p>生成的 jar 包的位置为 /usr/local/spark/mycode/json/target/scala-2.11/json-project_2.11-1.0.jar。<br>最后，通过 spark-submit 运行程序。我们就可以将生成的 jar 包通过 spark-submit 提交到 Spark 中运行了，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/spark/bin/spark-submit --class &quot;JSONApp&quot;  /usr/local/spark/mycode/json/target/scala-2.11/json-project_2.11-1.0.jar</div></pre></td></tr></table></figure></p>
<p>执行后可以在屏幕上的大量输出信息中找到如下结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Map(name -&gt; Michael)</div><div class="line">Map(name -&gt; Andy, age -&gt; 30.0)</div><div class="line">Map(name -&gt; Justin, age -&gt; 19.0)</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第三章 第三节 Spark 共享变量]]></title>
      <url>http://Melodylican.github.io/2017/02/25/Spark%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F/</url>
      <content type="html"><![CDATA[<p>Spark中的两个重要抽象是RDD和共享变量。上一章我们已经介绍了RDD，这里介绍共享变量。</p>
<p>在默认情况下，当Spark在集群的多个不同节点的多个任务上并行运行一个函数时，它会把函数中涉及到的每个变量，在每个任务上都生成一个副本。但是，有时候，需要在多个任务之间共享变量，或者在任务（Task）和任务控制节点（Driver Program）之间共享变量。为了满足这种需求，Spark提供了两种类型的变量：广播变量（broadcast variables）和累加器（accumulators）。广播变量用来把变量在所有节点的内存之间进行共享。累加器则支持在所有不同节点之间进行累加计算（比如计数或者求和）。<br><a id="more"></a><br><div class="note success"><h2 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h2></div><br>广播变量（broadcast variables）允许程序开发人员在每个机器上缓存一个只读的变量，而不是为机器上的每个任务都生成一个副本。通过这种方式，就可以非常高效地给每个节点（机器）提供一个大的输入数据集的副本。Spark的“动作”操作会跨越多个阶段（stage），对于每个阶段内的所有任务所需要的公共数据，Spark都会自动进行广播。通过广播方式进行传播的变量，会经过序列化，然后在被任务使用时再进行反序列化。这就意味着，显式地创建广播变量只有在下面的情形中是有用的：当跨越多个阶段的那些任务需要相同的数据，或者当以反序列化方式对数据进行缓存是非常重要的。</p>
<p>可以通过调用SparkContext.broadcast(v)来从一个普通变量v中创建一个广播变量。这个广播变量就是对普通变量v的一个包装器，通过调用value方法就可以获得这个广播变量的值，具体代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> broadcastVar = sc.broadcast(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</div><div class="line">broadcastVar: org.apache.spark.broadcast.<span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Broadcast</span>(<span class="number">0</span>)</div><div class="line">scala&gt; broadcastVar.value</div><div class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</div></pre></td></tr></table></figure></p>
<p>这个广播变量被创建以后，那么在集群中的任何函数中，都应该使用广播变量broadcastVar的值，而不是使用v的值，这样就不会把v重复分发到这些节点上。此外，一旦广播变量创建后，普通变量v的值就不能再发生修改，从而确保所有节点都获得这个广播变量的相同的值。</p>
<div class="note success"><h2 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h2></div>
<p>累加器是仅仅被相关操作累加的变量，通常可以被用来实现计数器（counter）和求和（sum）。Spark原生地支持数值型（numeric）的累加器，程序开发人员可以编写对新类型的支持。如果创建累加器时指定了名字，则可以在Spark UI界面看到，这有利于理解每个执行阶段的进程。<br>一个数值型的累加器，可以通过调用SparkContext.longAccumulator()或者SparkContext.doubleAccumulator()来创建。运行在集群中的任务，就可以使用add方法来把数值累加到累加器上，但是，这些任务只能做累加操作，不能读取累加器的值，只有任务控制节点（Driver Program）可以使用value方法来读取累加器的值。<br>下面是一个代码实例，演示了使用累加器来对一个数组中的元素进行求和：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> accum = sc.longAccumulator(<span class="string">"My Accumulator"</span>)</div><div class="line">accum: org.apache.spark.util.<span class="type">LongAccumulator</span> = <span class="type">LongAccumulator</span>(id: <span class="number">0</span>, name: <span class="type">Some</span>(<span class="type">My</span> <span class="type">Accumulator</span>), value: <span class="number">0</span>)</div><div class="line">scala&gt; sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)).foreach(x =&gt; accum.add(x))</div><div class="line">scala&gt; accum.value</div><div class="line">res1: <span class="type">Long</span> = <span class="number">10</span></div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第三章 第二节 键值对RDD]]></title>
      <url>http://Melodylican.github.io/2017/02/24/%E9%94%AE%E5%80%BC%E5%AF%B9RDD/</url>
      <content type="html"><![CDATA[<p>虽然RDD中可以包含任何类型的对象，但是“键值对”是一种比较常见的RDD元素类型，分组和聚合操作中经常会用到。<br>Spark操作中经常会用到“键值对RDD”（Pair RDD），用于完成聚合计算。普通RDD里面存储的数据类型是Int、String等，而“键值对RDD”里面存储的数据类型是“键值对”。<br><a id="more"></a></p>
<div class="note success"><h2 id="创建RDD之前的准备工作"><a href="#创建RDD之前的准备工作" class="headerlink" title="创建RDD之前的准备工作"></a>创建RDD之前的准备工作</h2></div>
<p>在即将进行相关的实践操作之前，我们首先要登录Linux系统（本教程统一采用hadoop用户登录），然后，打开命令行“终端”，请按照下面的命令启动Hadoop中的HDFS组件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span>  /usr/<span class="built_in">local</span>/hadoop</div><div class="line">./sbin/start-dfs.sh</div></pre></td></tr></table></figure></p>
<p>然后，我们按照下面命令启动spark-shell：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark</div><div class="line">./bin/spark-shell</div></pre></td></tr></table></figure></p>
<p>然后，新建第二个“终端”，方法是，在前面已经建设的第一个终端窗口的左上方，点击“终端”菜单，在弹出的子菜单中选择“新建终端”，就可以打开第二个终端窗口，现在，我们切换到第二个终端窗口，在第二个终端窗口中，执行以下命令，进入之前已经创建好的“/usr/local/spark/mycode/”目录，在这个目录下新建pairrdd子目录，用来存放本章的代码和相关文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/</div><div class="line">mkdir pairrdd</div></pre></td></tr></table></figure></p>
<p>然后，使用vim编辑器，在pairrdd目录下新建一个word.txt文件，你可以在文件里面随便输入几行英文语句用来测试。</p>
<p>经过上面的准备工作以后，我们就可以开始创建RDD了。</p>
<div class="note success"><h2 id="键值对RDD的创建"><a href="#键值对RDD的创建" class="headerlink" title="键值对RDD的创建"></a>键值对RDD的创建</h2></div>
<div class="note success"><h3 id="第一种创建方式：从文件中加载"><a href="#第一种创建方式：从文件中加载" class="headerlink" title="第一种创建方式：从文件中加载"></a>第一种创建方式：从文件中加载</h3></div>
<p>我们可以采用多种方式创建键值对RDD，其中一种主要方式是使用map()函数来实现，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">scala&gt;  <span class="keyword">val</span> lines = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/pairrdd/word.txt"</span>)</div><div class="line">lines: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/mycode/pairrdd/word.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:27</span></div><div class="line">scala&gt; <span class="keyword">val</span> pairRDD = lines.flatMap(line =&gt; line.split(<span class="string">" "</span>)).map(word =&gt; (word,<span class="number">1</span>))</div><div class="line">pairRDD: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">3</span>] at map at &lt;console&gt;:<span class="number">29</span></div><div class="line">scala&gt; pairRDD.foreach(println)</div><div class="line">(i,<span class="number">1</span>)</div><div class="line">(love,<span class="number">1</span>)</div><div class="line">(hadoop,<span class="number">1</span>)</div><div class="line">(i,<span class="number">1</span>)</div><div class="line">(love,<span class="number">1</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">1</span>)</div><div class="line">(is,<span class="number">1</span>)</div><div class="line">(fast,<span class="number">1</span>)</div><div class="line">(than,<span class="number">1</span>)</div><div class="line">(hadoop,<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>我们之前在“第一个Spark应用程序:WordCount”章节已经详细解释过类似代码，所以，上面代码不再做细节分析。从代码执行返回信息：pairRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[3] at map at :29，可以看出，返回的结果是键值对类型的RDD，即RDD[(String, Int)]。从pairRDD.foreach(println)执行的打印输出结果也可以看到，都是由(单词,1)这种形式的键值对。</p>
<div class="note success"><h3 id="第二种创建方式：通过并行集合（数组）创建RDD"><a href="#第二种创建方式：通过并行集合（数组）创建RDD" class="headerlink" title="第二种创建方式：通过并行集合（数组）创建RDD"></a>第二种创建方式：通过并行集合（数组）创建RDD</h3></div>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> list = <span class="type">List</span>(<span class="string">"Hadoop"</span>,<span class="string">"Spark"</span>,<span class="string">"Hive"</span>,<span class="string">"Spark"</span>)</div><div class="line">list: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="type">Hadoop</span>, <span class="type">Spark</span>, <span class="type">Hive</span>, <span class="type">Spark</span>)</div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(list)</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">11</span>] at parallelize at &lt;console&gt;:<span class="number">29</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> pairRDD = rdd.map(word =&gt; (word,<span class="number">1</span>))</div><div class="line">pairRDD: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">12</span>] at map at &lt;console&gt;:<span class="number">31</span></div><div class="line"> </div><div class="line">scala&gt; pairRDD.foreach(println)</div><div class="line">(<span class="type">Hadoop</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Hive</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">1</span>)</div></pre></td></tr></table></figure>
<p>我们下面实例都是采用这种方式得到的pairRDD作为基础。</p>
<div class="note success"><h2 id="常用的键值对转换操作"><a href="#常用的键值对转换操作" class="headerlink" title="常用的键值对转换操作"></a>常用的键值对转换操作</h2></div>
<p>常用的键值对转换操作包括reduceByKey()、groupByKey()、sortByKey()、join()、cogroup()等，下面我们通过实例来介绍。<br><div class="note success"><h3 id="reduceByKey-func"><a href="#reduceByKey-func" class="headerlink" title="reduceByKey(func)"></a>reduceByKey(func)</h3></div><br>reduceByKey(func)的功能是，使用func函数合并具有相同键的值。比如，reduceByKey((a,b) =&gt; a+b)，有四个键值对(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)，对具有相同key的键值对进行合并后的结果就是：(“spark”,3)、(“hadoop”,8)。可以看出，(a,b) =&gt; a+b这个Lamda表达式中，a和b都是指value，比如，对于两个具有相同key的键值对(“spark”,1)、(“spark”,2)，a就是1，b就是2。<br>我们对上面第二种方式创建得到的pairRDD进行reduceByKey()操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt; pairRDD.reduceByKey((a,b)=&gt;a+b).foreach(println)</div><div class="line">(<span class="type">Spark</span>,<span class="number">2</span>)</div><div class="line">(<span class="type">Hive</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Hadoop</span>,<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey()"></a>groupByKey()</h3></div>
<p>groupByKey()的功能是，对具有相同键的值进行分组。比如，对四个键值对(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)，采用groupByKey()后得到的结果是：(“spark”,(1,2))和(“hadoop”,(3,5))。<br>我们对上面第二种方式创建得到的pairRDD进行groupByKey()操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">scala&gt; pairRDD.groupByKey()</div><div class="line">res15: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Iterable</span>[<span class="type">Int</span>])] = <span class="type">ShuffledRDD</span>[<span class="number">15</span>] at groupByKey at &lt;console&gt;:<span class="number">34</span></div><div class="line"><span class="comment">//从上面执行结果信息中可以看出，分组后，value被保存到Iterable[Int]中</span></div><div class="line">scala&gt; pairRDD.groupByKey().foreach(println)</div><div class="line">(<span class="type">Spark</span>,<span class="type">CompactBuffer</span>(<span class="number">1</span>, <span class="number">1</span>))</div><div class="line">(<span class="type">Hive</span>,<span class="type">CompactBuffer</span>(<span class="number">1</span>))</div><div class="line">(<span class="type">Hadoop</span>,<span class="type">CompactBuffer</span>(<span class="number">1</span>))</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h3></div>
<p>keys只会把键值对RDD中的key返回形成一个新的RDD。比如，对四个键值对(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)构成的RDD，采用keys后得到的结果是一个RDD[Int]，内容是{“spark”,”spark”,”hadoop”,”hadoop”}。<br>我们对上面第二种方式创建得到的pairRDD进行keys操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">scala&gt; pairRDD.keys</div><div class="line">res17: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">17</span>] at keys at &lt;console&gt;:<span class="number">34</span></div><div class="line">scala&gt; pairRDD.keys.foreach(println)</div><div class="line"><span class="type">Hadoop</span></div><div class="line"><span class="type">Spark</span></div><div class="line"><span class="type">Hive</span></div><div class="line"><span class="type">Spark</span></div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="values"><a href="#values" class="headerlink" title="values"></a>values</h3></div>
<p>values只会把键值对RDD中的value返回形成一个新的RDD。比如，对四个键值对(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)构成的RDD，采用keys后得到的结果是一个RDD[Int]，内容是{1,2,3,5}。<br>我们对上面第二种方式创建得到的pairRDD进行values操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">scala&gt; pairRDD.values</div><div class="line">res0: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">2</span>] at values at &lt;console&gt;:<span class="number">34</span></div><div class="line"> </div><div class="line">scala&gt; pairRDD.values.foreach(println)</div><div class="line"><span class="number">1</span></div><div class="line"><span class="number">1</span></div><div class="line"><span class="number">1</span></div><div class="line"><span class="number">1</span></div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey()"></a>sortByKey()</h3></div>
<p>sortByKey()的功能是返回一个根据键排序的RDD。<br>我们对上面第二种方式创建得到的pairRDD进行keys操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">scala&gt; pairRDD.sortByKey()</div><div class="line">res0: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ShuffledRDD</span>[<span class="number">2</span>] at sortByKey at &lt;console&gt;:<span class="number">34</span></div><div class="line">scala&gt; pairRDD.sortByKey().foreach(println)</div><div class="line">(<span class="type">Hadoop</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Hive</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">1</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="mapValues-func"><a href="#mapValues-func" class="headerlink" title="mapValues(func)"></a>mapValues(func)</h3></div>
<p>我们经常会遇到一种情形，我们只想对键值对RDD的value部分进行处理，而不是同时对key和value进行处理。对于这种情形，Spark提供了mapValues(func)，它的功能是，对键值对RDD中的每个value都应用一个函数，但是，key不会发生变化。比如，对四个键值对(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)构成的pairRDD，如果执行pairRDD.mapValues(x =&gt; x+1)，就会得到一个新的键值对RDD，它包含下面四个键值对(“spark”,2)、(“spark”,3)、(“hadoop”,4)和(“hadoop”,6)。<br>我们对上面第二种方式创建得到的pairRDD进行keys操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">scala&gt; pairRDD.mapValues(x =&gt; x+<span class="number">1</span>)</div><div class="line">res2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">4</span>] at mapValues at &lt;console&gt;:<span class="number">34</span></div><div class="line">scala&gt; pairRDD.mapValues(x =&gt; x+<span class="number">1</span>).foreach(println)</div><div class="line">(<span class="type">Hadoop</span>,<span class="number">2</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">2</span>)</div><div class="line">(<span class="type">Hive</span>,<span class="number">2</span>)</div><div class="line">(<span class="type">Spark</span>,<span class="number">2</span>)</div></pre></td></tr></table></figure></p>
<div class="note success"><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3></div>
<p>join(连接)操作是键值对常用的操作。“连接”(join)这个概念来自于关系数据库领域，因此，join的类型也和关系数据库中的join一样，包括内连接(join)、左外连接(leftOuterJoin)、右外连接(rightOuterJoin)等。最常用的情形是内连接，所以，join就表示内连接。<br>对于内连接，对于给定的两个输入数据集(K,V1)和(K,V2)，只有在两个数据集中都存在的key才会被输出，最终得到一个(K,(V1,V2))类型的数据集。</p>
<p>比如，pairRDD1是一个键值对集合{(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)}，pairRDD2是一个键值对集合{(“spark”,”fast”)}，那么，pairRDD1.join(pairRDD2)的结果就是一个新的RDD，这个新的RDD是键值对集合{(“spark”,1,”fast”),(“spark”,2,”fast”)}。对于这个实例，我们下面在spark-shell中运行一下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> pairRDD1 = sc.parallelize(<span class="type">Array</span>((<span class="string">"spark"</span>,<span class="number">1</span>),(<span class="string">"spark"</span>,<span class="number">2</span>),(<span class="string">"hadoop"</span>,<span class="number">3</span>),(<span class="string">"hadoop"</span>,<span class="number">5</span>)))</div><div class="line">pairRDD1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">24</span>] at parallelize at &lt;console&gt;:<span class="number">27</span></div><div class="line"> </div><div class="line">scala&gt; <span class="keyword">val</span> pairRDD2 = sc.parallelize(<span class="type">Array</span>((<span class="string">"spark"</span>,<span class="string">"fast"</span>)))</div><div class="line">pairRDD2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">25</span>] at parallelize at &lt;console&gt;:<span class="number">27</span></div><div class="line"> </div><div class="line">scala&gt; pairRDD1.join(pairRDD2)</div><div class="line">res9: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">String</span>))] = <span class="type">MapPartitionsRDD</span>[<span class="number">28</span>] at join at &lt;console&gt;:<span class="number">32</span></div><div class="line"> </div><div class="line">scala&gt; pairRDD1.join(pairRDD2).foreach(println)</div><div class="line">(spark,(<span class="number">1</span>,fast))</div><div class="line">(spark,(<span class="number">2</span>,fast))</div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="一个综合实例"><a href="#一个综合实例" class="headerlink" title="一个综合实例"></a>一个综合实例</h2></div>
<p>题目：给定一组键值对(“spark”,2),(“hadoop”,6),(“hadoop”,4),(“spark”,6)，键值对的key表示图书名称，value表示某天图书销量，请计算每个键对应的平均值，也就是计算每种图书的每天平均销量。<br>很显然，对于上面的题目，结果是很显然的，(“spark”,4),(“hadoop”,5)。<br>下面，我们在spark-shell中演示代码执行过程：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="string">"spark"</span>,<span class="number">2</span>),(<span class="string">"hadoop"</span>,<span class="number">6</span>),(<span class="string">"hadoop"</span>,<span class="number">4</span>),(<span class="string">"spark"</span>,<span class="number">6</span>)))</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">38</span>] at parallelize at &lt;console&gt;:<span class="number">27</span></div><div class="line"> </div><div class="line">scala&gt; rdd.mapValues(x =&gt; (x,<span class="number">1</span>)).reduceByKey((x,y) =&gt; (x._1+y._1,x._2 + y._2)).mapValues(x =&gt; (x._1 / x._2)).collect()</div><div class="line">res22: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((spark,<span class="number">4</span>), (hadoop,<span class="number">5</span>))</div></pre></td></tr></table></figure></p>
<p>要注意，上面语句中，mapValues(x =&gt; (x,1))中出现了变量x，reduceByKey((x,y) =&gt; (x._1+y._1,x._2 + y._2))中也出现了变量x，mapValues(x =&gt; (x._1 / x._2))也出现了变量x。但是，必须要清楚，这三个地方出现的x，虽然都具有相同的变量名称x，但是，彼此之间没有任何关系，它们都处在不同的变量作用域内。如果你觉得这样会误导自己，造成理解上的掌握，实际上，你可以把三个出现x的地方分别替换成x1、x2、x3也是可以的，但是，很显然没有必要这么做。<br>上面是完整的语句和执行过程，可能不太好理解，下面我们进行逐条语句分解给大家介绍。每条语句执行后返回的屏幕信息，可以帮助大家更好理解语句的执行效果，比如生成了什么类型的RDD。</p>
<p>（1）首先构建一个数组，数组里面包含了四个键值对，然后，调用parallelize()方法生成RDD，从执行结果反馈信息，可以看出，rdd类型是RDD[(String, Int)]。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="string">"spark"</span>,<span class="number">2</span>),(<span class="string">"hadoop"</span>,<span class="number">6</span>),(<span class="string">"hadoop"</span>,<span class="number">4</span>),(<span class="string">"spark"</span>,<span class="number">6</span>)))</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">38</span>] at parallelize at &lt;console&gt;:<span class="number">27</span></div></pre></td></tr></table></figure></p>
<p>（2）针对构建得到的rdd，我们调用mapValues()函数，把rdd中的每个每个键值对(key,value)的value部分进行修改，把value转换成键值对(value,1)，其中，数值1表示这个key在rdd中出现了1次，为什么要记录出现次数呢？因为，我们最终要计算每个key对应的平均值，所以，必须记住这个key出现了几次，最后用value的总和除以key的出现次数，就是这个key对应的平均值。比如，键值对(“spark”,2)经过mapValues()函数处理后，就变成了(“spark”,(2,1))，其中，数值1表示“spark”这个键的1次出现。下面就是rdd.mapValues()操作在spark-shell中的执行演示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; rdd.mapValues(x =&gt; (x,<span class="number">1</span>)).collect()</div><div class="line">res23: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">Array</span>((spark,(<span class="number">2</span>,<span class="number">1</span>)), (hadoop,(<span class="number">6</span>,<span class="number">1</span>)), (hadoop,(<span class="number">4</span>,<span class="number">1</span>)), (spark,(<span class="number">6</span>,<span class="number">1</span>)))</div></pre></td></tr></table></figure></p>
<p>上面语句中，collect()是一个行动操作，功能是以数组的形式返回数据集中的所有元素，当我们要实时查看一个RDD中的元素内容时，就可以调用collect()函数。</p>
<p>（3）然后，再对上一步得到的RDD调用reduceByKey()函数，在spark-shell中演示如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; rdd.mapValues(x =&gt; (x,<span class="number">1</span>)).reduceByKey((x,y) =&gt; (x._1+y._1,x._2 + y._2)).collect()</div><div class="line">res24: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">Array</span>((spark,(<span class="number">8</span>,<span class="number">2</span>)), (hadoop,(<span class="number">10</span>,<span class="number">2</span>)))</div></pre></td></tr></table></figure></p>
<p>这里，必须要十分准确地理解reduceByKey()函数的功能。可以参考上面我们对该函数的介绍，reduceByKey(func)的功能是使用func函数合并具有相同键的值。这里的func函数就是Lamda表达式(x,y) =&gt; (x._1+y._1,x._2 + y._2)，这个表达式中，x和y都是value，而且是具有相同key的两个键值对所对应的value，比如，在这个例子中， (“hadoop”,(6,1))和(“hadoop”,(4,1))这两个键值对具有相同的key，所以，对于函数中的输入参数(x,y)而言，x就是(6,1)，x._1表示这个键值对中的第1个元素6，x._2表示这个键值对中的第二个元素1，y就是(4,1)，y._1表示这个键值对中的第1个元素4，y._2表示这个键值对中的第二个元素1，所以，函数体(x._1+y._1,x._2 + y._2)，相当于生成一个新的键值对(key,value)，其中，key是x._1+y._1，也就是6+4=10，value是x._2 + y._2，也就是1+1=2，因此，函数体(x._1+y._1,x._2 + y._2)执行后得到的value是(10,2)，但是，要注意，这个(10,2)是reduceByKey()函数执行后，”hadoop”这个key对应的value，也就是，实际上reduceByKey()函数执行后，会生成一个键值对(“hadoop”,(10,2))，其中，10表示hadoop书籍的总销量，2表示两天。同理，reduceByKey()函数执行后会生成另外一个键值对(“spark”,(8,2))。</p>
<p>(4)最后，就可以求出最终结果。我们可以对上面得到的两个键值对(“hadoop”,(10,2))和(“spark”,(8,2))所构成的RDD执行mapValues()操作，得到每种书的每天平均销量。当第一个键值对(“hadoop”,(10,2))输入给mapValues(x =&gt; (x._1 / x._2))操作时，key是”hadoop”，保持不变，value是(10,2)，会被赋值给Lamda表达式x =&gt; (x._1 / x._2中的x，因此，x的值就是(10,2)，x._1就是10，表示hadoop书总销量是10，x._2就是2，表示2天，因此，hadoop书籍的每天平均销量就是x._1 / x._2，也就是5。mapValues()输出的一个键值对就是(“hadoop”,5)。同理，当把(“spark”,(8,2))输入给mapValues()时，会计算得到另外一个键值对(“spark”,4)。在spark-shell中演示如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; rdd.mapValues(x =&gt; (x,<span class="number">1</span>)).reduceByKey((x,y) =&gt; (x._1+y._1,x._2 + y._2)).mapValues(x =&gt; (x._1 / x._2)).collect()</div><div class="line">res25: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((spark,<span class="number">4</span>), (hadoop,<span class="number">5</span>))</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第三章 第一节 RDD编程]]></title>
      <url>http://Melodylican.github.io/2017/02/22/RDD%E7%BC%96%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>通过前面几章的介绍，我们已经了解了Spark的运行架构和RDD设计与运行原理，并介绍了RDD操作的两种类型：转换操作和行动操作。<br>同时，我们前面通过一个简单的WordCount实例，也大概介绍了RDD的几种简单操作。现在我们介绍更多关于RDD编程的内容。<br>Spark中针对RDD的操作包括创建RDD、RDD转换操作和RDD行动操作。<br><a id="more"></a><br><div class="note success"><h2 id="RDD创建"><a href="#RDD创建" class="headerlink" title="RDD创建"></a>RDD创建</h2></div><br>RDD可以通过两种方式创建：</p>
<ul>
<li>第一种：读取一个外部数据集。比如，从本地文件加载数据集，或者从HDFS文件系统、HBase、Cassandra、Amazon S3等外部数据源中加载数据集。Spark可以支持文本文件、SequenceFile文件（Hadoop提供的 SequenceFile是一个由二进制序列化过的key/value的字节流组成的文本存储文件）和其他符合Hadoop InputFormat格式的文件。</li>
<li>第二种：调用SparkContext的parallelize方法，在Driver中一个已经存在的集合（数组）上创建。</li>
</ul>
<div class="note success"><h2 id="创建RDD之前的准备工作"><a href="#创建RDD之前的准备工作" class="headerlink" title="创建RDD之前的准备工作"></a>创建RDD之前的准备工作</h2></div>
<p>在即将进行相关的实践操作之前，我们首先要登录Linux系统（本教程统一采用hadoop用户登录），然后，打开命令行“终端”，请按照下面的命令启动Hadoop中的HDFS组件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span>  /usr/<span class="built_in">local</span>/hadoop</div><div class="line">./sbin/start-dfs.sh</div></pre></td></tr></table></figure></p>
<p>然后，我们按照下面命令启动spark-shell：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark</div><div class="line">./bin/spark-shell</div></pre></td></tr></table></figure></p>
<p>然后，新建第二个“终端”，方法是，在前面已经建设的第一个终端窗口的左上方，点击“终端”菜单，在弹出的子菜单中选择“新建终端”，就可以打开第二个终端窗口，现在，我们切换到第二个终端窗口，在第二个终端窗口中，执行以下命令，进入之前已经创建好的“/usr/local/spark/mycode/”目录，在这个目录下新建rdd子目录，用来存放本章的代码和相关文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> usr/<span class="built_in">local</span>/spark/mycode/</div><div class="line">mkdir rdd</div></pre></td></tr></table></figure></p>
<p>然后，使用vim编辑器，在rdd目录下新建一个word.txt文件，你可以在文件里面随便输入几行英文语句用来测试。</p>
<p>经过上面的准备工作以后，我们就可以开始创建RDD了。</p>
<div class="note success"><h2 id="从文件系统中加载数据创建RDD"><a href="#从文件系统中加载数据创建RDD" class="headerlink" title="从文件系统中加载数据创建RDD"></a>从文件系统中加载数据创建RDD</h2></div>
<p>Spark采用textFile()方法来从文件系统中加载数据创建RDD，该方法把文件的URI作为参数，这个URI可以是本地文件系统的地址，或者是分布式文件系统HDFS的地址，或者是Amazon S3的地址等等。<br>下面请切换回spark-shell窗口，看一下如何从本地文件系统中加载数据：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/rdd/word.txt"</span>)</div><div class="line">lines: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/mycode/rdd/word.txt MapPartitionsRDD[12] at textFile at &lt;console&gt;:27</span></div></pre></td></tr></table></figure></p>
<p>从执行结果反馈信息可以看出，lines是一个String类型的RDD，或者我们以后可以简单称为RDD[String]，也就是说，这个RDD[String]里面的元素都是String类型。<br>下面看一下如何从HDFS文件系统中加载数据，这个在前面的第一个Spark应用程序：WordCount实例中已经讲过，这里再简单复习一下。<br>请根据前面的第一个Spark应用程序：WordCount实例中的内容介绍，把刚才在本地文件系统中的“/usr/local/spark/mycode/rdd/word.txt”上传到HDFS文件系统的hadoop用户目录下（注意：本教程统一使用hadoop用户登录Linux系统）。然后，在spark-shell窗口中，就可以使用下面任意一条命令完成从HDFS文件系统中加载数据：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"hdfs://localhost:9000/user/hadoop/word.txt"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"/user/hadoop/word.txt"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"word.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>注意，上面三条命令是完全等价的命令，只不过使用了不同的目录形式，你可以使用其中任意一条命令完成数据加载操作。</p>
<p>在使用Spark读取文件时，需要说明以下几点：<br>（1）如果使用了本地文件系统的路径，那么，必须要保证在所有的worker节点上，也都能够采用相同的路径访问到该文件，比如，可以把该文件拷贝到每个worker节点上，或者也可以使用网络挂载共享文件系统。<br>（2）textFile()方法的输入参数，可以是文件名，也可以是目录，也可以是压缩文件等。比如，textFile(“/my/directory”), textFile(“/my/directory/<em>.txt”), and textFile(“/my/directory/</em>.gz”).<br>（3）textFile()方法也可以接受第2个输入参数（可选），用来指定分区的数目。默认情况下，Spark会为HDFS的每个block创建一个分区（HDFS中每个block默认是128MB）。你也可以提供一个比block数量更大的值作为分区数目，但是，你不能提供一个小于block数量的值作为分区数目。</p>
<div class="note success"><h2 id="通过并行集合（数组）创建RDD"><a href="#通过并行集合（数组）创建RDD" class="headerlink" title="通过并行集合（数组）创建RDD"></a>通过并行集合（数组）创建RDD</h2></div>
<p>可以调用SparkContext的parallelize方法，在Driver中一个已经存在的集合（数组）上创建。<br>下面请在spark-shell中操作：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt;<span class="keyword">val</span> array = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</div><div class="line">array: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</div><div class="line">scala&gt;<span class="keyword">val</span> rdd = sc.parallelize(array)</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">13</span>] at parallelize at &lt;console&gt;:<span class="number">29</span></div></pre></td></tr></table></figure></p>
<p>从执行结果信息可以看出，rdd是一个Int类型的RDD。<br>上面使用数组来创建，或者，也可以从列表中创建：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt;<span class="keyword">val</span> list = <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</div><div class="line">list: <span class="type">List</span>[<span class="type">Int</span>] = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</div><div class="line">scala&gt;<span class="keyword">val</span> rdd = sc.parallelize(list)</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">14</span>] at parallelize at &lt;console&gt;:<span class="number">29</span></div></pre></td></tr></table></figure></p>
<p>从执行结果信息可以看出，rdd是一个Int类型的RDD。</p>
<div class="note success"><h2 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h2></div>
<p>RDD被创建好以后，在后续使用过程中一般会发生两种操作：</p>
<ul>
<li> 转换（Transformation）： 基于现有的数据集创建一个新的数据集。</li>
<li> 行动（Action）：在数据集上进行运算，返回计算值。</li>
</ul>
<div class="note success"><h3 id="转换操作"><a href="#转换操作" class="headerlink" title="转换操作"></a>转换操作</h3></div>
<p>对于RDD而言，每一次转换操作都会产生不同的RDD，供给下一个“转换”使用。转换得到的RDD是惰性求值的，也就是说，整个转换过程只是记录了转换的轨迹，并不会发生真正的计算，只有遇到行动操作时，才会发生真正的计算，开始从血缘关系源头开始，进行物理的转换操作。<br>下面列出一些常见的转换操作（Transformation API）：</p>
<ul>
<li>filter(func)：筛选出满足函数func的元素，并返回一个新的数据集</li>
<li>map(func)：将每个元素传递到函数func中，并将结果返回为一个新的数据集</li>
<li>flatMap(func)：与map()相似，但每个输入元素都可以映射到0或多个输出结果</li>
<li>groupByKey()：应用于(K,V)键值对的数据集时，返回一个新的(K, Iterable)形式的数据集</li>
<li>reduceByKey(func)：应用于(K,V)键值对的数据集时，返回一个新的(K, V)形式的数据集，其中的每个值是将每个key传递到函数func中进行聚合</li>
</ul>
<div class="note success"><h3 id="行动操作"><a href="#行动操作" class="headerlink" title="行动操作"></a>行动操作</h3></div>
<p>行动操作是真正触发计算的地方。Spark程序执行到行动操作时，才会执行真正的计算，从文件中加载数据，完成一次又一次转换操作，最终，完成行动操作得到结果。<br>下面列出一些常见的行动操作（Action API）：</p>
<ul>
<li>count() 返回数据集中的元素个数</li>
<li>collect() 以数组的形式返回数据集中的所有元素</li>
<li>first() 返回数据集中的第一个元素</li>
<li>take(n) 以数组的形式返回数据集中的前n个元素</li>
<li>reduce(func) 通过函数func（输入两个参数并返回一个值）聚合数据集中的元素</li>
<li>foreach(func) 将数据集中的每个元素传递到函数func中运行*</li>
</ul>
<div class="note success"><h3 id="惰性机制"><a href="#惰性机制" class="headerlink" title="惰性机制"></a>惰性机制</h3></div>
<p>这里给出一段简单的代码来解释Spark的惰性机制。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"data.txt"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> lineLengths = lines.map(s =&gt; s.length)</div><div class="line">scala&gt; <span class="keyword">val</span> totalLength = lineLengths.reduce((a, b) =&gt; a + b)</div></pre></td></tr></table></figure></p>
<p>上面第一行首先从外部文件data.txt中构建得到一个RDD，名称为lines，但是，由于textFile()方法只是一个转换操作，因此，这行代码执行后，不会立即把data.txt文件加载到内存中，这时的lines只是一个指向这个文件的指针。<br>第二行代码用来计算每行的长度（即每行包含多少个单词），同样，由于map()方法只是一个转换操作，这行代码执行后，不会立即计算每行的长度。<br>第三行代码的reduce()方法是一个“动作”类型的操作，这时，就会触发真正的计算。这时，Spark会把计算分解成多个任务在不同的机器上执行，每台机器运行位于属于它自己的map和reduce，最后把结果返回给Driver Program。<br><div class="note success"><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2></div><br>下面我们举几个实例加深了解。<br>请在spark-shell下执行下面操作。<br>下面是一个关于filter()操作的实例。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/rdd/word.txt"</span>)</div><div class="line">lines: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/mycode/rdd/word.txt MapPartitionsRDD[16] at textFile at &lt;console&gt;:27</span></div><div class="line">scala&gt; lines.filter(line =&gt; line.contains(<span class="string">"Spark"</span>)).count()</div><div class="line">res1: <span class="type">Long</span> = <span class="number">2</span>  <span class="comment">//这是执行返回的结果</span></div></pre></td></tr></table></figure></p>
<p>上面的代码中，lines就是一个RDD。lines.filter()会遍历lines中的每行文本，并对每行文本执行括号中的匿名函数，也就是执行Lamda表达式：line =&gt; line.contains(“Spark”)，在执行Lamda表达式时，会把当前遍历到的这行文本内容赋值给参数line，然后，执行处理逻辑line.contains(“Spark”)，也就是只有当改行文本包含“Spark”才满足条件，才会被放入到结果集中。最后，等到lines集合遍历结束后，就会得到一个结果集，这个结果集中包含了所有包含“Spark”的行。最后，对这个结果集调用count()，这是一个行动操作，会计算出结果集中的元素个数。</p>
<p>这里再给出另外一个实例，我们要找出文本文件中单行文本所包含的单词数量的最大值，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/rdd/word.txt"</span>)</div><div class="line">scala&gt; lines.map(line =&gt; line.split(<span class="string">" "</span>).size).reduce((a,b) =&gt; <span class="keyword">if</span> (a&gt;b) a <span class="keyword">else</span> b)</div></pre></td></tr></table></figure></p>
<p>上面代码中，lines是一个RDD，是String类型的RDD，因为这个RDD里面包含了很多行文本。lines.map()，是一个转换操作，之前说过，map(func)：将每个元素传递到函数func中，并将结果返回为一个新的数据集，所以，lines.map(line =&gt; line.split(“ “).size)会把每行文本都传递给匿名函数，也就是传递给Lamda表达式line =&gt; line.split(“ “).size中的line，然后执行处理逻辑line.split(“ “).size。line.split(“ “).size这个处理逻辑的功能是，对line文本内容进行单词切分，得到很多个单词构成的集合，然后，计算出这个集合中的单词的个数。因此，最终lines.map(line =&gt; line.split(“ “).size)转换操作得到的RDD，是一个整型RDD，里面每个元素都是整数值（也就是单词的个数）。最后，针对这个RDD[Int]，调用reduce()行动操作，完成计算。reduce()操作每次接收两个参数，取出较大者留下，然后再继续比较，例如，RDD[Int]中包含了1,2,3,4,5，那么，执行reduce操作时，首先取出1和2，把a赋值为1，把b赋值为2，然后，执行大小判断，保留2。下一次，让保留下来的2赋值给a，再从RDD[Int]中取出下一个元素3，把3赋值给b，然后，对a和b执行大小判断，保留较大者3.依此类推。最终，reduce()操作会得到最大值是5。</p>
<p>（备注：关于reduce()操作，你也可以参考<a href="http://dblab.xmu.edu.cn/blog/966-2/" target="_blank" rel="external">Scala部分的reduce</a>）</p>
<p>实际上，如果我们把上面的 lines.map(line =&gt; line.split(“ “).size).reduce((a,b) =&gt; if (a&gt;b) a else b)分开逐步执行，你就可以更加清晰地发现每个步骤生成的RDD的类型。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> lines = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/rdd/word.txt"</span>)</div><div class="line">lines: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = file:<span class="comment">///usr/local/spark/mycode/rdd/word.txt MapPartitionsRDD[18] at textFile at &lt;console&gt;:27</span></div><div class="line">scala&gt; lines.map(line =&gt; line.split(<span class="string">" "</span>)）</div><div class="line">res8: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Array</span>[<span class="type">String</span>]] = <span class="type">MapPartitionsRDD</span>[<span class="number">19</span>] at map at &lt;console&gt;:<span class="number">30</span></div><div class="line"><span class="comment">//从上面执行结果可以发现，lines.map(line =&gt; line.split(" ")）返回的结果是一个Array[String]类型的RDD，也就是说，这个RDD中的每个元素都是一个Array[String]（一行文本被切分成多个单词后就是保存在这个数组中）</span></div><div class="line">scala&gt; lines.map(line =&gt; line.split(<span class="string">" "</span>).size)</div><div class="line">res9: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">20</span>] at map at &lt;console&gt;:<span class="number">30</span></div><div class="line"><span class="comment">//从上面执行结果信息可以发现，lines.map(line =&gt; line.split(" ").size)得到的RDD是Int类型的RDD，这个RDD中的每个元素都是一个整数值（也就是一行文本包含的单词数）</span></div><div class="line">scala&gt; lines.map(line =&gt; line.split(<span class="string">" "</span>).size).reduce((a,b) =&gt; <span class="keyword">if</span> (a&gt;b) a <span class="keyword">else</span> b)</div><div class="line">res10: <span class="type">Int</span> = <span class="number">5</span></div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2></div>
<p>前面我们已经说过，在Spark中，RDD采用惰性求值的机制，每次遇到行动操作，都会从头开始执行计算。如果整个Spark程序中只有一次行动操作，这当然不会有什么问题。但是，在一些情形下，我们需要多次调用不同的行动操作，这就意味着，每次调用行动操作，都会触发一次从头开始的计算。这对于迭代计算而言，代价是很大的，迭代计算经常需要多次重复使用同一组数据。<br>比如，下面就是多次计算同一个DD的例子：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> list = <span class="type">List</span>(<span class="string">"Hadoop"</span>,<span class="string">"Spark"</span>,<span class="string">"Hive"</span>)</div><div class="line">list: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="type">Hadoop</span>, <span class="type">Spark</span>, <span class="type">Hive</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(list)</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">22</span>] at parallelize at &lt;console&gt;:<span class="number">29</span></div><div class="line">scala&gt; println(rdd.count()) <span class="comment">//行动操作，触发一次真正从头到尾的计算</span></div><div class="line"><span class="number">3</span></div><div class="line">scala&gt; println(rdd.collect().mkString(<span class="string">","</span>)) <span class="comment">//行动操作，触发一次真正从头到尾的计算</span></div><div class="line"><span class="type">Hadoop</span>,<span class="type">Spark</span>,<span class="type">Hive</span></div></pre></td></tr></table></figure></p>
<p>上面代码执行过程中，前后共触发了两次从头到尾的计算。<br>实际上，可以通过持久化（缓存）机制避免这种重复计算的开销。可以使用persist()方法对一个RDD标记为持久化，之所以说“标记为持久化”，是因为出现persist()语句的地方，并不会马上计算生成RDD并把它持久化，而是要等到遇到第一个行动操作触发真正计算以后，才会把计算结果进行持久化，持久化后的RDD将会被保留在计算节点的内存中被后面的行动操作重复使用。<br>persist()的圆括号中包含的是持久化级别参数，比如，persist(MEMORY_ONLY)表示将RDD作为反序列化的对象存储于JVM中，如果内存不足，就要按照LRU原则替换缓存中的内容。persist(MEMORY_AND_DISK)表示将RDD作为反序列化的对象存储在JVM中，如果内存不足，超出的分区将会被存放在硬盘上。一般而言，使用cache()方法时，会调用persist(MEMORY_ONLY)。<br>例子如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> list = <span class="type">List</span>(<span class="string">"Hadoop"</span>,<span class="string">"Spark"</span>,<span class="string">"Hive"</span>)</div><div class="line">list: <span class="type">List</span>[<span class="type">String</span>] = <span class="type">List</span>(<span class="type">Hadoop</span>, <span class="type">Spark</span>, <span class="type">Hive</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> rdd = sc.parallelize(list)</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">22</span>] at parallelize at &lt;console&gt;:<span class="number">29</span></div><div class="line">scala&gt; rdd.cache()  <span class="comment">//会调用persist(MEMORY_ONLY)，但是，语句执行到这里，并不会缓存rdd，这是rdd还没有被计算生成</span></div><div class="line">scala&gt; println(rdd.count()) <span class="comment">//第一次行动操作，触发一次真正从头到尾的计算，这时才会执行上面的rdd.cache()，把这个rdd放到缓存中</span></div><div class="line"><span class="number">3</span></div><div class="line">scala&gt; println(rdd.collect().mkString(<span class="string">","</span>)) <span class="comment">//第二次行动操作，不需要触发从头到尾的计算，只需要重复使用上面缓存中的rdd</span></div><div class="line"><span class="type">Hadoop</span>,<span class="type">Spark</span>,<span class="type">Hive</span></div></pre></td></tr></table></figure></p>
<p>最后，可以使用unpersist()方法手动地把持久化的RDD从缓存中移除。</p>
<div class="note success"><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2></div>
<p>RDD是弹性分布式数据集，通常RDD很大，会被分成很多个分区，分别保存在不同的节点上。RDD分区的一个分区原则是使得分区的个数尽量等于集群中的CPU核心（core）数目。<br>对于不同的Spark部署模式而言（本地模式、Standalone模式、YARN模式、Mesos模式），都可以通过设置spark.default.parallelism这个参数的值，来配置默认的分区数目，一般而言：<br><em>本地模式：默认为本地机器的CPU数目，若设置了local[N],则默认为N；
</em>Apache Mesos：默认的分区数为8；<br>*Standalone或YARN：在“集群中所有CPU核心数目总和”和“2”二者中取较大值作为默认值；</p>
<p>因此，对于parallelize而言，如果没有在方法中指定分区数，则默认为spark.default.parallelism，比如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt;<span class="keyword">val</span> array = <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</div><div class="line">array: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</div><div class="line">scala&gt;<span class="keyword">val</span> rdd = sc.parallelize(array,<span class="number">2</span>) #设置两个分区</div><div class="line">rdd: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">13</span>] at parallelize at &lt;console&gt;:<span class="number">29</span></div></pre></td></tr></table></figure></p>
<p>对于textFile而言，如果没有在方法中指定分区数，则默认为min(defaultParallelism,2)，其中，defaultParallelism对应的就是spark.default.parallelism。<br>如果是从HDFS中读取文件，则分区数为文件分片数(比如，128MB/片)。</p>
<div class="note success"><h2 id="打印元素"><a href="#打印元素" class="headerlink" title="打印元素"></a>打印元素</h2></div>
<p>在实际编程中，我们经常需要把RDD中的元素打印输出到屏幕上（标准输出stdout），一般会采用语句rdd.foreach(println)或者rdd.map(println)。当采用本地模式（local）在单机上执行时，这些语句会打印出一个RDD中的所有元素。但是，当采用集群模式执行时，在worker节点上执行打印语句是输出到worker节点的stdout中，而不是输出到任务控制节点Driver Program中，因此，任务控制节点Driver Program中的stdout是不会显示打印语句的这些输出内容的。为了能够把所有worker节点上的打印输出信息也显示到Driver Program中，可以使用collect()方法，比如，rdd.collect().foreach(println)，但是，由于collect()方法会把各个worker节点上的所有RDD元素都抓取到Driver Program中，因此，这可能会导致内存溢出。因此，当你只需要打印RDD的部分元素时，可以采用语句rdd.take(100).foreach(println)。</p>
<font color="grey" size="1">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第二章 第四节 Spark集群环境的搭建]]></title>
      <url>http://Melodylican.github.io/2017/02/18/Spark%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>Apache Spark 是一个新兴的大数据处理通用引擎，提供了分布式的内存抽象。Spark 最大的特点就是快，可比 Hadoop MapReduce 的处理速度快 100 倍。本文没有使用一台电脑上构建多个虚拟机的方法来模拟集群，而是使用三台电脑来搭建一个小型分布式集群环境安装。<br>本教程采用Spark2.0以上版本（比如Spark2.0.2、Spark2.1.0等）搭建集群，同样适用于搭建Spark1.6.2集群。<br><a id="more"></a></p>
<h1 id="安装Hadoop并搭建好Hadoop集群环境"><a href="#安装Hadoop并搭建好Hadoop集群环境" class="headerlink" title="安装Hadoop并搭建好Hadoop集群环境"></a>安装Hadoop并搭建好Hadoop集群环境</h1><p>Spark分布式集群的安装环境，需要事先配置好Hadoop的分布式集群环境。如果没有配置好Hadoop的分布式集群环境，请点击<a href="http://dblab.xmu.edu.cn/blog/1177-2/" target="_blank" rel="external">Hadoop 2.7分布式集群环境搭建</a>，根据教程进行安装。（备注：本教程采用Spark2.0搭建集群，同样适用于搭建Spark1.6.2集群）</p>
<h1 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h1><p>这里采用3台机器（节点）作为实例来演示如何搭建Spark集群，其中1台机器（节点）作为Master节点，另外两台机器（节点）作为Slave节点（即作为Worker节点），主机名分别为Slave01和Slave02。<br>在Master节点机器上，访问Spark官方下载地址，按照如下图下载。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/12/20161205_010.png" alt=""><br>下载完成后，执行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxf ~/下载/spark-2.0.2-bin-without-hadoop.tgz -C /usr/<span class="built_in">local</span>/</div><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></div><div class="line">sudo mv ./spark-2.0.2-bin-without-hadoop/ ./spark</div><div class="line">sudo chown -R hadoop ./spark</div></pre></td></tr></table></figure></p>
<h1 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h1><p>在Mster节点主机的终端中执行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim ~/.bashrc</div></pre></td></tr></table></figure></p>
<p>在.bashrc添加如下配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/usr/local/spark</div><div class="line">export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</div></pre></td></tr></table></figure></p>
<p>执行如下命令使得配置立即生效：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> ~/.bashrc</div></pre></td></tr></table></figure></p>
<h1 id="Spark配置"><a href="#Spark配置" class="headerlink" title="Spark配置"></a>Spark配置</h1><p>在Master节点主机上进行如下操作：</p>
<ul>
<li>配置slaves文件<br>将 slaves.template 拷贝到 slaves<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/</div><div class="line">cp ./conf/slaves.template ./conf/slaves</div></pre></td></tr></table></figure>
</li>
</ul>
<p>slaves文件设置Worker节点。编辑slaves内容,把默认内容localhost替换成如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">slave01</div><div class="line">slave02</div></pre></td></tr></table></figure></p>
<ul>
<li>配置spark-env.sh文件<br>将 spark-env.sh.template 拷贝到 spark-env.sh<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp ./conf/spark-env.sh.template ./conf/spark-env.sh</div></pre></td></tr></table></figure>
</li>
</ul>
<p>编辑spark-env.sh,添加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</div><div class="line">export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop</div><div class="line">export SPARK_MASTER_IP=192.168.1.104</div></pre></td></tr></table></figure></p>
<p>SPARK_MASTER_IP 指定 Spark 集群 Master 节点的 IP 地址；</p>
<p>配置好后，将Master主机上的/usr/local/spark文件夹复制到各个节点上。在Master主机上执行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</div><div class="line">tar -zcf ~/spark.master.tar.gz ./spark</div><div class="line"><span class="built_in">cd</span> ~</div><div class="line">scp ./spark.master.tar.gz slave01:/home/hadoop</div><div class="line">scp ./spark.master.tar.gz slave02:/home/hadoop</div></pre></td></tr></table></figure></p>
<p>在slave01,slave02节点上分别执行下面同样的操作：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo rm -rf /usr/<span class="built_in">local</span>/spark/</div><div class="line">sudo tar -zxf ~/spark.master.tar.gz -C /usr/<span class="built_in">local</span></div><div class="line">sudo chown -R hadoop /usr/<span class="built_in">local</span>/spark</div></pre></td></tr></table></figure></p>
<h1 id="启动Spark集群"><a href="#启动Spark集群" class="headerlink" title="启动Spark集群"></a>启动Spark集群</h1><div class="note success"><h2 id="启动Hadoop集群"><a href="#启动Hadoop集群" class="headerlink" title="启动Hadoop集群"></a>启动Hadoop集群</h2></div>
<p>启动Spark集群前，要先启动Hadoop集群。在Master节点主机上运行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop/</div><div class="line">sbin/start-all.sh</div></pre></td></tr></table></figure></p>
<div class="note success"><h2 id="启动Spark集群"><a href="#启动Spark集群" class="headerlink" title="启动Spark集群"></a>启动Spark集群</h2></div>
<p>1.启动Master节点<br>在Master节点主机上运行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/</div><div class="line">sbin/start-master.sh</div></pre></td></tr></table></figure></p>
<p>在Master节点上运行jps命令，可以看到多了个Master进程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">15093 Jps</div><div class="line">14343 SecondaryNameNode</div><div class="line">14121 NameNode</div><div class="line">14891 Master</div><div class="line">14509 ResourceManager</div></pre></td></tr></table></figure></p>
<p>2.启动所有Slave节点<br>在Master节点主机上运行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sbin/start-slaves.sh</div></pre></td></tr></table></figure></p>
<p>分别在slave01、slave02节点上运行jps命令，可以看到多了个Worker进程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">37553 DataNode</div><div class="line">37684 NodeManager</div><div class="line">37876 Worker</div><div class="line">37924 Jps</div></pre></td></tr></table></figure></p>
<p>3.在浏览器上查看Spark独立集群管理器的集群信息<br>在master主机上打开浏览器，访问<a href="http://master:8080,如下图：" target="_blank" rel="external">http://master:8080,如下图：</a><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/12/20161205_011.png" alt=""></p>
<div class="note success"><h2 id="关闭Spark集群"><a href="#关闭Spark集群" class="headerlink" title="关闭Spark集群"></a>关闭Spark集群</h2></div>
<p>1.关闭Master节点<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sbin/stop-master.sh</div></pre></td></tr></table></figure></p>
<p>2.关闭Worker节点<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sbin/stop-slaves.sh</div></pre></td></tr></table></figure></p>
<p>3.关闭Hadoop集群<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop/</div><div class="line">sbin/stop-all.sh</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第二章 第三节 使用开发工具Intellij idea编写Spark应用程序(Scala+Maven)]]></title>
      <url>http://Melodylican.github.io/2017/02/15/%E4%BD%BF%E7%94%A8%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7Intellij%20idea%E7%BC%96%E5%86%99Spark%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F(Scala+Maven)/</url>
      <content type="html"><![CDATA[<p>对Scala代码进行打包编译时，可以采用Maven，也可以采用sbt，相对而言，业界更多使用sbt。这里介绍IntelliJ IDEA和Maven的组合使用方法。IntelliJ IDEA和SBT的组合使用方法，请参考“使用Intellij Idea编写Spark应用程序（Scala+SBT）”。<br><a id="more"></a><br><div class="note success"><h2 id="1-安装IntelliJ-IDEA"><a href="#1-安装IntelliJ-IDEA" class="headerlink" title="1.安装IntelliJ IDEA"></a>1.安装IntelliJ IDEA</h2></div><br>本次运行系统为Ubuntu16.04。</p>
<p>我们可以访问<a href="http://www.jetbrains.com/idea/download/#section=linux" target="_blank" rel="external">官网</a>下载安装包。文件较大，一般需要20分钟左右。有两种下载选择，我们选择下载正版，教程将使用试用版的idea。<br>下载后，我们把压缩包解压并且改名。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> ~/下载</div><div class="line">sudo tar -zxvf ideaIU-2016.3.4.tar.gz</div><div class="line">sudo mv idea-IU-163.12024.16 /usr/<span class="built_in">local</span>/Intellij</div></pre></td></tr></table></figure></p>
<p>然后我们打开Intellij文件夹，并且使用其bin文件夹下的idea.sh打开程序。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Intellij/bin</div><div class="line">./idea.sh</div></pre></td></tr></table></figure></p>
<p>会出现如图界面。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/1.png" alt=""><br>选择Ecalute for free进入免费试用版。<br>接下来我们要把程序放到启动栏里快捷启动。<br>首先进入到applications文件夹下，并且编辑idea.desktop文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/share/applications</div><div class="line">sudo gedit idea.desktop</div></pre></td></tr></table></figure></p>
<p>在打开的文档里添加如下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[Desktop Entry]</div><div class="line">Encoding=UTF-8</div><div class="line">Version=1.0</div><div class="line">Name=IntelliJ IDEA</div><div class="line">GenericName=Java IDE</div><div class="line">Comment=IntelliJ IDEA is a code-centric IDE focused on developer    productivity. The editor deeply understands your code and knows its way around the codebase, makes great suggestions right when you need them, and is always ready to help you shape your code.</div><div class="line">Exec=/usr/local/Intellij/bin/idea.sh</div><div class="line">Icon=/usr/local/Intellij/bin/idea.png</div><div class="line">Terminal=false</div><div class="line">Type=Application</div><div class="line">Categories=Development;IDE</div></pre></td></tr></table></figure></p>
<p>然后我们在启动栏里选择查找程序的那个应用（一般在启动栏第一个）。搜索Intellij即可找到程序，点击就可以启动idea。这时候我们就可以把程序锁定到启动栏使用了。如果搜索没找到，请重启系统。</p>
<div class="note success"><h2 id="2-在Intellij里安装scala插件，并配置JDK，scala-SDK"><a href="#2-在Intellij里安装scala插件，并配置JDK，scala-SDK" class="headerlink" title="2.在Intellij里安装scala插件，并配置JDK，scala SDK"></a>2.在Intellij里安装scala插件，并配置JDK，scala SDK</h2></div>
<p>首先如图打开plugins界面。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/2.png" alt=""><br>然后我们点击Install JetBrain Plugins..如下图<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/3.png" alt=""><br>搜索并安装scala。<br>等待安装完成后我们就可以配置JDK跟scala SDK。</p>
<div class="note success"><h3 id="配置JDK"><a href="#配置JDK" class="headerlink" title="## 配置JDK ##"></a>## 配置JDK ##</h3></div>
<p>首先我们打开Project Structure，如下图。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/4.png" alt=""><br>然后我们添加JDK（这里默认已经安装JDK并且配置了环境变量），操作按下面两张图。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/5.png" alt=""><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/6.png" alt=""><br><div class="note success"><h3 id="配置全局Scala-SDK"><a href="#配置全局Scala-SDK" class="headerlink" title="## 配置全局Scala SDK ##"></a>## 配置全局Scala SDK ##</h3></div><br>还是在Project Structure界面，操作如下。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/7.png" alt=""><br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/8.png" alt=""><br>然后我们右键我们添加的SDK选择Copy to Project Libraries…OK确认。如图<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/25.png" alt=""><br>配置好后我们就可以创建工程文件了。</p>
<div class="note success"><h2 id="3-创建Maven工程文件"><a href="#3-创建Maven工程文件" class="headerlink" title="3.创建Maven工程文件"></a>3.创建Maven工程文件</h2></div>
<p>我们点击初始界面的Create New Project进入如图界面。并按图创建Maven工程文件。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/9.png" alt=""><br>然后我们要填写GroupId：dblab；以及ArtifactId：WordCount，如图<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/10.png" alt=""><br>然后按下图填写各项，这一步容易出错请认真填写。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/11.png" alt=""><br>到此创建工程文件完成。</p>
<div class="note success"><h2 id="4-前置的一些配置"><a href="#4-前置的一些配置" class="headerlink" title="4.前置的一些配置"></a>4.前置的一些配置</h2></div>
<div class="note success"><h3 id="将scala框架添加到项目"><a href="#将scala框架添加到项目" class="headerlink" title="将scala框架添加到项目"></a>将scala框架添加到项目</h3></div>
<p>在IDEA启动后进入的界面中，可以看到界面左侧的项目界面，已经有一个名称为WordCount的工程。请在该工程名称上右键单击，在弹出的菜单中，选择Add Framework Surport ，在左侧有一排可勾选项，找到scala，勾选即可。<br><div class="note success"><h3 id="创建WordCount文件夹，并作为suorces-root"><a href="#创建WordCount文件夹，并作为suorces-root" class="headerlink" title="创建WordCount文件夹，并作为suorces root"></a>创建WordCount文件夹，并作为suorces root</h3></div></p>
<p>在src文件夹下创建一个WordCount文件夹。<br>右键新建的文件夹，按图把该文件夹设置为sources root。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/12.png" alt=""><br><div class="note success"><h2 id="5-两次的代码黏贴"><a href="#5-两次的代码黏贴" class="headerlink" title="5.两次的代码黏贴"></a>5.两次的代码黏贴</h2></div><br>黏贴wordcount代码到WordCount.scala<br>然后就可以通过右键刚刚设置为sources root的wordcount文件夹，就有了new-&gt;scala class的选项。<br>我们新建一个scala class，并且命名WordCount，选着为object类型。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/13.png" alt=""><br>我们打开建好的WordCount.scala文件，请空！然后黏贴以下代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">    <span class="keyword">val</span> inputFile =  <span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span></div><div class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"WordCount"</span>).setMaster(<span class="string">"local"</span>)</div><div class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">    <span class="keyword">val</span> textFile = sc.textFile(inputFile)</div><div class="line">    <span class="keyword">val</span> wordCount = textFile.flatMap(line =&gt; line.split(<span class="string">" "</span>)).map(word =&gt; (word, <span class="number">1</span>)).reduceByKey((a, b) =&gt; a + b)</div><div class="line">    wordCount.foreach(println)</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>黏贴pom.xml代码<br>现在我们把以下代码黏贴到pom.xml里。注意是全放在project标签内。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line">&lt;properties&gt;</div><div class="line">        &lt;spark.version&gt;2.1.0&lt;/spark.version&gt;</div><div class="line">        &lt;scala.version&gt;2.11&lt;/scala.version&gt;</div><div class="line">    &lt;/properties&gt;</div><div class="line"></div><div class="line"></div><div class="line">    &lt;dependencies&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spark-core_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spark-streaming_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spark-sql_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spark-hive_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spark-mllib_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line"></div><div class="line">    &lt;/dependencies&gt;</div><div class="line"></div><div class="line">    &lt;build&gt;</div><div class="line">        &lt;plugins&gt;</div><div class="line"></div><div class="line">            &lt;plugin&gt;</div><div class="line">                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;2.15.2&lt;/version&gt;</div><div class="line">                &lt;executions&gt;</div><div class="line">                    &lt;execution&gt;</div><div class="line">                        &lt;goals&gt;</div><div class="line">                            &lt;goal&gt;compile&lt;/goal&gt;</div><div class="line">                            &lt;goal&gt;testCompile&lt;/goal&gt;</div><div class="line">                        &lt;/goals&gt;</div><div class="line">                    &lt;/execution&gt;</div><div class="line">                &lt;/executions&gt;</div><div class="line">            &lt;/plugin&gt;</div><div class="line"></div><div class="line">            &lt;plugin&gt;</div><div class="line">                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;3.6.0&lt;/version&gt;</div><div class="line">                &lt;configuration&gt;</div><div class="line">                    &lt;source&gt;1.8&lt;/source&gt;</div><div class="line">                    &lt;target&gt;1.8&lt;/target&gt;</div><div class="line">                &lt;/configuration&gt;</div><div class="line">            &lt;/plugin&gt;</div><div class="line"></div><div class="line">            &lt;plugin&gt;</div><div class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;2.19&lt;/version&gt;</div><div class="line">                &lt;configuration&gt;</div><div class="line">                    &lt;skip&gt;true&lt;/skip&gt;</div><div class="line">                &lt;/configuration&gt;</div><div class="line">            &lt;/plugin&gt;</div><div class="line"></div><div class="line">        &lt;/plugins&gt;</div><div class="line">    &lt;/build&gt;</div></pre></td></tr></table></figure></p>
<p>黏贴好后，我们右键点击工程文件夹，更新一下，按下图操作。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/14.png" alt=""><br>这时候我们注意要记得点击右下角的“Import Changes Enables Auto-Import ”。如图。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/15.png" alt=""><br>这时候我们需要等待一段时间，可以看底部的进度条。等执行完毕，我们再进行后面的操作。</p>
<div class="note success"><h2 id="6-运行WordCount程序"><a href="#6-运行WordCount程序" class="headerlink" title="6.运行WordCount程序"></a>6.运行WordCount程序</h2></div>
<p>在WordCount.scala代码窗口内的任意位置，我们右键点击，可以唤出菜单，选择Run ‘WordCount’。运行的结果如下。注意根据代码，你必须有/usr/local/spark/mycode/wordcount/word.txt这个文件。输出信息较多，你可以拖动一下寻找结果信息。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/16.png" alt=""><br><div class="note success"><h2 id="7-打包WordCount程序的jar包"><a href="#7-打包WordCount程序的jar包" class="headerlink" title="7.打包WordCount程序的jar包"></a>7.打包WordCount程序的jar包</h2></div><br>首先打开File-&gt;Project Structure。如图。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/17-1.png" alt=""><br>然后选择Artifacts-&gt;绿色加号-&gt;Jar-&gt;From moduleswith dependencies…如图<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/18.png" alt=""><br>选择Main Class，如图<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/19.png" alt=""><br>然后因为我们只是在Spark上运行的，所以我们要删除下图红框里多余的部分，保留WordCount.jar以及‘WordCount’ compile output。小提示，这里可以利用Ctrl+A全选功能，选中全部选项，然后，配合Crtl+鼠标左键进行反选，也就是按住Ctrl键的同时用鼠标左键分别点击WordCount.jar和‘WordCount’ compile output，从而不选中这两项，最后，点击页面中的删除按钮（是一个减号图标），这样就把其他选项都删除，只保留了WordCount.jar以及‘WordCount’ compile output。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/20.png" alt=""><br>然后我们点击Apply，再点击OK，如图<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/21.png" alt=""><br>接着我们就可以导出Jar包了。选择Build-&gt;Build Artifacts…，在弹出的窗口选择Bulid就可以了。如下图：<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/22.png" alt=""><br>导出的Jar包会在工程文件“/home/wordcount/”目录下的“out/artifacts/WordCount_jar”目录下。我们把他复制到/home/hadoop目录下。也就是主文件夹目录下，如下图<br>实际上，可以用命令来复制WordCount.jar文件，请打开一个Linux终端，输入如下命令：<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/23.png" alt=""><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> ~</div><div class="line">cp /home/hadoop/WordCount/out/artifacts/WordCount_jar/WordCount.jar /home/hadoop</div></pre></td></tr></table></figure></p>
<p>然后我们在终端执行以下命令，运行Jar包：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> ~</div><div class="line">/usr/<span class="built_in">local</span>/spark/bin/spark-submit --class WordCount /home/hadoop/WordCount.jar</div></pre></td></tr></table></figure></p>
<p>运行结果如下（输出的信息较多请上下翻一下就能找到），要求还是跟上述一样要有那个文件存在。<br>到此我们就完成了本次的任务了。</p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第二章 第二节 第一个Spark应用程序：WordCount]]></title>
      <url>http://Melodylican.github.io/2017/02/10/%E7%AC%AC%E4%B8%80%E4%B8%AASpark%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%EF%BC%9AWordCount/</url>
      <content type="html"><![CDATA[<p>前面已经学习了Spark安装，完成了实验环境的搭建，并且学习了Spark运行架构和RDD设计原理，同时，我们还学习了Scala编程的基本语法，有了这些基础知识作为铺垫，现在我们可以没有障碍地开始编写一个简单的Spark应用程序了——词频统计。<br><a id="more"></a><br><div class="note success"><h2 id="任务要求"><a href="#任务要求" class="headerlink" title="任务要求"></a>任务要求</h2></div><br>任务：编写一个Spark应用程序，对某个文件中的单词进行词频统计。<br>准备工作：请进入Linux系统，打开“终端”，进入Shell命令提示符状态，然后，执行如下命令新建目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark</div><div class="line">mkdir mycode</div><div class="line"><span class="built_in">cd</span> mycode</div><div class="line">mkdir wordcount</div><div class="line"><span class="built_in">cd</span> wordcount</div></pre></td></tr></table></figure></p>
<p>然后，在“/usr/local/spark/mycode/wordcount”目录下新建一个包含了一些语句的文本文件word.txt，命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vim word.txt</div></pre></td></tr></table></figure></p>
<p>你可以在文本文件中随意输入一些单词，用空格隔开，我们会编写Spark程序对该文件进行单词词频统计。然后，按键盘Esc键退出vim编辑状态，输入“:wq”保存文件并退出vim编辑器。</p>
<div class="note success"><h2 id="在spark-shell中执行词频统计"><a href="#在spark-shell中执行词频统计" class="headerlink" title="在spark-shell中执行词频统计"></a>在spark-shell中执行词频统计</h2></div>
<div class="note success"><h2 id="启动spark-shell"><a href="#启动spark-shell" class="headerlink" title="启动spark-shell"></a>启动spark-shell</h2></div>
<p>首先，请登录Linux系统(要注意记住登录采用的用户名，本教程统一采用hadoop用户名进行登录)，打开“终端”（可以在Linux系统中使用Ctrl+Alt+T组合键开启终端），进入shell命令提示符状态，然后执行以下命令进入spark-shell：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark</div><div class="line">./bin/spark-shell</div><div class="line">....//这里省略启动过程显示的一大堆信息</div><div class="line">scala&gt;</div></pre></td></tr></table></figure></p>
<p>启动进入spark-shell需要一点时间，在进入spark-shell后，我们可能还需要到Linux文件系统中对相关目录下的文件进行编辑和操作（比如要查看spark程序执行过程生成的文件），这个无法在park-shell中完成，因此，这里再打开第二个终端，用来在Linux系统的Shell命令提示符下操作。</p>
<div class="note success"><h2 id="加载本地文件"><a href="#加载本地文件" class="headerlink" title="加载本地文件"></a>加载本地文件</h2></div>
<p>在开始具体词频统计代码之前，需要解决一个问题，就是如何加载文件？</p>
<p>要注意，文件可能位于本地文件系统中，也有可能存放在分布式文件系统HDFS中，所以，下面我们分别介绍如何加载本地文件，以及如何加载HDFS中的文件。<br>首先，请在第二个终端窗口下操作，用下面命令到达“/usr/local/spark/mycode/wordcount”目录，查看一下上面已经建好的word.txt的内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/wordcount</div><div class="line">cat word.txt</div></pre></td></tr></table></figure></p>
<p>cat命令会把word.txt文件的内容全部显示到屏幕上。</p>
<p>现有让我们切换回到第一个终端，也就是spark-shell，然后输入下面命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; val textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>上面代码中，val后面的是变量textFile，而sc.textFile()中的这个textFile是sc的一个方法名称，这个方法用来加载文件数据。这两个textFile不是一个东西，不要混淆。实际上，val后面的是变量textFile，你完全可以换个变量名称，比如,val lines = sc.textFile(“file:///usr/local/spark/mycode/wordcount/word.txt”)。这里使用相同名称，就是有意强调二者的区别。<br>注意，要加载本地文件，必须采用“file:///”开头的这种格式。执行上上面这条命令以后，并不会马上显示结果，因为，Spark采用惰性机制，只有遇到“行动”类型的操作，才会从头到尾执行所有操作。所以，下面我们执行一条“行动”类型的语句，就可以看到结果：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; textFile.first()</div></pre></td></tr></table></figure></p>
<p>first()是一个“行动”（Action）类型的操作，会启动真正的计算过程，从文件中加载数据到变量textFile中，并取出第一行文本。屏幕上会显示很多反馈信息，这里不再给出，你可以从这些结果信息中，找到word.txt文件中的第一行的内容。</p>
<p>正因为Spark采用了惰性机制，在执行转换操作的时候，即使我们输入了错误的语句，spark-shell也不会马上报错，而是等到执行“行动”类型的语句时启动真正的计算，那个时候“转换”操作语句中的错误就会显示出来，比如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">val textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word123.txt"</span>)</div></pre></td></tr></table></figure></p>
<p>上面我们使用了一个根本就不存在的word123.txt，执行上面语句时，spark-shell根本不会报错，因为，没有遇到“行动”类型的first()操作之前，这个加载操作时不会真正执行的。然后，我们执行一个“行动”类型的操作first()，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt; textFile.first()</div></pre></td></tr></table></figure></p>
<p>执行上面语句后，你会发现，会返回错误信息，其中有四个醒目的中文文字“拒绝连接”，因为，这个word123.txt文件根本就不存在。</p>
<p>好了，现在我们可以练习一下如何把textFile变量中的内容再次写回到另外一个文本文件wordback.txt中：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">val textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span>)</div><div class="line">textFile.saveAsTextFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/writeback"</span>)</div></pre></td></tr></table></figure></p>
<p>上面的saveAsTextFile()括号里面的参数是保存文件的路径，不是文件名。saveAsTextFile()是一个“行动”（Action）类型的操作，所以，马上会执行真正的计算过程，从word.txt中加载数据到变量textFile中，然后，又把textFile中的数据写回到本地文件目录“/usr/local/spark/mycode/wordcount/writeback/”下面，现在让我们切换到Linux Shell命令提示符窗口中，执行下面命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/wordcount/writeback/</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p>执行结果类似下面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">part-00000 _SUCCESS</div></pre></td></tr></table></figure></p>
<p>也就是说，该目录下包含两个文件，我们可以使用cat命令查看一下part-00000文件（注意:part-后面是五个零）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cat part-00000</div></pre></td></tr></table></figure></p>
<p>显示结果，是和上面word.txt中的内容一样的。</p>
<div class="note success"><h2 id="加载HDFS中的文件"><a href="#加载HDFS中的文件" class="headerlink" title="加载HDFS中的文件"></a>加载HDFS中的文件</h2></div>
<p>为了能够读取HDFS中的文件，请首先启动Hadoop中的HDFS组件。注意，之前我们在“Spark安装”这章内容已经介绍了如何安装Hadoop和Spark，所以，这里我们可以使用以下命令直接启动Hadoop中的HDFS组件（由于用不到MapReduce组件，所以，不需要启动MapReduce或者YARN）。请到第二个终端窗口，使用Linux Shell命令提示符状态，然后输入下面命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop</div><div class="line">./sbin/start-dfs.sh</div></pre></td></tr></table></figure></p>
<p>启动结束后，HDFS开始进入可用状态。如果你在HDFS文件系统中，还没有为当前Linux登录用户创建目录(本教程统一使用用户名hadoop登录Linux系统)，请使用下面命令创建：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -mkdir -p /user/hadoop</div></pre></td></tr></table></figure></p>
<p>也就是说，HDFS文件系统为Linux登录用户开辟的默认目录是“/user/用户名”（注意：是user，不是usr），本教程统一使用用户名hadoop登录Linux系统，所以，上面创建了“/user/hadoop”目录，再次强调，这个目录是在HDFS文件系统中，不在本地文件系统中。创建好以后，下面我们使用命令查看一下HDFS文件系统中的目录和文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div></pre></td></tr></table></figure></p>
<p>上面命令中，最后一个点号“.”，表示要查看Linux当前登录用户hadoop在HDFS文件系统中与hadoop对应的目录下的文件，也就是查看HDFS文件系统中“/user/hadoop/”目录下的文件，所以，下面两条命令是等价的：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div><div class="line">./bin/hdfs dfs -ls /user/hadoop</div></pre></td></tr></table></figure></p>
<p>如果要查看HDFS文件系统根目录下的内容，需要使用下面命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls /</div></pre></td></tr></table></figure></p>
<p>下面，我们把本地文件系统中的“/usr/local/spark/mycode/wordcount/word.txt”上传到分布式文件系统HDFS中（放到hadoop用户目录下）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -put /usr/<span class="built_in">local</span>/spark/mycode/wordcount/word.txt .</div></pre></td></tr></table></figure></p>
<p>然后，用命令查看一下HDFS的hadoop用户目录下是否多了word.txt文件，可以使用下面命令列出hadoop目录下的内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div></pre></td></tr></table></figure></p>
<p>可以看到，确实多了一个word.txt文件，我们使用cat命令查看一个HDFS中的word.txt文件的内容，命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -cat ./word.txt</div></pre></td></tr></table></figure></p>
<p>上面命令执行后，就会看到HDFS中word.txt的内容了。</p>
<p>现在，让我们切换回到spark-shell窗口，编写语句从HDFS中加载word.txt文件，并显示第一行文本内容：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"hdfs://localhost:9000/user/hadoop/word.txt"</span>)</div><div class="line">scala&gt; textFile.first()</div></pre></td></tr></table></figure></p>
<p>执行上面语句后，就可以看到HDFS文件系统中（不是本地文件系统）的word.txt的第一行内容了。</p>
<p>需要注意的是，sc.textFile(“hdfs://localhost:9000/user/hadoop/word.txt”)中，“hdfs://localhost:9000/”是前面介绍Hadoop安装内容时确定下来的端口地址9000。实际上，也可以省略不写，如下三条语句都是等价的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">val textFile = sc.textFile(&quot;hdfs://localhost:9000/user/hadoop/word.txt&quot;)</div><div class="line">val textFile = sc.textFile(&quot;/user/hadoop/word.txt&quot;)</div><div class="line">val textFile = sc.textFile(&quot;word.txt&quot;)</div></pre></td></tr></table></figure></p>
<p>下面，我们再把textFile的内容写回到HDFS文件系统中（写到hadoop用户目录下）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"word.txt"</span>)</div><div class="line">scala&gt; textFile.saveAsTextFile(<span class="string">"writeback"</span>)</div></pre></td></tr></table></figure></p>
<p>执行上面命令后，文本内容会被写入到HDFS文件系统的“/user/hadoop/writeback”目录下，我们可以切换到Linux Shell命令提示符窗口查看一下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls .</div></pre></td></tr></table></figure></p>
<p>执行上述命令后，在执行结果中，可以看到有个writeback目录，下面我们查看该目录下有什么文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/hdfs dfs -ls ./writeback</div></pre></td></tr></table></figure></p>
<p>执行结果中，可以看到存在两个文件：part-00000和_SUCCESS。我们使用下面命令输出part-00000文件的内容（注意：part-00000里面有五个零）：</p>
<p>./bin/hdfs dfs -cat ./writeback/part-00000<br>Shell 命令<br>执行结果中，就可以看到和word.txt文件中一样的文本内容。</p>
<div class="note success"><h2 id="词频统计"><a href="#词频统计" class="headerlink" title="词频统计"></a>词频统计</h2></div>
<p>有了前面的铺垫性介绍，下面我们就可以开始第一个Spark应用程序：WordCount。<br>请切换到spark-shell窗口：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span>)</div><div class="line">scala&gt; <span class="keyword">val</span> wordCount = textFile.flatMap(line =&gt; line.split(<span class="string">" "</span>)).map(word =&gt; (word, <span class="number">1</span>)).reduceByKey((a, b) =&gt; a + b)</div><div class="line">scala&gt; wordCount.collect()</div></pre></td></tr></table></figure></p>
<p>上面只给出了代码，省略了执行过程中返回的结果信息，因为返回信息很多。<br>下面简单解释一下上面的语句。<br>textFile包含了多行文本内容，textFile.flatMap(line =&gt; line.split(“ “))会遍历textFile中的每行文本内容，当遍历到其中一行文本内容时，会把文本内容赋值给变量line，并执行Lamda表达式line =&gt; line.split(“ “)。line =&gt; line.split(“ “)是一个Lamda表达式，左边表示输入参数，右边表示函数里面执行的处理逻辑，这里执行line.split(“ “)，也就是针对line中的一行文本内容，采用空格作为分隔符进行单词切分，从一行文本切分得到很多个单词构成的单词集合。这样，对于textFile中的每行文本，都会使用Lamda表达式得到一个单词集合，最终，多行文本，就得到多个单词集合。textFile.flatMap()操作就把这多个单词集合“拍扁”得到一个大的单词集合。<br>然后，针对这个大的单词集合，执行map()操作，也就是map(word =&gt; (word, 1))，这个map操作会遍历这个集合中的每个单词，当遍历到其中一个单词时，就把当前这个单词赋值给变量word，并执行Lamda表达式word =&gt; (word, 1)，这个Lamda表达式的含义是，word作为函数的输入参数，然后，执行函数处理逻辑，这里会执行(word, 1)，也就是针对输入的word，构建得到一个tuple，形式为(word,1)，key是word，value是1（表示该单词出现1次）。<br>程序执行到这里，已经得到一个RDD，这个RDD的每个元素是(key,value)形式的tuple。最后，针对这个RDD，执行reduceByKey((a, b) =&gt; a + b)操作，这个操作会把所有RDD元素按照key进行分组，然后使用给定的函数（这里就是Lamda表达式：(a, b) =&gt; a + b），对具有相同的key的多个value进行reduce操作，返回reduce后的(key,value)，比如(“hadoop”,1)和(“hadoop”,1)，具有相同的key，进行reduce以后就得到(“hadoop”,2)，这样就计算得到了这个单词的词频。</p>
<div class="note success"><h2 id="编写独立应用程序执行词频统计"><a href="#编写独立应用程序执行词频统计" class="headerlink" title="编写独立应用程序执行词频统计"></a>编写独立应用程序执行词频统计</h2></div>
<p>下面我们编写一个Scala应用程序来实现词频统计。<br>请登录Linux系统（本教程统一采用用户名hadoop进行登录），进入Shell命令提示符状态，然后，执行下面命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/wordcount/</div><div class="line">mkdir -p src/main/scala  //这里加入-p选项，可以一起创建src目录及其子目录</div></pre></td></tr></table></figure></p>
<p>请在“/usr/local/spark/mycode/wordcount/src/main/scala”目录下新建一个test.scala文件，里面包含如下代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">        <span class="keyword">val</span> inputFile =  <span class="string">"file:///usr/local/spark/mycode/wordcount/word.txt"</span></div><div class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"WordCount"</span>).setMaster(<span class="string">"local[2]"</span>)</div><div class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">                <span class="keyword">val</span> textFile = sc.textFile(inputFile)</div><div class="line">                <span class="keyword">val</span> wordCount = textFile.flatMap(line =&gt; line.split(<span class="string">" "</span>)).map(word =&gt; (word, <span class="number">1</span>)).reduceByKey((a, b) =&gt; a + b)</div><div class="line">                wordCount.foreach(println)       </div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>注意，SparkConf().setAppName(“WordCount”).setMaster(“local[2]”)这句语句，也可以删除.setMaster(“local[2]”)，只保留 val conf = new SparkConf().setAppName(“WordCount”)。<br>如果test.scala没有调用SparkAPI，那么，只要使用scalac命令编译后执行即可。但是，这个test.scala程序依赖 Spark API，因此我们需要通过 sbt 进行编译打包（前面的“<a href="http://dblab.xmu.edu.cn/blog/1307-2/" target="_blank" rel="external">Spark的安装和使用</a>”这个章节已经介绍过如何使用sbt进行编译打包）。下面我们再演示一次。</p>
<p>请执行如下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/wordcount/</div><div class="line">vim simple.sbt</div></pre></td></tr></table></figure></p>
<p>通过上面代码，新建一个simple.sbt文件，请在该文件中输入下面代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">name := &quot;Simple Project&quot;</div><div class="line"></div><div class="line">version := &quot;1.0&quot;</div><div class="line"></div><div class="line">scalaVersion := &quot;2.11.8&quot;</div></pre></td></tr></table></figure></p>
<p>libraryDependencies += “org.apache.spark” %% “spark-core” % “2.1.0”<br>注意， “org.apache.spark”后面是两个百分号，千万不要少些一个百分号%，如果少了，编译时候会报错。<br>下面我们使用 sbt 打包 Scala 程序。为保证 sbt 能正常运行，先执行如下命令检查整个应用程序的文件结构：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/wordcount/</div><div class="line">find .</div></pre></td></tr></table></figure></p>
<p>应该是类似下面的文件结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">./src</div><div class="line">./src/main</div><div class="line">./src/main/scala</div><div class="line">./src/main/scala/test.scala</div><div class="line">./simple.sbt</div><div class="line">./word.txt</div></pre></td></tr></table></figure></p>
<p>接着，我们就可以通过如下代码将整个应用程序打包成 JAR（首次运行同样需要下载依赖包 ）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/mycode/wordcount/  //请一定把这目录设置为当前目录</div><div class="line">/usr/<span class="built_in">local</span>/sbt/sbt package</div></pre></td></tr></table></figure></p>
<p>上面执行过程需要消耗几分钟时间，屏幕上会返回一下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">hadoop@dblab-VirtualBox:/usr/local/spark/mycode/wordcount$ /usr/local/sbt/sbt package</div><div class="line">OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=256M; support was removed in 8.0</div><div class="line">[info] Set current project to Simple Project (in build file:/usr/local/spark/mycode/wordcount/)</div><div class="line">[info] Updating &#123;file:/usr/local/spark/mycode/wordcount/&#125;wordcount...</div><div class="line">[info] Resolving jline#jline;2.12.1 ...</div><div class="line">[info] Done updating.</div><div class="line">[info] Packaging /usr/local/spark/mycode/wordcount/target/scala-2.11/simple-project_2.11-1.0.jar ...</div><div class="line">[info] Done packaging. </div><div class="line">[success] Total time: 34 s, completed 2017-2-20 10:13:13</div><div class="line">#屏幕上返回上述信息表明打包成功</div></pre></td></tr></table></figure></p>
<p>生成的 jar 包的位置为 /usr/local/spark/mycode/wordcount/target/scala-2.11/simple-project_2.11-1.0.jar。<br>最后，通过 spark-submit 运行程序。我们就可以将生成的 jar 包通过 spark-submit 提交到 Spark 中运行了，命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/<span class="built_in">local</span>/spark/bin/spark-submit --class <span class="string">"WordCount"</span>  /usr/<span class="built_in">local</span>/spark/mycode/wordcount/target/scala-2.11/simple-project_2.11-1.0.jar</div></pre></td></tr></table></figure></p>
<p>下面是笔者的word.txt进行词频统计后的结果（你的结果应该和这个类似）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(Spark,1)</div><div class="line">(is,1)</div><div class="line">(than,1)</div><div class="line">(fast,1)</div><div class="line">(love,2)</div><div class="line">(i,1)</div><div class="line">(I,1)</div><div class="line">(hadoop,2)</div><div class="line">(Spark,1)</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第二章 第一节 Spark的安装和使用]]></title>
      <url>http://Melodylican.github.io/2017/02/07/Spark%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>Spark可以独立安装使用，也可以和Hadoop一起安装使用。本教程中，我们采用和Hadoop一起安装使用，这样，就可以让Spark使用HDFS存取数据。需要说明的是，当安装好Spark以后，里面就自带了scala环境，不需要额外安装scala，因此，“Spark安装”这个部分的教程，假设读者的计算机上，没有安装Scala，也没有安装Java（当然了，如果已经安装Java和Scala，也没有关系，依然可以继续按照本教程进行安装），也就是说，你的计算机目前只有Linux系统，其他的软件和环境都没有安装（没有Java，没有Scala，没有Hadoop，没有Spark），需要从零开始安装所有大数据相关软件。下面，需要你在自己的Linux系统上（笔者采用的Linux系统是Ubuntu16.04），首先安装Java和Hadoop，然后再安装Spark（Spark安装好以后，里面就默认包含了Scala解释器）。本教程的具体运行环境如下：<br>Ubuntu16.04以上<br>Hadoop 2.7.1以上<br>Java JDK 1.7以上<br>Spark 2.1.0<br><a id="more"></a><br><div class="note success"><h2 id="一、安装Hadoop"><a href="#一、安装Hadoop" class="headerlink" title="一、安装Hadoop"></a>一、安装Hadoop</h2></div><br>如果你的计算机上已经安装了Hadoop，本步骤可以略过。这里假设没有安装。如果没有安装Hadoop，<a href="http://dblab.xmu.edu.cn/blog/install-hadoop/" target="_blank" rel="external">请访问Hadoop安装教程_单机/伪分布式配置_Hadoop2.6.0/Ubuntu14.04,依照教程</a>学习安装即可。注意，在这个Hadoop安装教程中，就包含了Java的安装，所以，按照这个教程，就可以完成JDK和Hadoop这二者的安装。</p>
<div class="note success"><h2 id="二、安装-Spark"><a href="#二、安装-Spark" class="headerlink" title="二、安装 Spark"></a>二、安装 Spark</h2></div>
<p>在Linux系统中打开浏览器，访问Spark官方下载地址，按照如下图下载。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/Spark2.1.0%E5%AE%98%E7%BD%91%E4%B8%8B%E8%BD%BD%E9%A1%B5%E9%9D%A2.png" alt=""><br>由于我们已经自己安装了Hadoop，所以，在“Choose a package type”后面需要选择“Pre-build with user-provided Hadoop [can use with most Hadoop distributions]”，然后，点击“Download Spark”后面的“spark-2.1.0-bin-without-hadoop.tgz”下载即可。下载的文件，默认会被浏览器保存在“/home/hadoop/下载”目录下。需要说明的是，Pre-build with user-provided Hadoop: 属于“Hadoop free”版，这样，下载到的Spark，可应用到任意Hadoop 版本。</p>
<p>Spark部署模式主要有四种：Local模式（单机模式）、Standalone模式（使用Spark自带的简单集群管理器）、YARN模式（使用YARN作为集群管理器）和Mesos模式（使用Mesos作为集群管理器）。<br>这里介绍Local模式（单机模式）的 Spark安装。我们选择Spark 2.1.0版本，并且假设当前使用用户名hadoop登录了Linux操作系统。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo tar -zxf ~/下载/spark-2.1.0-bin-without-hadoop.tgz -C /usr/local/</div><div class="line">cd /usr/local</div><div class="line">sudo mv ./spark-2.1.0-bin-without-hadoop/ ./spark</div><div class="line">sudo chown -R hadoop:hadoop ./spark          # 此处的 hadoop 为你的用户名</div></pre></td></tr></table></figure></p>
<p>安装后，还需要修改Spark的配置文件spark-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">cp ./conf/spark-env.sh.template ./conf/spark-env.sh</div></pre></td></tr></table></figure></p>
<p>编辑spark-env.sh文件(vim ./conf/spark-env.sh)，在第一行添加以下配置信息:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)</div></pre></td></tr></table></figure></p>
<p>有了上面的配置信息以后，Spark就可以把数据存储到Hadoop分布式文件系统HDFS中，也可以从HDFS中读取数据。如果没有配置上面信息，Spark就只能读写本地数据，无法读写HDFS数据。<br>配置完成后就可以直接使用，不需要像Hadoop运行启动命令。<br>通过运行Spark自带的示例，验证Spark是否安装成功。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">bin/run-example SparkPi</div></pre></td></tr></table></figure></p>
<p>执行时会输出非常多的运行信息，输出结果不容易找到，可以通过 grep 命令进行过滤（命令中的 2&gt;&amp;1 可以将所有的信息都输出到 stdout 中，否则由于输出日志的性质，还是会输出到屏幕中）:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/run-example SparkPi 2&gt;&amp;1 | grep &quot;Pi is&quot;</div></pre></td></tr></table></figure></p>
<p>这里涉及到Linux Shell中管道的知识，详情可以参考Linux Shell中的管道命令<br>过滤后的运行结果如下图示，可以得到π 的 5 位小数近似值：</p>
<div class="note success"><h2 id="三、在-Spark-Shell-中运行代码"><a href="#三、在-Spark-Shell-中运行代码" class="headerlink" title="三、在 Spark Shell 中运行代码"></a>三、在 Spark Shell 中运行代码</h2></div>
<p>学习Spark程序开发，建议首先通过spark-shell交互式学习，加深Spark程序开发的理解。<br>这里介绍Spark Shell 的基本使用。Spark shell 提供了简单的方式来学习 API，并且提供了交互的方式来分析数据。你可以输入一条语句，Spark shell会立即执行语句并返回结果，这就是我们所说的REPL（Read-Eval-Print Loop，交互式解释器），为我们提供了交互式执行环境，表达式计算完成就会输出结果，而不必等到整个程序运行完毕，因此可即时查看中间结果，并对程序进行修改，这样可以在很大程度上提升开发效率。<br>Spark Shell 支持 Scala 和 Python，这里使用 Scala 来进行介绍。</p>
<p>前面已经安装了Hadoop和Spark，如果Spark不使用HDFS和YARN，那么就不用启动Hadoop也可以正常使用Spark。如果在使用Spark的过程中需要用到 HDFS，就要首先启动 Hadoop（启动Hadoop的方法可以参考上面给出的Hadoop安装教程）。<br>这里假设不需要用到HDFS，因此，就没有启动Hadoop。现在我们直接开始使用Spark。<br>spark-shell命令及其常用的参数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/spark-shell --master &lt;master-url&gt;</div></pre></td></tr></table></figure></p>
<p>Spark的运行模式取决于传递给SparkContext的Master URL的值。Master URL可以是以下任一种形式：</p>
<ul>
<li>local 使用一个Worker线程本地化运行SPARK(完全不并行)</li>
<li>local[*] 使用逻辑CPU个数数量的线程来本地化运行Spark</li>
<li>local[K] 使用K个Worker线程本地化运行Spark（理想情况下，K应该根据运行机器的CPU核数设定）</li>
<li>spark://HOST:PORT 连接到指定的Spark standalone master。默认端口是7077.</li>
<li>yarn-client 以客户端模式连接YARN集群。集群的位置可以在HADOOP_CONF_DIR 环境变量中找到。</li>
<li>yarn-cluster 以集群模式连接YARN集群。集群的位置可以在HADOOP_CONF_DIR 环境变量中找到。</li>
<li>mesos://HOST:PORT 连接到指定的Mesos集群。默认接口是5050。</li>
</ul>
<p>需要强调的是，这里我们采用“本地模式”（local）运行Spark，关于如何在集群模式下运行Spark，可以参考后面的“<a href="http://dblab.xmu.edu.cn/blog/1217-2/" target="_blank" rel="external">在集群上运行Spark应用程序</a>”。<br>在Spark中采用本地模式启动Spark Shell的命令主要包含以下参数：<br>–master：这个参数表示当前的Spark Shell要连接到哪个master，如果是local[*]，就是使用本地模式启动spark-shell，其中，中括号内的星号表示需要使用几个CPU核心(core)；<br>–jars： 这个参数用于把相关的JAR包添加到CLASSPATH中；如果有多个jar包，可以使用逗号分隔符连接它们；</p>
<p>比如，要采用本地模式，在4个CPU核心上运行spark-shell：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell --master local[4]</div></pre></td></tr></table></figure></p>
<p>或者，可以在CLASSPATH中添加code.jar，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell --master local[4] --jars code.jar</div></pre></td></tr></table></figure></p>
<p>可以执行“spark-shell –help”命令，获取完整的选项列表，具体如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/spark</div><div class="line">./bin/spark-shell --help</div></pre></td></tr></table></figure></p>
<p>上面是命令使用方法介绍，下面正式使用命令进入spark-shell环境，可以通过下面命令启动spark-shell环境：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/spark-shell</div></pre></td></tr></table></figure></p>
<p>该命令省略了参数，这时，系统默认是“bin/spark-shell –master local[*]”，也就是说，是采用本地模式运行，并且使用本地所有的CPU核心。</p>
<p>启动spark-shell后，就会进入“scala&gt;”命令提示符状态,如下图所示：<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2017/02/Spark2.1.0Shell%E5%90%AF%E5%8A%A8%E7%95%8C%E9%9D%A2.png" alt=""><br>现在，你就可以在里面输入scala代码进行调试了。</p>
<p>比如，下面在命令提示符后面输入一个表达式“8 * 2 + 5”，然后回车，就会立即得到结果：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">8</span>*<span class="number">2</span>+<span class="number">5</span></div><div class="line">res0: <span class="type">Int</span> = <span class="number">21</span></div></pre></td></tr></table></figure></p>
<p>最后，可以使用命令“:quit”退出Spark Shell，如下所示：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scala&gt;:quit</div></pre></td></tr></table></figure></p>
<p>或者，也可以直接使用“Ctrl+D”组合键，退出Spark Shell。</p>
<div class="note success"><h2 id="四、Spark独立应用程序编程"><a href="#四、Spark独立应用程序编程" class="headerlink" title="四、Spark独立应用程序编程"></a>四、Spark独立应用程序编程</h2></div>
<p>接着我们通过一个简单的应用程序 SimpleApp 来演示如何通过 Spark API 编写一个独立应用程序。使用 Scala 编写的程序需要使用 sbt 进行编译打包，相应的，Java 程序使用 Maven 编译打包，而 Python 程序通过 spark-submit 直接提交。</p>
<div class="note success"><h2 id="（一）编写Scala独立应用程序"><a href="#（一）编写Scala独立应用程序" class="headerlink" title="（一）编写Scala独立应用程序"></a>（一）编写Scala独立应用程序</h2></div>
<h3 id="1-安装sbt"><a href="#1-安装sbt" class="headerlink" title="1.安装sbt"></a>1.安装sbt</h3><p>sbt是一款Spark用来对scala编写程序进行打包的工具，这里简单介绍sbt的安装过程，感兴趣的读者可以参考官网资料了解更多关于sbt的内容。<br>Spark 中没有自带 sbt，这里直接给出<a href="https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.11/sbt-launch.jar" target="_blank" rel="external">sbt-launch.jar</a>的下载地址，直接点击下载即可。<br>我们选择安装在 /usr/local/sbt 中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo mkdir /usr/local/sbt</div><div class="line">sudo chown -R hadoop /usr/local/sbt      # 此处的 hadoop 为你的用户名</div><div class="line">cd /usr/local/sbt</div></pre></td></tr></table></figure></p>
<p>下载后，执行如下命令拷贝至 /usr/local/sbt 中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp ~/下载/sbt-launch.jar .</div></pre></td></tr></table></figure></p>
<p>接着在 /usr/local/sbt 中创建 sbt 脚本（vim ./sbt），添加如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line">SBT_OPTS=&quot;-Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M&quot;</div><div class="line">java $SBT_OPTS -jar `dirname $0`/sbt-launch.jar &quot;$@&quot;</div></pre></td></tr></table></figure></p>
<p>保存后，为 ./sbt 脚本增加可执行权限：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chmod u+x ./sbt</div></pre></td></tr></table></figure></p>
<p>最后运行如下命令，检验 sbt 是否可用（请确保电脑处于联网状态，首次运行会处于 “Getting org.scala-sbt sbt 0.13.11 …” 的下载状态，请耐心等待。笔者等待了 7 分钟才出现第一条下载提示）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./sbt sbt-version</div></pre></td></tr></table></figure></p>
<p>只要能得到如下图的版本信息就没问题：<br><a href="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/07/4.png" target="_blank" rel="external">http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/07/4.png</a></p>
<h3 id="2-编写Scala应用程序"><a href="#2-编写Scala应用程序" class="headerlink" title="2.编写Scala应用程序"></a>2.编写Scala应用程序</h3><p>在终端中执行如下命令创建一个文件夹 sparkapp 作为应用程序根目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd ~           # 进入用户主文件夹</div><div class="line">mkdir ./sparkapp        # 创建应用程序根目录</div><div class="line">mkdir -p ./sparkapp/src/main/scala     # 创建所需的文件夹结构</div></pre></td></tr></table></figure></p>
<p>在 ./sparkapp/src/main/scala 下建立一个名为 SimpleApp.scala 的文件（vim ./sparkapp/src/main/scala/SimpleApp.scala），添加代码如下（目前不需要理解代码的具体含义，只需要理解如何编译运行代码就可以）：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* SimpleApp.scala */</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></div><div class="line"> </div><div class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleApp</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</div><div class="line">        <span class="keyword">val</span> logFile = <span class="string">"file:///usr/local/spark/README.md"</span> <span class="comment">// Should be some file on your system</span></div><div class="line">        <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"Simple Application"</span>)</div><div class="line">        <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line">        <span class="keyword">val</span> logData = sc.textFile(logFile, <span class="number">2</span>).cache()</div><div class="line">        <span class="keyword">val</span> numAs = logData.filter(line =&gt; line.contains(<span class="string">"a"</span>)).count()</div><div class="line">        <span class="keyword">val</span> numBs = logData.filter(line =&gt; line.contains(<span class="string">"b"</span>)).count()</div><div class="line">        println(<span class="string">"Lines with a: %s, Lines with b: %s"</span>.format(numAs, numBs))</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>该程序计算 /usr/local/spark/README 文件中包含 “a” 的行数 和包含 “b” 的行数。代码第8行的 /usr/local/spark 为 Spark 的安装目录，如果不是该目录请自行修改。不同于 Spark shell，独立应用程序需要通过 val sc = new SparkContext(conf) 初始化 SparkContext，SparkContext 的参数 SparkConf 包含了应用程序的信息。</p>
<h3 id="3-使用sbt打包Scala程序"><a href="#3-使用sbt打包Scala程序" class="headerlink" title="3.使用sbt打包Scala程序"></a>3.使用sbt打包Scala程序</h3><p>该程序依赖 Spark API，因此我们需要通过 sbt 进行编译打包。 请在./sparkapp 中新建文件 simple.sbt（vim ./sparkapp/simple.sbt），添加内容如下，声明该独立应用程序的信息以及与 Spark 的依赖关系：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">name := &quot;Simple Project&quot;</div><div class="line">version := &quot;1.0&quot;</div><div class="line">scalaVersion := &quot;2.11.8&quot;</div><div class="line">libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;2.1.0&quot;</div></pre></td></tr></table></figure></p>
<p>文件 simple.sbt 需要指明 Spark 和 Scala 的版本。在上面的配置信息中，scalaVersion用来指定scala的版本，sparkcore用来指定spark的版本，这两个版本信息都可以在之前的启动 Spark shell 的过程中，从屏幕的显示信息中找到。下面就是笔者在启动过程当中，看到的相关版本信息（备注：屏幕显示信息会很长，需要往回滚动屏幕仔细寻找信息）。</p>
<p>为保证 sbt 能正常运行，先执行如下命令检查整个应用程序的文件结构：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~/sparkapp</div><div class="line">find .</div></pre></td></tr></table></figure></p>
<p>文件结构应如下图所示：<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/01/spark-quick-start-guide-07-directory-structure.png" alt=""><br>SimpleApp的文件结构</p>
<p>接着，我们就可以通过如下代码将整个应用程序打包成 JAR（首次运行同样需要下载依赖包 ）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/sbt/sbt package</div></pre></td></tr></table></figure></p>
<p>对于刚安装好的Spark和sbt而言，第一次运行上面的打包命令时，会需要几分钟的运行时间，因为系统会自动从网络上下载各种文件。后面再次运行上面命令，就会很快，因为不再需要下载相关文件。<br>打包成功的话，会输出如下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hadoop@dblab:~/sparkapp$ /usr/local/sbt/sbt package</div><div class="line">OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=256M; support was removed in 8.0</div><div class="line">[info] Set current project to Simple Project (in build file:/home/hadoop/sparkapp/)</div><div class="line">[success] Total time: 2 s, completed 2017-2-19 15:45:29</div></pre></td></tr></table></figure></p>
<p>生成的 jar 包的位置为 ~/sparkapp/target/scala-2.11/simple-project_2.11-1.0.jar。</p>
<h3 id="4-通过-spark-submit-运行程序"><a href="#4-通过-spark-submit-运行程序" class="headerlink" title="4.通过 spark-submit 运行程序"></a>4.通过 spark-submit 运行程序</h3><p>最后，我们就可以将生成的 jar 包通过 spark-submit 提交到 Spark 中运行了，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">/usr/local/spark/bin/spark-submit --class &quot;SimpleApp&quot; ~/sparkapp/target/scala-2.11/simple-project_2.11-1.0.jar</div><div class="line">#上面命令执行后会输出太多信息，可以不使用上面命令，而使用下面命令查看想要的结果</div><div class="line">/usr/local/spark/bin/spark-submit --class &quot;SimpleApp&quot; ~/sparkapp/target/scala-2.11/simple-project_2.11-1.0.jar 2&gt;&amp;1 | grep &quot;Lines with a:&quot;</div></pre></td></tr></table></figure></p>
<p>最终得到的结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Lines with a: 62, Lines with b: 30</div></pre></td></tr></table></figure></p>
<p>自此，你就完成了你的第一个 Spark 应用程序了。</p>
<div class="note success"><h2 id="（二）Java独立应用编程"><a href="#（二）Java独立应用编程" class="headerlink" title="（二）Java独立应用编程"></a>（二）Java独立应用编程</h2></div>
<h3 id="1-安装maven"><a href="#1-安装maven" class="headerlink" title="1.安装maven"></a>1.安装maven</h3><p>ubuntu中没有自带安装maven，需要手动安装maven。可以访问maven官方下载自己下载。这里直接给出apache-maven-3.3.9-bin.zip的下载地址,直接点击下载即可。<br>选择安装在/usr/local/maven中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo unzip ~/下载/apache-maven-3.3.9-bin.zip -d /usr/local</div><div class="line">cd /usr/local</div><div class="line">sudo mv apache-maven-3.3.9/ ./maven</div><div class="line">sudo chown -R hadoop ./maven</div></pre></td></tr></table></figure></p>
<h3 id="2-Java应用程序代码"><a href="#2-Java应用程序代码" class="headerlink" title="2.Java应用程序代码"></a>2.Java应用程序代码</h3><p>在终端执行如下命令创建一个文件夹sparkapp2作为应用程序根目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~ #进入用户主文件夹</div><div class="line">mkdir -p ./sparkapp2/src/main/java</div></pre></td></tr></table></figure></p>
<p>在 ./sparkapp2/src/main/java 下建立一个名为 SimpleApp.java 的文件（vim ./sparkapp2/src/main/java/SimpleApp.java），添加代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*** SimpleApp.java ***/</span></div><div class="line">    <span class="keyword">import</span> org.apache.spark.api.java.*;</div><div class="line">    <span class="keyword">import</span> org.apache.spark.api.java.function.Function;</div><div class="line"> </div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleApp</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">            String logFile = <span class="string">"file:///usr/local/spark/README.md"</span>; <span class="comment">// Should be some file on your system</span></div><div class="line">            JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(<span class="string">"local"</span>, <span class="string">"Simple App"</span>,</div><div class="line">                <span class="string">"file:///usr/local/spark/"</span>, <span class="keyword">new</span> String[]&#123;<span class="string">"target/simple-project-1.0.jar"</span>&#125;);</div><div class="line">            JavaRDD&lt;String&gt; logData = sc.textFile(logFile).cache();</div><div class="line"> </div><div class="line">            <span class="keyword">long</span> numAs = logData.filter(<span class="keyword">new</span> Function&lt;String, Boolean&gt;() &#123;</div><div class="line">                <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String s)</span> </span>&#123; <span class="keyword">return</span> s.contains(<span class="string">"a"</span>); &#125;</div><div class="line">            &#125;).count();</div><div class="line"> </div><div class="line">            <span class="keyword">long</span> numBs = logData.filter(<span class="keyword">new</span> Function&lt;String, Boolean&gt;() &#123;</div><div class="line">                <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String s)</span> </span>&#123; <span class="keyword">return</span> s.contains(<span class="string">"b"</span>); &#125;</div><div class="line">            &#125;).count();</div><div class="line"> </div><div class="line">            System.out.println(<span class="string">"Lines with a: "</span> + numAs + <span class="string">", lines with b: "</span> + numBs);</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p>该程序依赖Spark Java API,因此我们需要通过Maven进行编译打包。在./sparkapp2中新建文件pom.xml(vim ./sparkapp2/pom.xml),添加内容如下，声明该独立应用程序的信息以及与Spark的依赖关系：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">&lt;project&gt;</div><div class="line">    &lt;groupId&gt;edu.berkeley&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;simple-project&lt;/artifactId&gt;</div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line">    &lt;name&gt;Simple Project&lt;/name&gt;</div><div class="line">    &lt;packaging&gt;jar&lt;/packaging&gt;</div><div class="line">    &lt;version&gt;1.0&lt;/version&gt;</div><div class="line">    &lt;repositories&gt;</div><div class="line">        &lt;repository&gt;</div><div class="line">            &lt;id&gt;Akka repository&lt;/id&gt;</div><div class="line">            &lt;url&gt;http://repo.akka.io/releases&lt;/url&gt;</div><div class="line">        &lt;/repository&gt;</div><div class="line">    &lt;/repositories&gt;</div><div class="line">    &lt;dependencies&gt;</div><div class="line">        &lt;dependency&gt; &lt;!-- Spark dependency --&gt;</div><div class="line">            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;2.1.0&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>关于Spark dependency的依赖关系，可以访问The Central Repository。搜索spark-core可以找到相关依赖关系信息。</p>
<h3 id="3-使用maven打包java程序"><a href="#3-使用maven打包java程序" class="headerlink" title="3.使用maven打包java程序"></a>3.使用maven打包java程序</h3><p>为了保证maven能够正常运行，先执行如下命令检查整个应用程序的文件结构:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd ~/sparkapp2</div><div class="line">find</div></pre></td></tr></table></figure></p>
<p>文件结构如下图：<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/07/3-1.png" alt=""></p>
<p>接着，我们可以通过如下代码将这整个应用程序打包成Jar(注意：电脑需要保持连接网络的状态，而且首次运行mvn package命令时，系统会自动从网络下载相关的依赖包，同样消耗几分钟的时间，后面再次运行mvn package命令，速度就会快很多):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/maven/bin/mvn package</div></pre></td></tr></table></figure></p>
<p>如果运行上面命令后出现类似下面的信息，说明生成Jar包成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] BUILD SUCCESS</div><div class="line">[INFO] ------------------------------------------------------------------------</div><div class="line">[INFO] Total time: 6.583 s</div><div class="line">[INFO] Finished at: 2017-02-19T15:52:08+08:00</div><div class="line">[INFO] Final Memory: 15M/121M</div><div class="line">[INFO] ------------------------------------------------------------------------</div></pre></td></tr></table></figure></p>
<h3 id="4-通过spark-submit-运行程序"><a href="#4-通过spark-submit-运行程序" class="headerlink" title="4.通过spark-submit 运行程序"></a>4.通过spark-submit 运行程序</h3><p>可以通过spark-submit提交应用程序，该命令的格式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit </div><div class="line">  --class &lt;main-class&gt;  //需要运行的程序的主类，应用程序的入口点</div><div class="line">  --master &lt;master-url&gt;  //Master URL，下面会有具体解释</div><div class="line">  --deploy-mode &lt;deploy-mode&gt;   //部署模式</div><div class="line">  ... # other options  //其他参数</div><div class="line">  &lt;application-jar&gt;  //应用程序JAR包</div><div class="line">  [application-arguments] //传递给主类的主方法的参数</div></pre></td></tr></table></figure></p>
<p>deploy-mode这个参数用来指定应用程序的部署模式，部署模式有两种：client和cluster，默认是client。当采用client部署模式时，就是直接在本地运行Driver Program，当采用cluster模式时，会在Worker节点上运行Driver Program。比较常用的部署策略是从网关机器提交你的应用程序，这个网关机器和你的Worker集群进行协作。在这种设置下，比较适合采用client模式，在client模式下，Driver直接在spark-submit进程中启动，这个进程直接作为集群的客户端，应用程序的输入和输出都和控制台相连接。因此，这种模式特别适合涉及REPL的应用程序。另一种选择是，如果你的应用程序从一个和Worker机器相距很远的机器上提交，那么采用cluster模式会更加合适，它可以减少Driver和Executor之间的网络迟延。</p>
<p>Spark的运行模式取决于传递给SparkContext的Master URL的值。Master URL可以是以下任一种形式：</p>
<ul>
<li>local 使用一个Worker线程本地化运行SPARK(完全不并行)</li>
<li>local[*] 使用逻辑CPU个数数量的线程来本地化运行Spark</li>
<li>local[K] 使用K个Worker线程本地化运行Spark（理想情况下，K应该根据运行机器的CPU核数设定）</li>
<li>spark://HOST:PORT 连接到指定的Spark standalone master。默认端口是7077.</li>
<li>yarn-client 以客户端模式连接YARN集群。集群的位置可以在HADOOP_CONF_DIR 环境变量中找到。</li>
<li>yarn-cluster 以集群模式连接YARN集群。集群的位置可以在HADOOP_CONF_DIR 环境变量中找到。</li>
<li>mesos://HOST:PORT 连接到指定的Mesos集群。默认接口是5050。</li>
</ul>
<p>最后，针对上面编译打包得到的应用程序，可以通过将生成的jar包通过spark-submit提交到Spark中运行，如下命令：</p>
<p>/usr/local/spark/bin/spark-submit –class “SimpleApp” ~/sparkapp2/target/simple-project-1.0.jar</p>
<p>#上面命令执行后会输出太多信息，可以不使用上面命令，而使用下面命令查看想要的结果<br>/usr/local/spark/bin/spark-submit –class “SimpleApp” ~/sparkapp2/target/simple-project-1.0.jar 2&gt;&amp;1 | grep “Lines with a”<br>Shell 命令<br>最后得到的结果如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Lines with a: 62, Lines with b: 30</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第一章 第四节 Spark的部署模式]]></title>
      <url>http://Melodylican.github.io/2017/02/05/Spark%E7%9A%84%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>本节首先介绍Spark支持的三种典型集群部署方式，即standalone、Spark on Mesos和Spark on YARN；然后，介绍在企业中是如何具体部署和应用Spark框架的，在企业实际应用环境中，针对不同的应用场景，可以采用不同的部署应用方式，或者采用Spark完全替代原有的Hadoop架构，或者采用Spark和Hadoop一起部署的方式。<br><a id="more"></a><br><div class="note success"><h2 id="Spark三种部署方式"><a href="#Spark三种部署方式" class="headerlink" title="Spark三种部署方式"></a>Spark三种部署方式</h2></div><br>Spark应用程序在集群上部署运行时，可以由不同的组件为其提供资源管理调度服务（资源包括CPU、内存等）。比如，可以使用自带的独立集群管理器（standalone），或者使用YARN，也可以使用Mesos。因此，Spark包括三种不同类型的集群部署方式，包括standalone、Spark on Mesos和Spark on YARN。</p>
<h3 id="1-standalone模式"><a href="#1-standalone模式" class="headerlink" title="1.standalone模式"></a>1.standalone模式</h3><p>与MapReduce1.0框架类似，Spark框架本身也自带了完整的资源调度管理服务，可以独立部署到一个集群中，而不需要依赖其他系统来为其提供资源管理调度服务。在架构的设计上，Spark与MapReduce1.0完全一致，都是由一个Master和若干个Slave构成，并且以槽（slot）作为资源分配单位。不同的是，Spark中的槽不再像MapReduce1.0那样分为Map 槽和Reduce槽，而是只设计了统一的一种槽提供给各种任务来使用。</p>
<h3 id="2-Spark-on-Mesos模式"><a href="#2-Spark-on-Mesos模式" class="headerlink" title="2.Spark on Mesos模式"></a>2.Spark on Mesos模式</h3><p>Mesos是一种资源调度管理框架，可以为运行在它上面的Spark提供服务。Spark on Mesos模式中，Spark程序所需要的各种资源，都由Mesos负责调度。由于Mesos和Spark存在一定的血缘关系，因此，Spark这个框架在进行设计开发的时候，就充分考虑到了对Mesos的充分支持，因此，相对而言，Spark运行在Mesos上，要比运行在YARN上更加灵活、自然。目前，Spark官方推荐采用这种模式，所以，许多公司在实际应用中也采用该模式。</p>
<h3 id="3-Spark-on-YARN模式"><a href="#3-Spark-on-YARN模式" class="headerlink" title="3. Spark on YARN模式"></a>3. Spark on YARN模式</h3><p>Spark可运行于YARN之上，与Hadoop进行统一部署，即“Spark on YARN”，其架构如图9-13所示，资源管理和调度依赖YARN，分布式存储则依赖HDFS。</p>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-13-Spark-on-Yarn%E6%9E%B6%E6%9E%84.jpg" alt=""><br>图9-13 Spark on YARN架构</p>
<div class="note success"><h2 id="从“Hadoop-Storm”架构转向Spark架构"><a href="#从“Hadoop-Storm”架构转向Spark架构" class="headerlink" title="从“Hadoop+Storm”架构转向Spark架构"></a>从“Hadoop+Storm”架构转向Spark架构</h2></div>
<p>为了能同时进行批处理与流处理，企业应用中通常会采用“Hadoop+Storm”的架构（也称为Lambda架构）。图9-14给出了采用“Hadoop+Storm”部署方式的一个案例，在这种部署架构中，Hadoop和Storm框架部署在资源管理框架YARN（或Mesos）之上，接受统一的资源管理和调度，并共享底层的数据存储（HDFS、HBase、Cassandra等）。Hadoop负责对批量历史数据的实时查询和离线分析，而Storm则负责对流数据的实时处理。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-14-%E9%87%87%E7%94%A8HadoopStorm%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F%E7%9A%84%E4%B8%80%E4%B8%AA%E6%A1%88%E4%BE%8B.jpg" alt=""><br>图9-14 采用“Hadoop+Storm”部署方式的一个案例</p>
<p>但是，上面这种架构部署较为繁琐。由于Spark同时支持批处理与流处理，因此，对于一些类型的企业应用而言，从“Hadoop+Storm”架构转向Spark架构（如图9-15所示）就成为一种很自然的选择。采用Spark架构具有如下优点：</p>
<ul>
<li> 实现一键式安装和配置、线程级别的任务监控和告警；</li>
<li> 降低硬件集群、软件维护、任务监控和应用开发的难度；</li>
<li> 便于做成统一的硬件、计算平台资源池。<br>需要说明的是，Spark Streaming的原理是将流数据分解成一系列短小的批处理作业，每个短小的批处理作业使用面向批处理的Spark Core进行处理，通过这种方式变相实现流计算，而不是真正实时的流计算，因而通常无法实现毫秒级的响应。因此，对于需要毫秒级实时响应的企业应用而言，仍然需要采用流计算框架（如Storm）。</li>
</ul>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-15-%E7%94%A8Spark%E6%9E%B6%E6%9E%84%E6%BB%A1%E8%B6%B3%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86%E9%9C%80%E6%B1%82.jpg" alt=""><br>图9-15 用Spark架构同时满足批处理和流处理需求</p>
<div class="note success"><h2 id="Hadoop和Spark的统一部署"><a href="#Hadoop和Spark的统一部署" class="headerlink" title="Hadoop和Spark的统一部署"></a>Hadoop和Spark的统一部署</h2></div>
<p>一方面，由于Hadoop生态系统中的一些组件所实现的功能，目前还是无法由Spark取代的，比如，Storm可以实现毫秒级响应的流计算，但是，Spark则无法做到毫秒级响应。另一方面，企业中已经有许多现有的应用，都是基于现有的Hadoop组件开发的，完全转移到Spark上需要一定的成本。因此，在许多企业实际应用中，Hadoop和Spark的统一部署是一种比较现实合理的选择。<br>由于Hadoop MapReduce、HBase、Storm和Spark等，都可以运行在资源管理框架YARN之上，因此，可以在YARN之上进行统一部署（如图9-16所示）。这些不同的计算框架统一运行在YARN中，可以带来如下好处：</p>
<ul>
<li> 计算资源按需伸缩；</li>
<li> 不用负载应用混搭，集群利用率高；</li>
<li> 共享底层存储，避免数据跨集群迁移。</li>
</ul>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-16-Hadoop%E5%92%8CSpark%E7%9A%84%E7%BB%9F%E4%B8%80%E9%83%A8%E7%BD%B2.jpg" alt=""><br>图9-16 Hadoop和Spark的统一部署</p>
<font color="grey">注：此博客参考自 厦门大学林子雨老师博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第一章 第三节 RDD的设计与运行原理]]></title>
      <url>http://Melodylican.github.io/2017/02/04/RDD%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/</url>
      <content type="html"><![CDATA[<p>Spark的核心是建立在统一的抽象RDD之上，使得Spark的各个组件可以无缝进行集成，在同一个应用程序中完成大数据计算任务。RDD的设计理念源自AMP实验室发表的论文《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》。<br><a id="more"></a><br><div class="note success"><h2 id="1-RDD设计背景"><a href="#1-RDD设计背景" class="headerlink" title="1.RDD设计背景"></a>1.RDD设计背景</h2></div><br>在实际应用中，存在许多迭代式算法（比如机器学习、图算法等）和交互式数据挖掘工具，这些应用场景的共同之处是，不同计算阶段之间会重用中间结果，即一个阶段的输出结果会作为下一个阶段的输入。但是，目前的MapReduce框架都是把中间结果写入到HDFS中，带来了大量的数据复制、磁盘IO和序列化开销。虽然，类似Pregel等图计算框架也是将结果保存在内存当中，但是，这些框架只能支持一些特定的计算模式，并没有提供一种通用的数据抽象。RDD就是为了满足这种需求而出现的，它提供了一个抽象的数据架构，我们不必担心底层数据的分布式特性，只需将具体的应用逻辑表达为一系列转换处理，不同RDD之间的转换操作形成依赖关系，可以实现管道化，从而避免了中间结果的存储，大大降低了数据复制、磁盘IO和序列化开销。</p>
<div class="note success"><h2 id="2-RDD概念"><a href="#2-RDD概念" class="headerlink" title="2.RDD概念"></a>2.RDD概念</h2></div>
<p>一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算。RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集来创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和groupBy）而创建得到新的RDD。RDD提供了一组丰富的操作以支持常见的数据运算，分为“行动”（Action）和“转换”（Transformation）两种类型，前者用于执行计算并指定输出的形式，后者指定RDD之间的相互依赖关系。两类操作的主要区别是，转换操作（比如map、filter、groupBy、join等）接受RDD并返回RDD，而行动操作（比如count、collect等）接受RDD但是返回非RDD（即输出一个值或结果）。RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改。因此，RDD比较适合对于数据集中元素执行相同操作的批处理式应用，而不适合用于需要异步、细粒度状态的应用，比如Web应用系统、增量式的网页爬虫等。正因为这样，这种粗粒度转换接口设计，会使人直觉上认为RDD的功能很受限、不够强大。但是，实际上RDD已经被实践证明可以很好地应用于许多并行计算应用中，可以具备很多现有计算框架（比如MapReduce、SQL、Pregel等）的表达能力，并且可以应用于这些框架处理不了的交互式数据挖掘应用。<br>Spark用Scala语言实现了RDD的API，程序员可以通过调用API实现对RDD的各种操作。RDD典型的执行过程如下：</p>
<ol>
<li>RDD读入外部数据源（或者内存中的集合）进行创建；</li>
<li>RDD经过一系列的“转换”操作，每一次都会产生不同的RDD，供给下一个“转换”使用；</li>
<li>最后一个RDD经“行动”操作进行处理，并输出到外部数据源（或者变成Scala集合或标量）。<br>需要说明的是，RDD采用了惰性调用，即在RDD的执行过程中（如图9-8所示），真正的计算发生在RDD的“行动”操作，对于“行动”之前的所有“转换”操作，Spark只是记录下“转换”操作应用的一些基础数据集以及RDD生成的轨迹，即相互之间的依赖关系，而不会触发真正的计算。</li>
</ol>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-8-Spark%E7%9A%84%E8%BD%AC%E6%8D%A2%E5%92%8C%E8%A1%8C%E5%8A%A8%E6%93%8D%E4%BD%9C.jpg" alt=""><br>图9-8 Spark的转换和行动操作</p>
<p>例如，在图9-9中，从输入中逻辑上生成A和C两个RDD，经过一系列“转换”操作，逻辑上生成了F（也是一个RDD），之所以说是逻辑上，是因为这时候计算并没有发生，Spark只是记录了RDD之间的生成和依赖关系。当F要进行输出时，也就是当F进行“行动”操作的时候，Spark才会根据RDD的依赖关系生成DAG，并从起点开始真正的计算。</p>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-9-RDD%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B.jpg" alt=""><br>图9-9 RDD执行过程的一个实例</p>
<p>上述这一系列处理称为一个“血缘关系（Lineage）”，即DAG拓扑排序的结果。采用惰性调用，通过血缘关系连接起来的一系列RDD操作就可以实现管道化（pipeline），避免了多次转换操作之间数据同步的等待，而且不用担心有过多的中间数据，因为这些具有血缘关系的操作都管道化了，一个操作得到的结果不需要保存为中间数据，而是直接管道式地流入到下一个操作进行处理。同时，这种通过血缘关系把一系列操作进行管道化连接的设计方式，也使得管道中每次操作的计算变得相对简单，保证了每个操作在处理逻辑上的单一性；相反，在MapReduce的设计中，为了尽可能地减少MapReduce过程，在单个MapReduce中会写入过多复杂的逻辑。<br>例1：一个Spark的“Hello World”程序<br>这里以一个“Hello World”入门级Spark程序来解释RDD执行过程，这个程序的功能是读取一个HDFS文件，计算出包含字符串“Hello World”的行数。<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> sc= <span class="keyword">new</span> <span class="type">SparkContext</span>(“spark:<span class="comment">//localhost:7077”,”Hello World”, “YOUR_SPARK_HOME”,”YOUR_APP_JAR”)</span></div><div class="line"><span class="keyword">val</span> fileRDD = sc.textFile(“hdfs:<span class="comment">//192.168.0.103:9000/examplefile”)</span></div><div class="line"><span class="keyword">val</span> filterRDD = fileRDD.filter(_.contains(“<span class="type">Hello</span> <span class="type">World</span>”))</div><div class="line">filterRDD.cache()</div><div class="line">filterRDD.count()</div></pre></td></tr></table></figure></p>
<p>可以看出，一个Spark应用程序，基本是基于RDD的一系列计算操作。第1行代码用于创建SparkContext对象；第2行代码从HDFS文件中读取数据创建一个RDD；第3行代码对fileRDD进行转换操作得到一个新的RDD，即filterRDD；第4行代码表示对filterRDD进行持久化，把它保存在内存或磁盘中（这里采用cache接口把数据集保存在内存中），方便后续重复使用，当数据被反复访问时（比如查询一些热点数据，或者运行迭代算法），这是非常有用的，而且通过cache()可以缓存非常大的数据集，支持跨越几十甚至上百个节点；第5行代码中的count()是一个行动操作，用于计算一个RDD集合中包含的元素个数。这个程序的执行过程如下：</p>
<ul>
<li> 创建这个Spark程序的执行上下文，即创建SparkContext对象；</li>
<li> 从外部数据源（即HDFS文件）中读取数据创建fileRDD对象；</li>
<li> 构建起fileRDD和filterRDD之间的依赖关系，形成DAG图，这时候并没有发生真正的计算，只是记录转换的轨迹；</li>
<li> 执行到第5行代码时，count()是一个行动类型的操作，触发真正的计算，开始实际执行从fileRDD到filterRDD的转换操作，并把结果持久化到内存中，最后计算出filterRDD中包含的元素个数。</li>
</ul>
<div class="note success"><h2 id="3-RDD特性"><a href="#3-RDD特性" class="headerlink" title="3.RDD特性"></a>3.RDD特性</h2></div>
<p>总体而言，Spark采用RDD以后能够实现高效计算的主要原因如下：<br>（1）高效的容错性。现有的分布式共享内存、键值存储、内存数据库等，为了实现容错，必须在集群节点之间进行数据复制或者记录日志，也就是在节点之间会发生大量的数据传输，这对于数据密集型应用而言会带来很大的开销。在RDD的设计中，数据只读，不可修改，如果需要修改数据，必须从父RDD转换到子RDD，由此在不同RDD之间建立了血缘关系。所以，RDD是一种天生具有容错机制的特殊集合，不需要通过数据冗余的方式（比如检查点）实现容错，而只需通过RDD父子依赖（血缘）关系重新计算得到丢失的分区来实现容错，无需回滚整个系统，这样就避免了数据复制的高开销，而且重算过程可以在不同节点之间并行进行，实现了高效的容错。此外，RDD提供的转换操作都是一些粗粒度的操作（比如map、filter和join），RDD依赖关系只需要记录这种粗粒度的转换操作，而不需要记录具体的数据和各种细粒度操作的日志（比如对哪个数据项进行了修改），这就大大降低了数据密集型应用中的容错开销；<br>（2）中间结果持久化到内存。数据在内存中的多个RDD操作之间进行传递，不需要“落地”到磁盘上，避免了不必要的读写磁盘开销；<br>（3）存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化开销。</p>
<div class="note success"><h2 id="4-RDD之间的依赖关系"><a href="#4-RDD之间的依赖关系" class="headerlink" title="4. RDD之间的依赖关系"></a>4. RDD之间的依赖关系</h2></div>
<p>RDD中不同的操作会使得不同RDD中的分区会产生不同的依赖。RDD中的依赖关系分为窄依赖（Narrow Dependency）与宽依赖（Wide Dependency），图9-10展示了两种依赖之间的区别。<br>窄依赖表现为一个父RDD的分区对应于一个子RDD的分区，或多个父RDD的分区对应于一个子RDD的分区；比如图9-10(a)中，RDD1是RDD2的父RDD，RDD2是子RDD，RDD1的分区1，对应于RDD2的一个分区（即分区4）；再比如，RDD6和RDD7都是RDD8的父RDD，RDD6中的分区（分区15）和RDD7中的分区（分区18），两者都对应于RDD8中的一个分区（分区21）。<br>宽依赖则表现为存在一个父RDD的一个分区对应一个子RDD的多个分区。比如图9-10(b)中，RDD9是RDD12的父RDD，RDD9中的分区24对应了RDD12中的两个分区（即分区27和分区28）。<br>总体而言，如果父RDD的一个分区只被一个子RDD的一个分区所使用就是窄依赖，否则就是宽依赖。窄依赖典型的操作包括map、filter、union等，宽依赖典型的操作包括groupByKey、sortByKey等。对于连接（join）操作，可以分为两种情况。<br>（1）对输入进行协同划分，属于窄依赖（如图9-10(a)所示）。所谓协同划分（co-partitioned）是指多个父RDD的某一分区的所有“键（key）”，落在子RDD的同一个分区内，不会产生同一个父RDD的某一分区，落在子RDD的两个分区的情况。<br>（2）对输入做非协同划分，属于宽依赖，如图9-10(b)所示。<br>对于窄依赖的RDD，可以以流水线的方式计算所有父分区，不会造成网络之间的数据混合。对于宽依赖的RDD，则通常伴随着Shuffle操作，即首先需要计算好所有父分区数据，然后在节点之间进行Shuffle。</p>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-10-%E7%AA%84%E4%BE%9D%E8%B5%96%E4%B8%8E%E5%AE%BD%E4%BE%9D%E8%B5%96%E7%9A%84%E5%8C%BA%E5%88%AB.jpg" alt=""><br>图9-10 窄依赖与宽依赖的区别</p>
<p>Spark的这种依赖关系设计，使其具有了天生的容错性，大大加快了Spark的执行速度。因为，RDD数据集通过“血缘关系”记住了它是如何从其它RDD中演变过来的，血缘关系记录的是粗颗粒度的转换操作行为，当这个RDD的部分分区数据丢失时，它可以通过血缘关系获取足够的信息来重新运算和恢复丢失的数据分区，由此带来了性能的提升。相对而言，在两种依赖关系中，窄依赖的失败恢复更为高效，它只需要根据父RDD分区重新计算丢失的分区即可（不需要重新计算所有分区），而且可以并行地在不同节点进行重新计算。而对于宽依赖而言，单个节点失效通常意味着重新计算过程会涉及多个父RDD分区，开销较大。此外，Spark还提供了数据检查点和记录日志，用于持久化中间RDD，从而使得在进行失败恢复时不需要追溯到最开始的阶段。在进行故障恢复时，Spark会对数据检查点开销和重新计算RDD分区的开销进行比较，从而自动选择最优的恢复策略。</p>
<div class="note success"><h2 id="5-阶段的划分"><a href="#5-阶段的划分" class="headerlink" title="5.阶段的划分"></a>5.阶段的划分</h2></div>
<p>Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分阶段，具体划分方法是：在DAG中进行反向解析，遇到宽依赖就断开，遇到窄依赖就把当前的RDD加入到当前的阶段中；将窄依赖尽量划分在同一个阶段中，可以实现流水线计算（具体的阶段划分算法请参见AMP实验室发表的论文《Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing》）。例如，如图9-11所示，假设从HDFS中读入数据生成3个不同的RDD（即A、C和E），通过一系列转换操作后再将计算结果保存回HDFS。对DAG进行解析时，在依赖图中进行反向解析，由于从RDD A到RDD B的转换以及从RDD B和F到RDD G的转换，都属于宽依赖，因此，在宽依赖处断开后可以得到三个阶段，即阶段1、阶段2和阶段3。可以看出，在阶段2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作，比如，分区7通过map操作生成的分区9，可以不用等待分区8到分区9这个转换操作的计算结束，而是继续进行union操作，转换得到分区13，这样流水线执行大大提高了计算的效率。<br><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-11-%E6%A0%B9%E6%8D%AERDD%E5%88%86%E5%8C%BA%E7%9A%84%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E5%88%92%E5%88%86%E9%98%B6%E6%AE%B5.jpg" alt=""><br>图9-11根据RDD分区的依赖关系划分阶段</p>
<p>由上述论述可知，把一个DAG图划分成多个“阶段”以后，每个阶段都代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集合。每个任务集合会被提交给任务调度器（TaskScheduler）进行处理，由任务调度器将任务分发给Executor运行。</p>
<div class="note success"><h3 id="6-RDD运行过程"><a href="#6-RDD运行过程" class="headerlink" title="6.RDD运行过程"></a>6.RDD运行过程</h3></div>
<p>通过上述对RDD概念、依赖关系和阶段划分的介绍，结合之前介绍的Spark运行基本流程，这里再总结一下RDD在Spark架构中的运行过程（如图9-12所示）：<br>（1）创建RDD对象；<br>（2）SparkContext负责计算RDD之间的依赖关系，构建DAG；<br>（3）DAGScheduler负责把DAG图分解成多个阶段，每个阶段中包含了多个任务，每个任务会被任务调度器分发给各个工作节点（Worker Node）上的Executor去执行。</p>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-12-RDD%E5%9C%A8Spark%E4%B8%AD%E7%9A%84%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B.jpg" alt=""><br>图9-12 RDD在Spark中的运行过程</p>
<font color="grey">注：此博客参考自 厦门大学林子雨博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark入门 第一章 第二节 Spark运行架构]]></title>
      <url>http://Melodylican.github.io/2017/02/01/Spark%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84/</url>
      <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>在具体讲解Spark运行架构之前，需要先了解几个重要的概念：</p>
<ul>
<li>RDD：是弹性分布式数据集（Resilient Distributed Dataset）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型；</li>
<li>DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系；</li>
<li>Executor：是运行在工作节点（Worker Node）上的一个进程，负责运行任务，并为应用程序存储数据；</li>
<li>应用：用户编写的Spark应用程序；</li>
<li>任务：运行在Executor上的工作单元；</li>
<li>作业：一个作业包含多个RDD及作用于相应RDD上的各种操作；</li>
<li>阶段：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为“阶段”，或者也被称为“任务集”。<a id="more"></a>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2>如图所示，Spark运行架构包括集群资源管理器（Cluster Manager）、运行作业任务的工作节点（Worker Node）、每个应用的任务控制节点（Driver）和每个工作节点上负责具体任务的执行进程（Executor）。其中，集群资源管理器可以是Spark自带的资源管理器，也可以是YARN或Mesos等资源管理框架。<br>与Hadoop MapReduce计算框架相比，Spark所采用的Executor有两个优点：一是利用多线程来执行具体的任务（Hadoop MapReduce采用的是进程模型），减少任务的启动开销；二是Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，当需要多轮迭代计算时，可以将中间结果存储到这个存储模块里，下次需要时，就可以直接读该存储模块里的数据，而不需要读写到HDFS等文件系统里，因而有效减少了IO开销；或者在交互式查询场景下，预先将表缓存到该存储系统上，从而可以提高读写IO性能。</li>
</ul>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-5-Spark%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84.jpg" alt=""></p>
<p>总体而言，如图所示，在Spark中，一个应用（Application）由一个任务控制节点（Driver）和若干个作业（Job）构成，一个作业由多个阶段（Stage）构成，一个阶段由多个任务（Task）组成。当执行一个应用时，任务控制节点会向集群管理器（Cluster Manager）申请资源，启动Executor，并向Executor发送应用程序代码和文件，然后在Executor上执行任务，运行结束后，执行结果会返回给任务控制节点，或者写到HDFS或者其他数据库中。</p>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-6-Spark%E4%B8%AD%E5%90%84%E7%A7%8D%E6%A6%82%E5%BF%B5%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BA%92%E5%85%B3%E7%B3%BB.jpg" alt=""></p>
<h2 id="Spark运行基本流程"><a href="#Spark运行基本流程" class="headerlink" title="Spark运行基本流程"></a>Spark运行基本流程</h2><p>如图 所示，Spark的基本运行流程如下：<br>（1）当一个Spark应用被提交时，首先需要为这个应用构建起基本的运行环境，即由任务控制节点（Driver）创建一个SparkContext，由SparkContext负责和资源管理器（Cluster Manager）的通信以及进行资源的申请、任务的分配和监控等。SparkContext会向资源管理器注册并申请运行Executor的资源；<br>（2）资源管理器为Executor分配资源，并启动Executor进程，Executor运行情况将随着“心跳”发送到资源管理器上；<br>（3）SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAG调度器（DAGScheduler）进行解析，将DAG图分解成多个“阶段”（每个阶段都是一个任务集），并且计算出各个阶段之间的依赖关系，然后把一个个“任务集”提交给底层的任务调度器（TaskScheduler）进行处理；Executor向SparkContext申请任务，任务调度器将任务分发给Executor运行，同时，SparkContext将应用程序代码发放给Executor；<br>（4）任务在Executor上运行，把执行结果反馈给任务调度器，然后反馈给DAG调度器，运行完毕后写入数据并释放所有资源。</p>
<p><img src="http://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-7-Spark%E8%BF%90%E8%A1%8C%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E5%9B%BE.jpg" alt=""></p>
<p>总体而言，Spark运行架构具有以下特点：<br>（1）每个应用都有自己专属的Executor进程，并且该进程在应用运行期间一直驻留。Executor进程以多线程的方式运行任务，减少了多进程任务频繁的启动开销，使得任务执行变得非常高效和可靠；<br>（2）Spark运行过程与资源管理器无关，只要能够获取Executor进程并保持通信即可；<br>（3）Executor上有一个BlockManager存储模块，类似于键值存储系统（把内存和磁盘共同作为存储设备），在处理迭代计算任务时，不需要把中间结果写入到HDFS等文件系统，而是直接放在这个存储系统上，后续有需要时就可以直接读取；在交互式查询场景下，也可以把表提前缓存到这个存储系统上，提高读写IO性能；<br>（4）任务采用了数据本地性和推测执行等优化机制。数据本地性是尽量将计算移到数据所在的节点上进行，即“计算向数据靠拢”，因为移动计算比移动数据所占的网络资源要少得多。而且，Spark采用了延时调度机制，可以在更大的程度上实现执行过程优化。比如，拥有数据的节点当前正被其他的任务占用，那么，在这种情况下是否需要将数据移动到其他的空闲节点呢？答案是不一定。因为，如果经过预测发现当前节点结束当前任务的时间要比移动数据的时间还要少，那么，调度就会等待，直到当前节点可用。</p>
<font color="grey">注：此博客参考自 厦门大学林子雨博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ZooKeeper经典应用场景]]></title>
      <url>http://Melodylican.github.io/2017/01/10/ZooKeeper%E7%BB%8F%E5%85%B8%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
      <content type="html"><![CDATA[<p>转载自：<a href="http://rdc.taobao.com/team/jm/archives/1232" target="_blank" rel="external">http://rdc.taobao.com/team/jm/archives/1232</a></p>
<p>这篇文章写的非常贴近实际，比官方好！</p>
<p>ZooKeeper是一个高可用的分布式数据管理与系统协调框架。基于对Paxos算法的实现，使该框架保证了分布式环境中数据的强一致性，也正是基于这样的特性，使得ZooKeeper解决很多分布式问题。网上对ZK的应用场景也有不少介绍，本文将结合作者身边的项目例子，系统地对ZK的应用场景进行一个分门归类的介绍。</p>
<p>值得注意的是，ZK并非天生就是为这些应用场景设计的，都是后来众多开发者根据其框架的特性，利用其提供的一系列API接口（或者称为原语集），摸索出来的典型使用方法。因此，也非常欢迎读者分享你在ZK使用上的奇技淫巧。<br><a id="more"></a></p>
<h1 id="ZooKeeper典型应用场景一览"><a href="#ZooKeeper典型应用场景一览" class="headerlink" title="ZooKeeper典型应用场景一览"></a>ZooKeeper典型应用场景一览</h1><h2 id="数据发布与订阅（配置中心）"><a href="#数据发布与订阅（配置中心）" class="headerlink" title="数据发布与订阅（配置中心）"></a>数据发布与订阅（配置中心）</h2><p>发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，服务式服务框架的服务地址列表等就非常适合使用。</p>
<ul>
<li>应用中用到的一些配置信息放到ZK上进行集中管理。这类场景通常是这样：应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。</li>
<li>分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在ZK的一些指定节点，供各个客户端订阅使用。</li>
<li>分布式日志收集系统。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用来分配收集任务单元，因此需要在ZK上创建一个以应用名作为path的节点P，并将这个应用的所有机器ip，以子节点的形式注册到节点P上，这样一来就能够实现机器变动的时候，能够实时通知到收集器调整任务分配。</li>
<li>系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息的发问。通常是暴露出接口，例如JMX接口，来获取一些运行时的信息。引入ZK之后，就不用自己实现一套方案了，只要将这些信息存放到指定的ZK节点上即可。<br><strong>注意</strong>：在上面提到的应用场景中，有个默认前提是：数据量很小，但是数据更新可能会比较快的场景。</li>
</ul>
<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>这里说的负载均衡是指软负载均衡。在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，其中比较典型的是消息中间件中的生产者，消费者负载均衡。</p>
<p>消息中间件中发布者和订阅者的负载均衡，linkedin开源的KafkaMQ和阿里开源的metaq都是通过zookeeper来做到生产者、消费者的负载均衡。这里以metaq为例如讲下：</p>
<ol>
<li>生产者负载均衡：metaq发送消息的时候，生产者在发送消息的时候必须选择一台broker上的一个分区来发送消息，因此metaq在运行过程中，会把所有broker和对应的分区信息全部注册到ZK指定节点上，默认的策略是一个依次轮询的过程，生产者在通过ZK获取分区列表之后，会按照brokerId和partition的顺序排列组织成一个有序的分区列表，发送的时候按照从头到尾循环往复的方式选择一个分区来发送消息。</li>
<li>消费负载均衡：在消费过程中，一个消费者会消费一个或多个分区中的消息，但是一个分区只会由一个消费者来消费。MetaQ的消费策略是：</li>
</ol>
<ul>
<li>每个分区针对同一个group只挂载一个消费者。</li>
<li>如果同一个group的消费者数目大于分区数目，则多出来的消费者将不参与消费。</li>
<li>如果同一个group的消费者数目小于分区数目，则有部分消费者需要额外承担消费任务。<br>在某个消费者故障或者重启等情况下，其他消费者会感知到这一变化（通过 zookeeper watch消费者列表），然后重新进行负载均衡，保证所有的分区都有消费者进行消费。</li>
</ul>
<h2 id="命名服务-Naming-Service"><a href="#命名服务-Naming-Service" class="headerlink" title="命名服务(Naming Service)"></a>命名服务(Naming Service)</h2><p>命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。</p>
<p>阿里巴巴集团开源的分布式服务框架Dubbo中使用ZooKeeper来作为其命名服务，维护全局的服务地址列表，点击这里查看Dubbo开源项目。在Dubbo实现中：</p>
<ul>
<li>服务提供者在启动的时候，向ZK上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这个操作就完成了服务的发布。</li>
<li>服务消费者启动的时候，订阅/dubbo/${serviceName}/providers目录下的提供者URL地址， 并向/dubbo/${serviceName} /consumers目录下写入自己的URL地址。<br>注意，所有向ZK上注册的地址都是临时节点，这样就能够保证服务提供者和消费者能够自动感应资源的变化。</li>
</ul>
<p>另外，Dubbo还有针对服务粒度的监控，方法是订阅/dubbo/${serviceName}目录下所有提供者和消费者的信息。</p>
<h2 id="分布式通知-协调"><a href="#分布式通知-协调" class="headerlink" title="分布式通知/协调"></a>分布式通知/协调</h2><p>ZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理</p>
<ul>
<li>另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。</li>
<li>另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而ZK就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。</li>
<li>另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。<br>总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合</li>
</ul>
<h2 id="集群管理与Master选举"><a href="#集群管理与Master选举" class="headerlink" title="集群管理与Master选举"></a>集群管理与Master选举</h2><p>集群机器监控：这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：</p>
<ol>
<li>集群中机器有变动的时候，牵连修改的东西比较多。</li>
<li><p>有一定的延时。<br>利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：</p>
</li>
<li><p>客户端在节点 x 上注册一个Watcher，那么如果 x?的子节点变化了，会通知该客户端。</p>
</li>
<li>创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。<br>例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。</li>
</ol>
<p><font color="red"><strong>Master选举则是zookeeper中最为经典的应用场景了</strong></font>。</p>
<p>在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。</p>
<p>利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。</p>
<p>另外，这种场景演化一下，就是动态Master选举。这就要用到?EPHEMERAL_SEQUENTIAL类型节点的特性了。</p>
<p>上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 ,?/currentMaster/{sessionId}-2 ,?/currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。</p>
<ul>
<li>在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成，然后同步到集群中其它机器。另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。</li>
<li>在Hbase中，也是使用ZooKeeper来实现动态HMaster的选举。在Hbase实现中，会在ZK上存储一些ROOT表的地址和HMaster的地址，HRegionServer也会把自己以临时节点（Ephemeral）的方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的存活状态，同时，一旦HMaster出现问题，会重新选举出一个HMaster来运行，从而避免了HMaster的单点问题<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2></li>
</ul>
<p>分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是保持独占，另一个是控制时序。</p>
<ul>
<li>所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。</li>
<li>控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。<h2 id="分布式队列"><a href="#分布式队列" class="headerlink" title="分布式队列"></a>分布式队列</h2></li>
</ul>
<p>队列方面，简单地讲有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第一种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致，这里不再赘述。</p>
<p>第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> ZooKeeper </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[使用Java开发高性能网站需要注意的那些事]]></title>
      <url>http://Melodylican.github.io/2017/01/10/Java%E5%BC%80%E5%8F%91%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%AB%99%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
      <content type="html"><![CDATA[<p><center><br><img src="http://www.javabloger.com/wp-content/uploads/2016/02/li8hzoM36n1XM.jpg" alt=""><br></center><br><a id="more"></a><br>近期各家IT媒体举办的业内技术大会让很多网站都在披露自己的技术内幕与同行们分享，大到facebook，百度，小到刚起步的网站。facebook，百度之类的大型网站采用的技术和超凡的处理能力的确给人耳目一新的感觉，但并不是每个网站都是像facebook，百度 有上亿的用户访问流量，有海量的数据需要存储，需要使用到mapreduce/并行计算，HBase/列存储这些技术不可。技术手段始终是运营的支撑，对于当前的运营环境适用就好，没有必要非要赶个时髦，一定要和某项流行的技术产生点关系才善罢甘休。</p>
<p>在最近的技术大会中我们更多的目光都聚焦在这些大型网站，其实中小型门户网站的技术体系也是值得去探讨和关注。全天下的攻城师们并不是都在为这些大型门户网站服务，更多的攻城师们正在默默无闻的为一些刚刚起步的中小型网站服务，而且占据了攻城师队伍中的60%以上的人群。在关注大型门户网站的时候，中小型门户网站的技术发展和实战经验更值得去分享。</p>
<p>无论大型门户网站还是中小型垂直类型网站都会对稳定性、性能和可伸缩性有所追求。大型网站的技术经验分享值得我们去学习和借用，但落实到更具体的实践上并不是对所有网站可以适用,其他语言开发的网站我还不敢多说，但Java开发的系统，我还是能您给插上几句话：</p>
<h2 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h2><p>JEE容器中运行的JVM参数配置参数的正确使用直接关系到整个系统的性能和处理能力，JVM的调优主要是对内存管理方面的调优，优化的方向分为以下4点：<br>1.HeapSize             堆的大小，也可以说Java虚拟机使用内存的策略，这点是非常关键的。<br>2.GarbageCollector  通过配置相关的参数进行Java中的垃圾收集器的4个算法(策略)进行使用。<br>3.StackSize             栈是JVM的内存指令区,每个线程都有他自己的Stack，Stack的大小限制着线程的数量。<br>4.DeBug/Log           在JVM中还可以设置对JVM运行时的日志和JVM挂掉后的日志输出，这点非常的关键，根据各类JVM的日志输出才能配置合适的参数。<br>网上随处可见JVM的配置技巧，但是我还是推荐阅读Sun官方的2篇文章，可以对配置参数的其所依然有一个了解<br>1.Java HotSpot VM Options<br><a href="http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html</a><br>2.Troubleshooting Guide for Java SE 6 with HotSpot VM <a href="http://www.oracle.com/technetwork/java/javase/index-137495.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/index-137495.html</a><br>另外，我相信不是每个人攻城师都是天天对着这些JVM参数的，如果你忘记了那些关键的参数你可以输入Java -X(大写X)进行提示。</p>
<h2 id="JDBC"><a href="#JDBC" class="headerlink" title="JDBC"></a>JDBC</h2><p>针对MySQL的JDBC的参数在之前的文章中也有介绍过，在单台机器或者集群的环境下合理的使用JDBC中的配置参数对操作数据库也有很大的影响。<br>一些所谓高性能的 Java ORM开源框架也就是打开了很多JDBC中的默认参数：<br>1.例如：autoReconnect、prepStmtCacheSize、cachePrepStmts、useNewIO、blobSendChunkSize 等，<br>2.例如集群环境下：roundRobinLoadBalance、failOverReadOnly、autoReconnectForPools、secondsBeforeRetryMaster。<br>具体内容可以参阅MySQL的JDBC官方使用手册：<br><a href="http://dev.mysql.com/doc/refman/5.1/zh/connectors.html#cj-jdbc-reference" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.1/zh/connectors.html#cj-jdbc-reference</a></p>
<h2 id="数据库连接池-DataSource"><a href="#数据库连接池-DataSource" class="headerlink" title="数据库连接池(DataSource)"></a>数据库连接池(DataSource)</h2><p>应用程序与数据库连接频繁的交互会给系统带来瓶颈和大量的开销会影响到系统的性能，JDBC连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而再不是重新建立一个连接，因此应用程序不需要频繁的与数据库开关连接，并且可以释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏。这项技术能明显提高对数据库操作的性能。<br>在此我认为有一点需要说明：<br>连接池的使用也是需要关闭，因为在数据库连接池启动的时候就预先和数据库获得了相应的连接，之后不再需要应用程序直接的和数据库打交道，因为应用程序使用数据库连接池是一个“借”的概念，应用程序从数据库连接池中获得资源是“借出”，还需要还回去，就好比有20个水桶放在这里，需要拿水的人都可以使用这些木桶从水池里面拿水，如果20个人都拿完水，不将水桶还回原地，那么后面来的人再需要拿水，只能在旁边等待有人将木桶还回去，之前的人用完后需要放回去，不然后面的人就会一直等待，造成资源堵塞，同理，应用程序获取数据库连接的时候Connection连接对象的时候是从“池”中分配一个数据库连接出去，在使用完毕后，归还这个数据库连接，这样才能保持数据库的连接“有借有还”准则。</p>
<p><font color="red">参考资料</font>：<br><a href="http://dev.mysql.com/doc/refman/5.1/zh/connectors.html#cj-connection-pooling" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.1/zh/connectors.html#cj-connection-pooling</a></p>
<h2 id="数据存取"><a href="#数据存取" class="headerlink" title="数据存取"></a>数据存取</h2><p>数据库服务器的优化和数据的存取，什么类型的数据放在什么地方更好是值得去思考的问题，将来的存储很可能是混用的，Cache，NOSQL，DFS，DataBase 在一个系统中都会有，生活的餐具和平日里穿衣服需要摆放在家里，但是不会用同一种类型的家具存放，貌似没有那个人家把餐具和衣服放在同一个柜子里面的。这就像是系统中不同类型的数据一样，对不同类型的数据需要使用合适的存储环境。文件和图片的存储，首先按照访问的热度分类，或者按照文件的大小。强关系类型并且需要事务支持的采用传统的数据库，弱关系型不需要事务支持的可以考虑NOSQL，海量文件存储可以考虑一下支持网络存储的DFS，至于缓存要看你单个数据存储的大小和读写的比例。<br>还有一点值得注意就是数据读写分离，无论在DataBase还是NOSQL的环境中大部分都是读大于写，因此在设计时还需考虑 不仅仅需要让数据的读分散在多台机器上，还需要考虑多台机器之间的数据一致性，MySQL的一主多从，在加上MySQL-Proxy或者借用JDBC中的一些参数(roundRobinLoadBalance、failOverReadOnly、autoReconnectForPools、secondsBeforeRetryMaster)对后续应用程序开发，可以将读和写分离，将大量读的压力分散在多台机器上，并且还保证了数据的一致性。</p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>在宏观上看缓存一般分为2种：本地缓存和分布式缓存</p>
<ol>
<li>本地缓存，对于Java的本地缓存而言就是讲数据放入静态(static)的数据结合中，然后需要用的时候就从静态数据结合中拿出来,对于高并发的环境建议使用 ConcurrentHashMap或者CopyOnWriteArrayList作为本地缓存。缓存的使用更具体点说就是对系统内存的使用，使用多少内存的资源需要有一个适当比例，如果超过适当的使用存储访问，将会适得其反，导致整个系统的运行效率低下。</li>
<li>分布式缓存，一般用于分布式的环境，将每台机器上的缓存进行集中化的存储，并且不仅仅用于缓存的使用范畴，还可以作为分布式系统数据同步/传输的一种手段，一般被使用最多的就是Memcached和Redis。<br>数据存储在不同的介质上读/写得到的效率是不同的，在系统中如何善用缓存，让你的数据更靠近cpu，下面有一张图你需要永远牢记在心里，来自Google的技术大牛Jeff Dean(Ref)的杰作，如图所示：<br><img src="http://www.javabloger.com/wp-content/uploads/2016/02/cache-speed.png" alt=""></li>
</ol>
<h2 id="并发-多线程"><a href="#并发-多线程" class="headerlink" title="并发/多线程"></a>并发/多线程</h2><p>在高并发环境下建议开发者使用JDK中自带的并发包(java.util.concurrent)，在JDK1.5以后使用java.util.concurrent下的工具类可以简化多线程开发，在java.util.concurrent的工具中主要分为以下几个主要部分：<br>1.线程池，线程池的接口(Executor、ExecutorService)与实现类(ThreadPoolExecutor、 ScheduledThreadPoolExecutor），利用jdk自带的线程池框架可以管理任务的排队和安排，并允许受控制的关闭。因为运行一个线程需要消耗系统CPU资源，而创建、结束一个线程也对系统CPU资源有开销，使用线程池不仅仅可以有效的管理多线程的使用，还是可以提高线程的运行效率。<br>2.本地队列，提供了高效的、可伸缩的、线程安全的非阻塞 FIFO 队列。java.util.concurrent 中的五个实现都支持扩展的 BlockingQueue 接口，该接口定义了 put 和 take 的阻塞版本：LinkedBlockingQueue、ArrayBlockingQueue、SynchronousQueue、PriorityBlockingQueue 和 DelayQueue。这些不同的类覆盖了生产者-使用者、消息传递、并行任务执行和相关并发设计的大多数常见使用的上下文。<br>3.同步器，四个类可协助实现常见的专用同步语句。Semaphore 是一个经典的并发工具。CountDownLatch 是一个极其简单但又极其常用的实用工具，用于在保持给定数目的信号、事件或条件前阻塞执行。CyclicBarrier 是一个可重置的多路同步点，在某些并行编程风格中很有用。Exchanger 允许两个线程在 collection 点交换对象，它在多流水线设计中是有用的。<br>4.并发包 Collection，此包还提供了设计用于多线程上下文中的 Collection 实现：ConcurrentHashMap、ConcurrentSkipListMap、ConcurrentSkipListSet、CopyOnWriteArrayList 和 CopyOnWriteArraySet。当期望许多线程访问一个给定 collection 时，ConcurrentHashMap 通常优于同步的 HashMap，ConcurrentSkipListMap 通常优于同步的 TreeMap。当期望的读数和遍历远远大于列表的更新数时，CopyOnWriteArrayList 优于同步的 ArrayList。</p>
<h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><p>关于队列可以分为：本地的队列 和 分布式队列 2类<br>本地队列：一般常见的用于非及时性的数据批量写入，可以将获取的数据缓存在一个数组中等达到一定数量的时候在进行批量的一次写入，可以使用BlockingQueue或者List/Map来实现。<br>相关资料：Sun Java API.<br>分布式队列：一般作为消息中间件，构建分布式环境下子系统与子系统之间通信的桥梁，JEE环境中使用最多的就是Apache的AvtiveMQ和Sun公司的OpenMQ。<br>轻量级的MQ中间件之前也向大家介绍过一些例如：Kestrel和Redis(Ref <a href="http://www.javabloger.com/article/mq-kestrel-redis-for-java.html)，最近又听说LinkedIn的搜索技术团队推出了一个MQ产品-kaukaf(Ref" target="_blank" rel="external">http://www.javabloger.com/article/mq-kestrel-redis-for-java.html)，最近又听说LinkedIn的搜索技术团队推出了一个MQ产品-kaukaf(Ref</a> <a href="http://sna-projects.com/kafka" target="_blank" rel="external">http://sna-projects.com/kafka</a> )，对此保持关注。<br>相关资料：<br>1.ActiveMQ <a href="http://activemq.apache.org/getting-started.html" target="_blank" rel="external">http://activemq.apache.org/getting-started.html</a><br>2.OpenMQ  <a href="http://mq.java.net/about.html" target="_blank" rel="external">http://mq.java.net/about.html</a><br>3.Kafka       <a href="http://sna-projects.com/kafka" target="_blank" rel="external">http://sna-projects.com/kafka</a><br>4.JMS文章  <a href="http://www.javabloger.com/article/category/jms" target="_blank" rel="external">http://www.javabloger.com/article/category/jms</a></p>
<h2 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h2><p>NIO是在JDK1.4后的版本中出现的，在Java 1.4之前，Jdk提供的都是面向流的I/O系统，例如读/写文件则是一次一个字节地处理数据，一个输入流产生一个字节的数据，一个输出流消费一个字节的数据， 面向流的I/O速度非常慢，并且一个数据包要么整个数据报已经收到，要么还没有。Java NIO非堵塞技术实际是采取Reactor模式，有内容进来会自动通知,不必死等、死循环，大大的提升了系统性能。在现实场景中NIO技术多数运用两个方面，1是文件的读写操作，2是网络上数据流的操作。在NIO中有几个核心对象需要掌握：1选择器(Selector)、2通道(Channel)、3缓冲区(Buffer)。<br>我的废话：<br>1.在Java NIO的技术范畴中内存映射文件是一种高效的做法，可以用于缓存中存储的冷/热数据分离，将缓存中的一部分冷数据进行这样的处理，这种做法上比常规的基于流或者基于通道的I/O快的多，通过使文件中的数据出现为内存数组的内容来完成的，将文件中实际读取或者写入的部分才会映射到内存中，并不是将整个文件读到内存中。<br>2.在Mysql的jdbc驱动中也可以使用NIO技术对数据库进行操作来提升系统的性能。</p>
<h2 id="长连接-Servlet3-0"><a href="#长连接-Servlet3-0" class="headerlink" title="长连接/Servlet3.0"></a>长连接/Servlet3.0</h2><p>这里说的长连接就是长轮询，以前浏览器(客户端)需要关注服务器端发生的数据变化需要不断的访问服务器，这样客户端的数量一多必然会给服务器端造成很大的压力，例如：论坛中的站内消息。现在Servlet3.0规范中提供了一个新的特性：异步IO通信；该特性会保持一个长连接。利用Servlet3异步请求的这项技术可以大大的缓解服务器端的压力。<br>Servlet3.0的原理就是将request的请求开启一个线程挂起，中间设置等待超时的时间，如果后台事件触发request请求，得到的结果返回给客户端的request请求，如果在设置等待超时的时间内没有任何事件发生也将请求返回给客户端，客户端将再次发起request请求，客户端与服务器端的交互可以与此往复。<br>就好比，你先过来跟我说如果有人找你，我就立马通知你你来见他，原先你需要不断的问我有没有要找你，而不管有没有人找你，你都需要不断的问我有没有人找你，这样的话不论问的人还是被问的人都会累死。</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>Log4J是通常被人们使用的工具，系统在刚刚上线的时候日志一般都设置在INFO的级，真正上线后一般设置在ERROR级，但无论在任何时候，日志的输入内容都是需要关注的，开发人员一般可以依靠输出的日志查找出现的问题或者依靠输出的日志对系统的性能进行优化，日志也是系统运行状态的报告和排错的依据。<br>简单来说日志按照定义的不同策略和等级输出到不同的环境，那样便于我们分析和管理。相反你没有策略的输出，那么机器一多，时间一长，会有一大推乱糟糟的日志，会让你排错的时候无从下手，所以日志的输出策略是使用日志的关键点。<br>参考资料：<a href="http://logging.apache.org/log4j/1.2/manual.html" target="_blank" rel="external">http://logging.apache.org/log4j/1.2/manual.html</a></p>
<h2 id="打包-部署"><a href="#打包-部署" class="headerlink" title="打包/部署"></a>打包/部署</h2><p>在代码设计的时候最好能将不同类型的功能模块在IDE环境中粗粒度的分为不同的工程，便于打成不同jar包部署在不同的环境中。有这样的一个应用场景：需要每天定时远程从SP那边获得当天100条新闻和部分城市的天气预报，虽然每天的数据量不多，但是前端访问的并发量很大，显然需要在系统架构上做到读写分离。<br>如果把web工程和定时抓取的功能模块完全集中在一个工程里打包，将导致需要扩展的时候每台机器上既有web应用也有定时器，因为功能模块没有分开，每台机器上都有定时器工作将会造成数据库里面的数据重复。<br>如果开发的时候就将web和定时器分为2个工程，打包的时候就可以分开部署，10台web对应一台定期器，分解了前端请求的压力，数据的写入也不会重复。<br>这样做的另一个好处就是可以共用，在上述的场景中web和定时器都需要对数据库进行读取，那么web和定时器的工程里都有操作数据库的代码，在代码的逻辑上还是感觉乱乱的。如果再抽出一个DAL层的jar，web和定时器的应用模块开发者只需要引用DAL层的jar，开发相关的业务逻辑，面向接口编程，无需考虑具体的数据库操作，具体的对数据库操作由其他开发者完成，可以在开发任务分工上很明确，并且互不干涉。</p>
<h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p>所谓流行的SSH(Struts/Spring/Hiberanet)轻量级框架,对于很多中小型项目而言一点都不轻量级，开发者不仅需要维护代码，还需要维护繁琐的xml配置文件，而且说不定某个配置文件写的不对就让整个都工程无法运行。无配置文件可以取代SSH(struts/Spring/Hiberanet)框架的产品真的太多了，我之前就向大家介绍过一些个产品(Ref)。<br>这个我并不是一味的反对使用SSH(Struts/Spring/Hiberanet)框架，在我眼里SSH框架真的作用是做到了规范开发，而并不使用了SSH(Struts/Spring/Hiberanet)框架能提高多少性能。<br>SSH框架只是对于非常大的项目人数上百人的团队，还需要、继续增加团队规模的公司而言，是需要选择一些市面上大家都认可，并且熟悉的技术，SSH(Struts/Spring/Hiberanet)框架比较成熟所以是首先产品。<br>但是对于一些小团队中间有个把技术高人的团队而言完全可以选择更加简洁的框架，真正的做到提速你的开发效率，早日抛弃SSH框架选择更简洁的技术在小团队开发中是一种比较明知的选择。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[浅谈协程]]></title>
      <url>http://Melodylican.github.io/2016/12/25/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%8D%9A%E5%AE%A2%E8%83%8C%E6%99%AF%E5%9B%BE5.jpg" alt=""><br></center><br>最近在研究网络服务框架方面的东西，发现了一个神奇的东西-<strong>协程</strong>。</p>
<p>一句话说明什么是线程：<strong>协程是一种用户态的轻量级线程</strong>。<br><a id="more"></a><br>一句话并不能完全概括协程的全部，但是起码能让我们对协程这个概念有一个基本的印象。</p>
<p>从硬件发展来看，从最初的单核单CPU，到单核多CPU，多核多CPU，似乎已经到了极限了，但是单核CPU性能却还在不断提升。server端也在不断的发展变化。如果将程序分为IO密集型应用和CPU密集型应用，二者的server的发展如下：</p>
<p>IO密集型应用: <strong>多进程-&gt;多线程-&gt;事件驱动-&gt;协程</strong></p>
<p>CPU密集型应用:<strong>多进程–&gt;多线程</strong></p>
<p>如果说多进程对于多CPU，多线程对应多核CPU，那么事件驱动和协程则是在充分挖掘不断提高性能的单核CPU的潜力。</p>
<p>以下的讨论如无特别说明，不考虑cpu密集型应用。</p>
<h2 id="异步-vs-同步"><a href="#异步-vs-同步" class="headerlink" title="异步 vs 同步"></a>异步 vs 同步</h2><p>无论是线程还是进程，使用的都是同步进制，当发生阻塞时，性能会大幅度降低，无法充分利用CPU潜力，浪费硬件资源，更重要造成软件模块的铁板化，紧耦合，无法切割，不利于日后扩展和变化。不管是进程还是线程，每次阻塞、切换都需要陷入系统调用(system call)，先让CPU跑操作系统的调度程序，然后再由调度程序决定该跑哪一个进程(线程)。多个线程之间在一些访问互斥的代码时还需要加上锁，这也是导致多线程编程难的原因之一。</p>
<p>现下流行的异步server都是基于事件驱动的（如nginx）。事件驱动简化了编程模型，很好地解决了多线程难于编程，难于调试的问题。异步事件驱动模型中，把会导致阻塞的操作转化为一个异步操作，主线程负责发起这个异步操作，并处理这个异步操作的结果。由于所有阻塞的操作都转化为异步操作，理论上主线程的大部分时间都是在处理实际的计算任务，少了多线程的调度时间，所以这种模型的性能通常会比较好。</p>
<p>总的说来，当单核cpu性能提升，cpu不在成为性能瓶颈时，采用异步server能够简化编程模型，也能提高IO密集型应用的性能。</p>
<h2 id="协程-vs-线程"><a href="#协程-vs-线程" class="headerlink" title="协程 vs 线程"></a>协程 vs 线程</h2><p>之前说道，协程是一种用户级的轻量级线程。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：</p>
<p>协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置。</p>
<p>在并发编程中，协程与线程类似，每个协程表示一个执行单元，有自己的本地数据，与其它协程共享全局数据和其它资源。目前主流语言基本上都选择了多线程作为并发设施，与线程相关的概念是抢占式多任务（Preemptive multitasking），而与协程相关的是协作式多任务。</p>
<p>不管是进程还是线程，每次阻塞、切换都需要陷入系统调用(system call)，先让CPU跑操作系统的调度程序，然后再由调度程序决定该跑哪一个进程(线程)。</p>
<p>而且由于抢占式调度执行顺序无法确定的特点，使用线程时需要非常小心地处理同步问题，而协程完全不存在这个问题（事件驱动和异步程序也有同样的优点）。</p>
<p>我们在自己在进程里面完成逻辑流调度，碰着i\o我就用非阻塞式的。那么我们即可以利用到异步优势，又可以避免反复系统调用，还有进程切换造成的开销，分分钟给你上几千个逻辑流不费力。这就是协程。</p>
<h2 id="协程-vs-事件驱动"><a href="#协程-vs-事件驱动" class="headerlink" title="协程 vs 事件驱动"></a>协程 vs 事件驱动</h2><p>以nginx为代表的事件驱动的异步server正在横扫天下，那么事件驱动模型会是server端模型的终点吗？</p>
<p>我们可以深入了解下，事件驱动编程的模型。</p>
<p>事件驱动编程的架构是预先设计一个事件循环，这个事件循环程序不断地检查目前要处理的信息，根据要处理的信息运行一个触发函数。其中这个外部信息可能来自一个目录夹中的文件，可能来自键盘或鼠标的动作，或者是一个时间事件。这个触发函数，可以是系统默认的也可以是用户注册的回调函数。</p>
<p>事件驱动程序设计着重于弹性以及异步化上面。许多GUI框架（如windows的MFC，Android的GUI框架），Zookeeper的Watcher等都使用了事件驱动机制。未来还会有其他的基于事件驱动的作品出现。</p>
<p>基于事件驱动的编程是单线程思维，其特点是异步+回调。</p>
<p>协程也是单线程，但是它能让原来要使用异步+回调方式写的非人类代码,可以用看似同步的方式写出来。它是实现推拉互动的所谓非抢占式协作的关键。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>协程的好处：</p>
<p>跨平台</p>
<ul>
<li>跨体系架构</li>
<li>无需线程上下文切换的开销</li>
<li>无需原子操作锁定及同步的开销</li>
<li>方便切换控制流，简化编程模型</li>
<li>高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。</li>
</ul>
<p>缺点：</p>
<ul>
<li>无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。</li>
<li>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序：这一点和事件驱动一样，可以使用异步IO操作来解决</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 协程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Integer缓存策略]]></title>
      <url>http://Melodylican.github.io/2016/12/12/Integer%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5/</url>
      <content type="html"><![CDATA[<p>这篇文章其实是讲Java和Python的，其他的语言并不知道。</p>
<p>在Java里你可能会遇到这样一个问题：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaIntegerCache</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String... strings)</span> </span>&#123;</div><div class="line">        Integer integer1 = <span class="number">3</span>;</div><div class="line">        Integer integer2 = <span class="number">3</span>;</div><div class="line">        <span class="keyword">if</span> (integer1 == integer2)</div><div class="line">            System.out.println(<span class="string">"integer1 == integer2"</span>);</div><div class="line">        <span class="keyword">else</span></div><div class="line">            System.out.println(<span class="string">"integer1 != integer2"</span>);</div><div class="line">        Integer integer3 = <span class="number">300</span>;</div><div class="line">        Integer integer4 = <span class="number">300</span>;</div><div class="line">        <span class="keyword">if</span> (integer3 == integer4)</div><div class="line">            System.out.println(<span class="string">"integer3 == integer4"</span>);</div><div class="line">        <span class="keyword">else</span></div><div class="line">            System.out.println(<span class="string">"integer3 != integer4"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>那么问题来了，答案是什么，首先，我们应该比较的是地址，这是引用类型，那么应该两个都不等吗？<br><a id="more"></a><br>运行结果是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">integer1 == integer2</div><div class="line">integer3 != integer4</div></pre></td></tr></table></figure></p>
<p>似乎是个神奇的结论，但是是为什么？</p>
<p>其实是源于一种缓存策略，这种策略会把小数缓存到内存地址里，提高性能和节省内存，实现小数的重用。</p>
<p>当然，这是缓存在Java中仅适用于自动装箱。</p>
<p>接下来我们来看看Java是怎么实现缓存的：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">     * Cache to support the object identity semantics of autoboxing for values between</div><div class="line">     * -128 and 127 (inclusive) as required by JLS.</div><div class="line">     *</div><div class="line">     * The cache is initialized on first usage.  The size of the cache</div><div class="line">     * may be controlled by the &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;<span class="doctag">@code</span>&lt;/a&gt; -XX:AutoBoxCacheMax=&#125; option.</div><div class="line">     * During VM initialization, java.lang.Integer.IntegerCache.high property</div><div class="line">     * may be set and saved in the private system properties in the</div><div class="line">     * sun.misc.VM class.</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntegerCache</span> </span>&#123;</div><div class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> low = -<span class="number">128</span>;</div><div class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> high;</div><div class="line">        <span class="keyword">static</span> <span class="keyword">final</span> Integer cache[];</div><div class="line">        <span class="keyword">static</span> &#123;</div><div class="line">            <span class="comment">// high value may be configured by property</span></div><div class="line">            <span class="keyword">int</span> h = <span class="number">127</span>;</div><div class="line">            String integerCacheHighPropValue =</div><div class="line">                sun.misc.VM.getSavedProperty(<span class="string">"java.lang.Integer.IntegerCache.high"</span>);</div><div class="line">            <span class="keyword">if</span> (integerCacheHighPropValue != <span class="keyword">null</span>) &#123;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    <span class="keyword">int</span> i = parseInt(integerCacheHighPropValue);</div><div class="line">                    i = Math.max(i, <span class="number">127</span>);</div><div class="line">                    <span class="comment">// Maximum array size is Integer.MAX_VALUE</span></div><div class="line">                    h = Math.min(i, Integer.MAX_VALUE - (-low) -<span class="number">1</span>);</div><div class="line">                &#125; <span class="keyword">catch</span>( NumberFormatException nfe) &#123;</div><div class="line">                    <span class="comment">// If the property cannot be parsed into an int, ignore it.</span></div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            high = h;</div><div class="line">            cache = <span class="keyword">new</span> Integer[(high - low) + <span class="number">1</span>];</div><div class="line">            <span class="keyword">int</span> j = low;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>; k &amp;amp;lt; cache.length; k++)</div><div class="line">                cache[k] = <span class="keyword">new</span> Integer(j++);</div><div class="line">            <span class="comment">// range [-128, 127] must be interned (JLS7 5.1.7)</span></div><div class="line">            <span class="keyword">assert</span> IntegerCache.high &amp;amp;gt;= <span class="number">127</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="title">IntegerCache</span><span class="params">()</span> </span>&#123;&#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p>实际上，这一范围可以调整JVM启动参数调整，默认是-128-127，通过Integer类第一次被使用来初始化，实现就是一个简单的for循环。</p>
<p>详细阅读：<a href="http://www.codeceo.com/article/java-integer-cache.html" target="_blank" rel="external">理解Java Integer的缓存策略</a></p>
<p>看上去还是很简单的，其实Python中也有类似的策略：</p>
<p>尝试一下代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>x=<span class="number">256</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x <span class="keyword">is</span> <span class="number">256</span></div><div class="line"><span class="keyword">True</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x=<span class="number">1024</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>x <span class="keyword">is</span> <span class="number">1024</span></div><div class="line"><span class="keyword">False</span></div></pre></td></tr></table></figure></p>
<p>is以及id()都是用于比较地址二不是值得，这样比较好明确。</p>
<p>实际上同样的跟Java一样，在解释器运行时也会进行初始化缓存缓存一些数字（当然平时写程序我们应该不会关注到这一点）。</p>
<p>Python的详细解释：</p>
<p><a href="http://stackoverflow.com/questions/4293408/ids-of-immutable-types" target="_blank" rel="external">http://stackoverflow.com/questions/4293408/ids-of-immutable-types</a><br>之后我还试了试JavaScript，很遗憾并没有这个特性。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[快学Scala-第二章 Scala基础]]></title>
      <url>http://Melodylican.github.io/2016/12/04/%E5%BF%AB%E5%AD%A6Scala_Scala%E5%9F%BA%E7%A1%80%E7%AC%AC%E4%B8%89%E8%8A%82_Range/</url>
      <content type="html"><![CDATA[<h1 id="第三节-Range"><a href="#第三节-Range" class="headerlink" title="第三节 Range"></a>第三节 Range</h1><p>在执行for循环时，我们经常会用到数值序列，比如，i的值从1循环到5，这时就可以采用Range来实现。Range可以支持创建不同数据类型的数值序列，包括Int、Long、Float、Double、Char、BigInt和BigDecimal等。</p>
<p>在创建Range时，需要给出区间的起点和终点以及步长（默认步长为1）。下面通过几个实例来介绍：<br>（1）创建一个从1到5的数值序列，包含区间终点5，步长为1<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">1</span> to <span class="number">5</span></div><div class="line">res0: scala.collection.immutable.<span class="type">Range</span>.<span class="type">Inclusive</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</div></pre></td></tr></table></figure></p>
<p>之前我们已经介绍过，在Scala中允许对“字面量”直接执行方法，所以，上面的代码，也可以用下面的代码来实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">1.</span>to(<span class="number">5</span>)</div><div class="line">res0: scala.collection.immutable.<span class="type">Range</span>.<span class="type">Inclusive</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</div></pre></td></tr></table></figure></p>
<p>（2）创建一个从1到5的数值序列，不包含区间终点5，步长为1<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">1</span> until <span class="number">5</span></div><div class="line">res1: scala.collection.immutable.<span class="type">Range</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</div></pre></td></tr></table></figure></p>
<p>（3）创建一个从1到10的数值序列，包含区间终点10，步长为2<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">1</span> to <span class="number">10</span> by <span class="number">2</span></div><div class="line">res2: scala.collection.immutable.<span class="type">Range</span> = <span class="type">Range</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>)</div></pre></td></tr></table></figure></p>
<p>（4）创建一个Float类型的数值序列，从0.5f到5.9f，步长为0.3f<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">0.5</span>f to <span class="number">5.9</span>f by <span class="number">0.8</span>f</div><div class="line">res3: scala.collection.immutable.<span class="type">NumericRange</span>[<span class="type">Float</span>] = <span class="type">NumericRange</span>(<span class="number">0.5</span>, <span class="number">1.3</span>, <span class="number">2.1</span>, <span class="number">2.8999999</span>, <span class="number">3.6999998</span>, <span class="number">4.5</span>, <span class="number">5.3</span>)</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[快学Scala-第二章 Scala基础]]></title>
      <url>http://Melodylican.github.io/2016/12/03/%E5%BF%AB%E5%AD%A6Scala_Scala%E5%9F%BA%E7%A1%80%E7%AC%AC%E4%BA%8C%E8%8A%82/</url>
      <content type="html"><![CDATA[<h1 id="第二节-基本数据类型和操作"><a href="#第二节-基本数据类型和操作" class="headerlink" title="第二节 基本数据类型和操作"></a>第二节 基本数据类型和操作</h1><blockquote>
<p>基本数据类型</p>
</blockquote>
<p>Scala的数据类型包括：Byte、Char、Short、Int、Long、Float、Double和Boolean。和Java不同的是，在Scala中，这些类型都是“类”，并且都是包scala的成员，比如，Int的全名是scala.Int。对于字符串，Scala用java.lang.String类来表示字符串。<br><a id="more"></a><br>这里要明确什么是“字面量”？字面量包括整数字面量、浮点数字面量、布尔型字面量、字符字面量、字符串字面量、符号字面量、函数字面量和元组字面量。举例如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> i = <span class="number">123</span>  <span class="comment">//123就是整数字面量</span></div><div class="line"><span class="keyword">val</span> i = <span class="number">3.14</span> <span class="comment">//3.14就是浮点数字面量</span></div><div class="line"><span class="keyword">val</span> i = <span class="literal">true</span> <span class="comment">//true就是布尔型字面量</span></div><div class="line"><span class="keyword">val</span> i = '<span class="type">A</span>' <span class="comment">//'A'就是字符字面量</span></div><div class="line"><span class="keyword">val</span> i = <span class="string">"Hello"</span> <span class="comment">//"Hello"就是字符串字面量</span></div></pre></td></tr></table></figure></p>
<p>Scala允许对“字面量”直接执行方法，比如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">5.</span>toString() <span class="comment">//产生字符串"5"</span></div><div class="line"><span class="string">"abc"</span>.intersect(<span class="string">"bcd"</span>)  <span class="comment">//输出"bc"</span></div></pre></td></tr></table></figure></p>
<p>上面的intersect()方法用来输出两个字符串中都存在的字符。</p>
<blockquote>
<p>操作符</p>
</blockquote>
<p>在Scala中，可以使用加(+)、减(-) 、乘(*) 、除(/) 、余数（%）等操作符，而且，这些操作符就是方法。例如，5 + 3和(5).+(3)是等价的，也就是说：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">a 方法 b</div><div class="line">a.方法(b)</div></pre></td></tr></table></figure></p>
<p>上面这二者是等价的。前者是后者的简写形式，这里的+是方法名，是Int类中的一个方法。具体代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> sum1 = <span class="number">5</span> + <span class="number">3</span> <span class="comment">//实际上调用了 (5).+(3)</span></div><div class="line">sum1: <span class="type">Int</span> = <span class="number">8</span></div><div class="line">scala&gt; <span class="keyword">val</span> sum2 = (<span class="number">5</span>).+(<span class="number">3</span>) <span class="comment">//可以发现，写成方法调用的形式，和上面得到相同的结果</span></div><div class="line">sum2: <span class="type">Int</span> = <span class="number">8</span></div></pre></td></tr></table></figure></p>
<p>需要注意的是，和Java不同，在Scala中并没有提供++和–操作符，当需要递增和递减时，可以采用如下方式表达：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">var</span> i = <span class="number">5</span>;</div><div class="line">i: <span class="type">Int</span> = <span class="number">5</span></div><div class="line">scala&gt; i += <span class="number">1</span>  <span class="comment">//将i递增</span></div><div class="line">scala&gt; println(i)</div><div class="line"><span class="number">6</span></div></pre></td></tr></table></figure></p>
<p>此外，也可以使用关系和逻辑操作，比如，大于(&gt;)、小于(&lt;)、大于等于(&gt;=)和小于等于(&lt;=)，会产生Boolean类型的结果。</p>
<font color="grey">注：此博客参考自 厦门大学林子雨博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[快学Scala-第二章 Scala基础]]></title>
      <url>http://Melodylican.github.io/2016/12/02/%E5%BF%AB%E5%AD%A6Scala_Scala%E5%9F%BA%E7%A1%80%E7%AC%AC%E4%B8%80%E8%8A%82/</url>
      <content type="html"><![CDATA[<h1 id="第一节-声明值和变量"><a href="#第一节-声明值和变量" class="headerlink" title="第一节 声明值和变量"></a>第一节 声明值和变量</h1><p>Scala有两种类型的变量，一种是val，是不可变的，在声明时就必须被初始化，而且初始化以后就不能再赋值；另一种是var，是可变的，声明的时候需要进行初始化，初始化以后还可以再次对其赋值。<br><a id="more"></a></p>
<blockquote>
<p>val变量</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> myStr = <span class="string">"Hello World!"</span></div><div class="line">myStr: <span class="type">String</span> = <span class="type">Hello</span> <span class="type">World</span>!</div></pre></td></tr></table></figure>
<p>上面第1行代码是我们输入的代码，敲入回车后，Scala解释器会解析我们输入的代码，然后返回执行结果，第2行就是Scala解释器执行后返回的结果，从中我们可以看到，myStr变量的类型是String类型，变量的值是Hello World! 这里需要注意的是，尽管我们在第1行代码的声明中，没有给出myStr是String类型，但是，Scala具有“类型推断”能力，可以自动推断出变量的类型。</p>
<p>当然，我们也可以显式声明变量的类型：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> myStr2 : <span class="type">String</span> = <span class="string">"Hello World!"</span></div><div class="line">myStr2: <span class="type">String</span> = <span class="type">Hello</span> <span class="type">World</span>!</div></pre></td></tr></table></figure></p>
<p>需要说明的是，上面的String类型全称是java.lang.String，也就是说，Scala的字符串是由Java的String类来实现的，因此，我们也可以使用java.lang.String来声明，具体如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> myStr3 : java.lang.<span class="type">String</span> = <span class="string">"Hello World!"</span></div><div class="line">myStr3: <span class="type">String</span> = <span class="type">Hello</span> <span class="type">World</span>!</div></pre></td></tr></table></figure></p>
<p>但是，为什么可以不用java.lang.String，而只需要使用String就可以声明变量呢？这是因为，在每个应用程序中，Scala都会自动添加一些引用，这样，就相当于在每个程序源文件的顶端都增加了一行下面的代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.lang._ <span class="comment">//java.lang包里面所有的东西</span></div></pre></td></tr></table></figure></p>
<p>上面已经声明了一个String类型的不可变的变量，下面我们可以使用该变量，比如要打印出来：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; println(myStr)</div><div class="line"><span class="type">Hello</span> <span class="type">World</span>!</div></pre></td></tr></table></figure></p>
<p>上面的第1行代码是我们在scala命令提示符后面输入的代码，第2行是执行结果。</p>
<p>因为myStr是val变量，因此，一旦初始化以后，就不能再次赋值，所以，下面我们执行的再次赋值操作会报错：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">scala&gt; myStr = <span class="string">"Hello Scala!"</span></div><div class="line">&lt;console&gt;:<span class="number">27</span>: error: reassignment to <span class="keyword">val</span></div><div class="line">          myStr = <span class="string">"Hello Scala!"</span></div><div class="line">                          ^</div></pre></td></tr></table></figure></p>
<blockquote>
<p>var变量</p>
</blockquote>
<p>如果一些变量，需要在初始化以后还要不断修改它的值（比如商品价格），则需要声明为var变量。<br>下面我们把myPrice声明为var变量，并且在声明的时候需要进行初始化：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">var</span> myPrice : <span class="type">Double</span> = <span class="number">9.9</span></div><div class="line">myPrice: <span class="type">Double</span> = <span class="number">9.9</span></div></pre></td></tr></table></figure></p>
<p>然后，我们可以再次对myPrice进行赋值：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; myPrice = <span class="number">10.6</span></div><div class="line">myPrice: <span class="type">Double</span> = <span class="number">10.6</span></div></pre></td></tr></table></figure></p>
<blockquote>
<p>小技巧：如何在Scala解释器中输入多行代码</p>
</blockquote>
<p>在Scala解释器中，当在命令提示符后面输入一个表达式并且按回车以后，代码就会被执行并显示出结果，比如下面我们输入一行表达式并回车：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="number">2</span>*<span class="number">9</span>+<span class="number">4</span></div><div class="line">res1: <span class="type">Int</span> = <span class="number">22</span></div></pre></td></tr></table></figure></p>
<p>这是输入单行代码的情形，但是，有时候，我们需要在命令提示符后面输入多行代码，这该如何实现呢？怎么才能让Scala解释器意识到你要输入多行代码呢？<br>在Java中，每个语句都是以英文的分号结束，但是，在Scala中，可以不用分号。当然，如果你想把多条语句全部写在一行上面，这时还是需要使用分号来隔开各个语句的。<br>通常而言，只要Scala解释器推断出你的代码还没有结束，应该延续到下一行，解释器就会在下一行显示一个竖线“|”，你可以继续输入剩余的代码，比如，我们要输入表达式val myStr4 = “Hello World!”，我们只在命令提示符后面输入“val myStr4 = ”然后就回车，显然，这个表达式还没有结束，所以，解释器会在下一行显示一个竖线“|”，你可以在第2行继续输入”Hello World!”然后回车，解释器就会得到执行结果，具体如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> myStr4 =</div><div class="line">       | <span class="string">"Hello World!"</span></div><div class="line">myStr4: <span class="type">String</span> = <span class="type">Hello</span> <span class="type">World</span>!</div></pre></td></tr></table></figure></p>
<p>此外，如果我们在命令提示符后面输入“val myStr5 = ”然后就回车，解释器会在下一行显示一个竖线“|”，这时如果我们发现变量名称错误，想放弃本次输入，就可以在“|”后面连续敲入两个回车，结束本次输入，具体如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> myStr5 =</div><div class="line">       |</div><div class="line">       |</div><div class="line"><span class="type">You</span> typed two blank lines. <span class="type">Starting</span> a <span class="keyword">new</span> command.</div><div class="line">scala&gt;</div></pre></td></tr></table></figure></p>
<font color="grey">注：此博客参考自 厦门大学林子雨博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[快学Scala-第一章 Scala简介]]></title>
      <url>http://Melodylican.github.io/2016/12/01/%E5%BF%AB%E5%AD%A6Scala_Scala%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<p>Scala是一门现代的多范式编程语言，平滑地集成了面向对象和函数式语言的特性，旨在以简练、优雅的方式来表达常用编程模式。Scala的设计吸收借鉴了许多种编程语言的思想，只有很少量特点是Scala自己独有的。Scala语言的名称来自于“可伸展的语言”，从写个小脚本到建立个大系统的编程任务均可胜任。Scala运行于Java平台（JVM，Java 虚拟机）上，并兼容现有的Java程序，Scala代码可以调用Java方法，访问Java字段，继承Java类和实现Java接口。在面向对象方面，Scala是一门非常纯粹的面向对象编程语言，也就是说，在Scala中，每个值都是对象，每个操作都是方法调用。<br><a id="more"></a><br>Spark的设计目的之一就是使程序编写更快更容易，这也是Spark选择Scala的原因所在。总体而言，Scala具有以下突出的优点：</p>
<ul>
<li>Scala具备强大的并发性，支持函数式编程，可以更好地支持分布式系统；</li>
<li>Scala语法简洁，能提供优雅的API；</li>
<li>Scala兼容Java，运行速度快，且能融合到Hadoop生态圈中。</li>
</ul>
<p>实际上，AMP实验室的大部分核心产品都是使用Scala开发的。Scala近年来也吸引了不少开发者的眼球，例如，知名社交网站Twitter已将代码从Ruby转到了Scala。<br>Scala是Spark的主要编程语言，但Spark还支持Java、Python、R作为编程语言，因此，若仅仅是编写Spark程序，并非一定要用Scala。Scala的优势是提供了REPL（Read-Eval-Print Loop，交互式解释器），因此，在Spark Shell中可进行交互式编程（即表达式计算完成就会输出结果，而不必等到整个程序运行完毕，因此可即时查看中间结果，并对程序进行修改），这样可以在很大程度上提升开发效率。现在的计算机都是多核CPU，想充分利用其多核处理，需要写可并行计算的代码。而函数式编程在并行操作性有着天生的优势，函数式编程没有可变变量，就不会有内存共享的问题。</p>
<font color="grey">注：此博客参考自 厦门大学林子雨博客 仅供博主自身复习用</font>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Scala </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[IT牛人博客收集]]></title>
      <url>http://Melodylican.github.io/2016/10/10/IT%E7%89%9B%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h2 id="IT牛人博客"><a href="#IT牛人博客" class="headerlink" title="IT牛人博客"></a>IT牛人博客</h2><h3 id="大数据必学博客"><a href="#大数据必学博客" class="headerlink" title="大数据必学博客"></a>大数据必学博客</h3><p>• <a href="http://dblab.xmu.edu.cn/post/bigdata-online-course/#lesson2" target="_blank" rel="external">厦门大学林子雨</a>简单易懂</p>
<h3 id="团队技术博客"><a href="#团队技术博客" class="headerlink" title="团队技术博客"></a>团队技术博客</h3><p>• <font color="#D2691E"><a href="http://blog.csdn.net/soso_blog/" target="_blank" rel="external">腾讯SOSO</a></font>团队博客<br>• <a href="http://cdc.tencent.com/" target="_blank" rel="external">腾讯CDC</a>为用户创造优质在线生活体验<br><a id="more"></a></p>
<h3 id="底层架构博客"><a href="#底层架构博客" class="headerlink" title="底层架构博客"></a>底层架构博客</h3><p>•<a href="http://blog.sina.com.cn/kdeng" target="_blank" rel="external">邓侃</a>移动互联网围观者，起哄者<br>•<a href="http://blog.sina.com.cn/iyangjian" target="_blank" rel="external">杨建</a>新浪架构师<br>•<a href="http://www.54chen.com/" target="_blank" rel="external">陈臻</a>米聊开发经理，54chen<br>•<a href="http://blog.sina.com.cn/kern0612" target="_blank" rel="external">阳振坤</a>专注云计算和海量数据库<br>•<a href="http://coolshell.cn/" target="_blank" rel="external">陈皓</a>酷壳博主<br>•<a href="http://blog.yufeng.info/" target="_blank" rel="external">余锋</a>Erlang系统深度探索和应用<br>•<a href="http://www.pagefault.info/" target="_blank" rel="external">刘炜</a>他就是淘宝雕梁<br>•<a href="http://www.cnblogs.com/foxmailed/" target="_blank" rel="external">吴镝</a>专注基础架构，分布式系统<br>•<a href="http://zyan.cc/index.php" target="_blank" rel="external">张宴</a>Nginx大神<br>•<a href="http://blog.lifeibo.com/" target="_blank" rel="external">李飞勃</a>非主流程序员，呵呵<br>•<a href="http://www.yankay.com/" target="_blank" rel="external">颜开</a>在EMC<br>•<a href="http://dinglin.iteye.com/" target="_blank" rel="external">林晓斌</a>他就是淘宝丁奇<br>•<a href="http://rednaxelafx.iteye.com/" target="_blank" rel="external">RednaxelaFX</a>曾经的淘撒迦<br>•<a href="https://martinfowler.com/" target="_blank" rel="external">Martin FowlerOO</a>，CI泰山北斗<br>•<a href="https://timyang.net/" target="_blank" rel="external">TimYang</a>新浪微博滴牛X人<br>•<a href="http://blog.csdn.net/cenwenchu79/" target="_blank" rel="external">放翁 文初</a>淘宝开放平台技术产品负责人<br>•<a href="http://mqzhuang.iteye.com/" target="_blank" rel="external">淘宝华庭</a>Glibc内存管理<br>•<a href="http://wangyuanzju.blog.163.com/" target="_blank" rel="external">网易汪源</a>网易杭州研究院副总监<br>•<a href="http://blog.sina.com.cn/firegl" target="_blank" rel="external">黄亮</a>关注企业存储、服务器相关<br>•<a href="http://blog.fulin.org/" target="_blank" rel="external">唐福林</a>新浪微博开放平台架构师<br>•<a href="http://sunli.cnblogs.com/" target="_blank" rel="external">孙立</a>去哪儿网架构师<br>•<a href="https://yemaosheng.com/" target="_blank" rel="external">叶茂盛</a>专注系统管理<br>•<a href="http://blog.csdn.net/heiyeshuwu" target="_blank" rel="external">黑夜路人</a>百度码农，很多有用博文<br>•<a href="http://dbanotes.net/" target="_blank" rel="external">冯大辉</a>UNIX，DB，WEB<br>•<a href="http://www.parallellabs.com/" target="_blank" rel="external">陈冠诚</a>关注并行计算</p>
<h3 id="数据存储相关博客"><a href="#数据存储相关博客" class="headerlink" title="数据存储相关博客"></a>数据存储相关博客</h3><p>•<a href="http://www.orczhou.com/" target="_blank" rel="external">周振兴</a>专注MySQL<br>•<a href="http://blog.itpub.net/7318139/" target="_blank" rel="external">朱龙春</a>资深应用系统架构师<br>•<a href="http://www.eygle.com/blog/" target="_blank" rel="external">盖国强</a>Oracle ACE总监<br>•<a href="http://www.laoxiong.net/" target="_blank" rel="external">老熊</a>Oracle/UNIX/数据恢复</p>
<h3 id="语言开发"><a href="#语言开发" class="headerlink" title="语言开发"></a>语言开发</h3><p>•<a href="http://www.laruence.com/" target="_blank" rel="external">惠新宸</a>他就是鸟哥<br>•<a href="https://blog.yanbin.org/" target="_blank" rel="external">闫斌</a>PHP高手<br>•<a href="http://www.javabloger.com/" target="_blank" rel="external">黄毅</a>Java传教士<br>•<a href="http://www.cnblogs.com/jobs/" target="_blank" rel="external">温少</a>做Java和.NET<br>•<a href="http://blog.csdn.net/Solstice" target="_blank" rel="external">陈硕</a>muduo网络库作者<br>•<a href="http://www.cnblogs.com/shanyou" target="_blank" rel="external">张善友</a>多年的微软MVP<br>•<a href="http://mindhacks.cn/" target="_blank" rel="external">刘未鹏</a>C++罗浮宫</p>
<h3 id="前端开发"><a href="#前端开发" class="headerlink" title="前端开发"></a>前端开发</h3><p>•<a href="https://www.qianduan.net/" target="_blank" rel="external">前端</a>观察资讯，资源，技术<br>•<a href="http://blog.cssforest.org/" target="_blank" rel="external">CSS森林</a>腾讯滴，不知道离职了没</p>
<h3 id="其他博客"><a href="#其他博客" class="headerlink" title="其他博客"></a>其他博客</h3><p>•<a href="http://www.paulgraham.com/articles.html" target="_blank" rel="external">EssaysPaul</a> Graham文集<br>•<a href="http://www.williamlong.info/" target="_blank" rel="external">月光博客</a>关注互联网与搜索引擎<br>•<a href="http://www.jianshu.com/u/c22ccc510fb9" target="_blank" rel="external">纯银</a>网易产品总监<br>•<a href="http://iamsujie.com/" target="_blank" rel="external">人人都是产品经理</a>专注PM的知名博客<br>•<a href="http://ucdchina.com/baiya/" target="_blank" rel="external">白鸦</a>UCDChina发起人<br>•<a href="http://www.cnblogs.com/zhoujg/" target="_blank" rel="external">周金根</a>敏捷个人创立和推广者<br>•<a href="http://www.matrix67.com/blog/" target="_blank" rel="external">matrix67</a>神牛，不解释<br>•<a href="http://blog.chinaunix.net/uid/12924167.html" target="_blank" rel="external">余洪春</a>构建高可用Linux服务器作者<br>•<a href="http://blog.csdn.net/david_lv" target="_blank" rel="external">阿朱</a>《走出软件作坊》作者<br>•<a href="https://blog.youxu.info/" target="_blank" rel="external">徐宥</a>Google的软件工程师<br>•<a href="http://blog.vgod.tw/" target="_blank" rel="external">vgod</a>MIT的博士<br>•<a href="http://zhiqiang.org/blog/" target="_blank" rel="external">阅微堂</a>数学、金融、计算机</p>
<h3 id="其他博客-1"><a href="#其他博客-1" class="headerlink" title="其他博客"></a>其他博客</h3><p>•<a href="https://zhuanlan.zhihu.com/p/28133818" target="_blank" rel="external">java8新特性</a></p>
<h3 id="持续收集中-敬请关注"><a href="#持续收集中-敬请关注" class="headerlink" title="持续收集中 敬请关注"></a>持续收集中 敬请关注</h3>]]></content>
      
        <categories>
            
            <category> IT牛人博客 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> IT牛人博客 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习理论基础（二）]]></title>
      <url>http://Melodylican.github.io/2016/10/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%802/</url>
      <content type="html"><![CDATA[<h3 id="数据分析与机器学习的区别："><a href="#数据分析与机器学习的区别：" class="headerlink" title="数据分析与机器学习的区别："></a>数据分析与机器学习的区别：</h3><h3 id="1、数据特点："><a href="#1、数据特点：" class="headerlink" title="1、数据特点："></a>1、数据特点：</h3><p>（1）</p>
<ul>
<li>数据分析处理交易数据（和钱有关系的）；</li>
<li>机器学习处理行为数据（搜索历史、点击历史、浏览历史、评论）。<br>（2）数据量</li>
<li>数据分析是少量数据</li>
<li>机器学习是海量数据<a id="more"></a>
（3）分析方法：</li>
<li>数据分析采用采样分析</li>
<li>机器学习采用全量分析<br>NOSQL：非关系型的数据库，只能用来处理行为数据，而不能处理交易数据。如MangoDB。<h3 id="2、解决业务问题不同-："><a href="#2、解决业务问题不同-：" class="headerlink" title="2、解决业务问题不同 ###："></a>2、解决业务问题不同 ###：</h3></li>
<li>数据分析：报告过去的事情</li>
<li>机器学习：预测未来的事情<h3 id="3、技术手段不同："><a href="#3、技术手段不同：" class="headerlink" title="3、技术手段不同："></a>3、技术手段不同：</h3>（1）分析方法：</li>
<li>数据分析：用户驱动&amp;交互式分析&amp;OLAP</li>
<li>机器学习：数据驱动&amp;自动进行知识发现&amp;数据挖掘<br>（2）分析技术：</li>
<li>数据分析：多维、钻取、多层次、多视角观察（透视表）</li>
<li>机器学习：准备数据、引入挖掘工具后就不管了<h3 id="4、参与者不同："><a href="#4、参与者不同：" class="headerlink" title="4、参与者不同："></a>4、参与者不同：</h3>（1）</li>
<li>数据分析：分析师、算法+数据，分析师能力决定结果</li>
<li>机器学习：数据质量决定结果<br>（2）目标用户：</li>
<li>数据分析：公司高层</li>
<li>机器学习：个体用户<h2 id="算法分类一："><a href="#算法分类一：" class="headerlink" title="算法分类一："></a>算法分类一：</h2></li>
<li>有监督学习</li>
<li>无监督学习</li>
<li>半监督学习<h3 id="1、有监督学习："><a href="#1、有监督学习：" class="headerlink" title="1、有监督学习："></a>1、有监督学习：</h3></li>
<li>分类算法：X类&amp;Y类</li>
<li>回归算法：<h3 id="2、无监督学习："><a href="#2、无监督学习：" class="headerlink" title="2、无监督学习："></a>2、无监督学习：</h3></li>
<li>聚类<h3 id="3、半监督学习（强化学习）"><a href="#3、半监督学习（强化学习）" class="headerlink" title="3、半监督学习（强化学习）"></a>3、半监督学习（强化学习）</h3><h2 id="算法分类二："><a href="#算法分类二：" class="headerlink" title="算法分类二："></a>算法分类二：</h2></li>
<li>分类与回归</li>
<li>聚类</li>
<li>标注<br>算法分类三：很重要！！！！</li>
<li>生成模型</li>
<li>判别模型<br>1、生成模型：指能够随机生成观测数据的模型，尤其是在给定某些隐含参数的条件下。<br>在机器学习中，生成模型可以用来直接对数据建模（例如对一个概率密度函数产生的数据建模），或者作为建立条件概率密度函数的中间过程。条件概率分布可以有生成模型根据贝叶斯准测形成。<br>2、判别模型：是一种对为观测数据y与已观测数据x之间关系进行建模的方法。与生成模型不同，判别模型不考虑x与y之间的联合分布。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习理论基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习理论基础（一）]]></title>
      <url>http://Melodylican.github.io/2016/09/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%801/</url>
      <content type="html"><![CDATA[<h3 id="什么是机器学习："><a href="#什么是机器学习：" class="headerlink" title="什么是机器学习："></a>什么是机器学习：</h3><p>1、利用计算机从历史数据中找出规律，并把这些规律用到对未来不确定场景的决策。<br>2、对不确定场景的决策的两种方法：<br>（1）机器学习<br>（2）数据分析：依赖于数据分析师，即人</p>
<h3 id="从数据中寻找规律："><a href="#从数据中寻找规律：" class="headerlink" title="从数据中寻找规律："></a>从数据中寻找规律：</h3><p>1、全部数据<br>2、量化、用模型刻画（拟合）规律<br><a id="more"></a></p>
<h3 id="机器学习发展的原动力："><a href="#机器学习发展的原动力：" class="headerlink" title="机器学习发展的原动力："></a>机器学习发展的原动力：</h3><p>1、从历史数据中找出规律，把这些规律用到对未来自动做出决定。<br>2、用数据替代expert<br>3、经济驱动，数据变现</p>
<h3 id="业务系统发展的历史："><a href="#业务系统发展的历史：" class="headerlink" title="业务系统发展的历史："></a>业务系统发展的历史：</h3><p>1、基于专家经验<br>2、基于统计——分纬度统计<br>3、机器学习——在线学习<br>OLAP（联机分析处理）：数据仓库最主要的；<br>典型应用自然语言处理和图像识别：</p>
<h3 id="1、自然语言处理：情感分析-实体识别"><a href="#1、自然语言处理：情感分析-实体识别" class="headerlink" title="1、自然语言处理：情感分析+实体识别"></a>1、自然语言处理：情感分析+实体识别</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">* 情感分析（SA）：又称为倾向性分析和意见挖掘，对带有感情色彩的主观性文本进行分析、处理、归纳和推理的过程，其中情感分析还可以分为情感极性（倾向）分析，情感程度分析，主客观分析等。</div><div class="line">* 实体识别（NER）：指识别文本中具有特定意义的实体，包括人名、地名、机构名、专有名词等。</div></pre></td></tr></table></figure>
<h3 id="2、图像识别——深度学习"><a href="#2、图像识别——深度学习" class="headerlink" title="2、图像识别——深度学习"></a>2、图像识别——深度学习</h3><p>ctr预估和协同过滤<br><strong>1、互联网广告——ctr预估</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">* ctr：Click-through-rate，点击通过率，是衡量互联网广告效果的一项重要指标。</div></pre></td></tr></table></figure></p>
<p><strong>2、推荐系统——协同过滤</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">* 协同过滤：用于分辨某位特定顾客可能感兴趣的东西，这些结论来源于其他相似顾客对那些产品感兴趣的分析。</div></pre></td></tr></table></figure></p>
<p>朴素贝叶斯和决策树<br>1、垃圾邮件<br>2、信用卡欺诈<br>关联规则：<br>1、购物篮分析：啤酒+尿片</p>
<p>聚类：<br>1、用户经分细准营销</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习理论基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Storm 笔记 fieldsGrouping]]></title>
      <url>http://Melodylican.github.io/2016/06/09/storm_fieldsgrouping/</url>
      <content type="html"><![CDATA[<h2 id="Twitter-Storm-数据流分组策略，fieldsGrouping"><a href="#Twitter-Storm-数据流分组策略，fieldsGrouping" class="headerlink" title="Twitter Storm, 数据流分组策略，fieldsGrouping"></a>Twitter Storm, 数据流分组策略，fieldsGrouping</h2><hr>
<h3 id="Storm-Grouping"><a href="#Storm-Grouping" class="headerlink" title="Storm Grouping"></a>Storm Grouping</h3><p><strong>1.    shuffleGrouping</strong><br>将流分组定义为混排。这种混排分组意味着来自Spout的输入将混排，或随机分发给此Bolt中的任务。shuffle grouping对各个task的tuple分配的比较均匀。<br><strong>2.    fieldsGrouping</strong><br>这种grouping机制保证相同field值的tuple会去同一个task，这对于WordCount来说非常关键，如果同一个单词不去同一个task，那么统计出来的单词次数就不对了。<br><strong>3.    All grouping</strong><br>广播发送， 对于每一个tuple将会复制到每一个bolt中处理。<br><strong>4.    Global grouping</strong><br>Stream中的所有的tuple都会发送给同一个bolt任务处理，所有的tuple将会发送给拥有最小task_id的bolt任务处理。<br><strong>5.    None grouping</strong><br>不关注并行处理负载均衡策略时使用该方式，目前等同于shuffle grouping,另外storm将会把bolt任务和他的上游提供数据的任务安排在同一个线程下。<br><strong>6.    Direct grouping</strong><br>由tuple的发射单元直接决定tuple将发射给那个bolt，一般情况下是由接收tuple的bolt决定接收哪个bolt发射的Tuple。这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的taskid (OutputCollector.emit方法也会返回taskid)</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Storm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce]]></title>
      <url>http://Melodylican.github.io/2016/05/15/MapReduce/</url>
      <content type="html"><![CDATA[<h2 id="MapReduce-工作原理"><a href="#MapReduce-工作原理" class="headerlink" title="MapReduce 工作原理"></a>MapReduce 工作原理</h2><p>一图胜千言：<br><a id="more"></a></p>
<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/mapreduce.png" alt=""><br></center></p>
<h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper:"></a>Mapper:</h3><ol>
<li>Mapper 主要做些信息抽取、过滤等工作</li>
<li>Mapper 数量由输入的 split 数决定，hadoop 会尽量选择靠近数据的节点运行 mapper 任务，因此可以认为 mapper 是 data-local 的</li>
<li>生成的<h2 id="常见算法的-MapReduce-实现"><a href="#常见算法的-MapReduce-实现" class="headerlink" title="常见算法的 MapReduce 实现"></a>常见算法的 MapReduce 实现</h2></li>
</ol>
<h3 id="count-distinct"><a href="#count-distinct" class="headerlink" title="count / distinct"></a>count / distinct</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>其实就是 Hadoop wordcount 的例子：一堆文档，每个文档内一堆单词，统计每个单词出现次数。</p>
<h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><p><strong>Mapper：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">raw data    --&gt;    对每个碰到的单词，输出 &lt;word,1&gt;</div></pre></td></tr></table></figure></p>
<p>Shuffle 后可以保证同一个单词的所有键值对被一个 Reducer 处理</p>
<p><strong>Reducer：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;word,[1,1,1...]&gt;   --(sum)--&gt;    &lt;word,5&gt;</div></pre></td></tr></table></figure></p>
<p><strong>优化</strong></p>
<p>用 combiner 合并 mapper 的输出，减少传输数据量：<br><strong>Mapper：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">raw data </div><div class="line">1. --(mapper)--&gt;    &lt;word1,1&gt; &lt;word1,1&gt; &lt;word2,1&gt; </div><div class="line">2. --(combine)--&gt;   &lt;word1,2&gt; &lt;word2,1&gt;</div></pre></td></tr></table></figure></p>
<p><strong>distinct</strong><br>distinct 就是集合去重，解决思路和 count 问题一样，不过不需要记录单词出现次数，键值对的 value 用 null 就可以了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Mapper:</div><div class="line">raw data    --&gt;    &lt;word,null&gt;</div><div class="line"></div><div class="line">Reducer:</div><div class="line">&lt;word,[null,null...]&gt;   --&gt;    &lt;word,null&gt;</div></pre></td></tr></table></figure></p>
<h3 id="group-by-aggregation"><a href="#group-by-aggregation" class="headerlink" title="group by / aggregation"></a>group by / aggregation</h3><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>实现类似数据库的 group by 及聚合函数的功能</p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>Mapreduce 的 shuffle 过程其实已经帮我们做了 group by 的工作，Reducer 拿到的输入就是 group by 后的结果，对其 value 应用聚合函数即可。</p>
<h2 id="inverted-index"><a href="#inverted-index" class="headerlink" title="inverted index"></a>inverted index</h2><h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h3><p>一堆文档，构造对应的倒排索引。</p>
<h3 id="解决-1"><a href="#解决-1" class="headerlink" title="解决"></a>解决</h3><p>思路和 wordcount 是一样的。</p>
<p><strong>Mapper：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">对一个文档中的每个单词，输出 &lt;word,fileName&gt;</div></pre></td></tr></table></figure></p>
<p>优化：可以用 Combiner 合并 Mapper 的输出。</p>
<p><strong>Reducer</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Rducuer 的输入是 &lt;word,[file1,file2...]&gt;，直接输出就好了</div></pre></td></tr></table></figure></p>
<h2 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h2><h3 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h3><p>一堆文件，每个文件都有若干行，一行是一个数字，数字的范围是确定的，要求对其排序。</p>
<h3 id="解决-2"><a href="#解决-2" class="headerlink" title="解决"></a>解决</h3><p>利用 Reducer 拿到的输入是有序的这一特性，Mapper 和 Recuder 如果都用 identity function，那么每个 Reducer 的输出都是有序的，但 Reducer 之间无法保证有序。</p>
<p>如果用归并排序的思路， 那么最后还需要一个只有一个 Reducer 的 Mapreduce 任务对所有数据做一次 merge，这显然是无法接受的。</p>
<p>真正可行的算法是 桶排序。回顾桶排序的过程，它首先将数据分布范围划分为若干个桶，接着遍历一遍元素并分配到对应的桶中，然后对每个桶做一次排序，因为桶之间是有序的，所以不需要 merge。</p>
<p>在 Mapreduce 中，Partitioner 负责划分桶。举个例子，假设数据分布在 1 到 1w 之间，我们可以将其划分为 10 个桶，同时用 10 个 Reducer 处理每个桶内的数据，这样 Reducer 间就是有序的。为了实现这个效果，可以用一个自定义的Partitioner，将 Mapper 输出划分到上述 10 个桶内即可。</p>
<h2 id="median-第-k-大数"><a href="#median-第-k-大数" class="headerlink" title="median / 第 k 大数"></a>median / 第 k 大数</h2><h3 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h3><p>一堆数字，找中位数或第 k 大数。</p>
<p>工作中遇见过一个类似的问题，场景是：</p>
<blockquote>
<p>有一堆 Nginx 登陆日志，每条 log 都有一个时间点，要求找到一个时间点，使得该时间点之前的日志数占总日志数的 30%。</p>
<h3 id="解决-3"><a href="#解决-3" class="headerlink" title="解决"></a>解决</h3></blockquote>
<p>在小数据量场景下，反复利用快速排序的分割可以在 O(n) 范围内找到第 K 大数。我们可以将这个思路扩展到分布式环境下：</p>
<ol>
<li>用一个 MapReduce 任务统计所有日志的时间范围和日志总数；</li>
<li>随机选一个时间点，用一个新的任务统计该时间点之前和之后的日志数；</li>
<li>如果该时间点不满足要求，则根据 2 的结果找一个新的时间点，重复步骤2。<br>通常这类统计需求不要求非常精确，得到一个差不多的值就可以了。</li>
</ol>
<h2 id="top-k"><a href="#top-k" class="headerlink" title="top k"></a>top k</h2><h3 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h3><p>求一堆数前 k 大的数。</p>
<h3 id="解决-4"><a href="#解决-4" class="headerlink" title="解决"></a>解决</h3><p>其实这个问题和上面的第 k 大数是一样的，可以用上面的思路解决，这里介绍一种 k 比较小时效率更高的算法。</p>
<p>如果数据量很小，求 top k 可以用一个小根堆维护 top k，堆顶为这最大的 k 个数中的最小元素，把所有数据过一遍，最后堆内就是所求值了。这个算法可以很容易地扩展到分布式的环境中：先求出每个 split 的 top k，合并这些元素再求一次 top k 即得结果。</p>
<p><strong>Mapper</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">维护一个小根堆，任务结束后对堆内每个元素输出一个键值对 &lt;&quot;&quot;,num1&gt;, &lt;&quot;&quot;,num2&gt; ...</div></pre></td></tr></table></figure></p>
<p><strong>Reducer</strong>（数量为 1）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">得到的输入为 &lt;&quot;&quot;,[每个 split 的 top k]&gt;，对 value 求一次 top k 就可以了。</div></pre></td></tr></table></figure></p>
<p>该算法的优势在于只要一次 Mapreduce 任务即可，但缺点是只适用于 k 比较小的情况，如果 k 很大：</p>
<ol>
<li>如果 k 大于每个 split 内包含的记录数，算法失效；</li>
<li>Reducer 可能没有足够的内存容纳输入<h3 id="出现次数-top-k-的元素"><a href="#出现次数-top-k-的元素" class="headerlink" title="出现次数 top k 的元素"></a>出现次数 top k 的元素</h3></li>
</ol>
<p>比上面的 top k 问题多了一个步骤，要求出每个元素的出现次数。如果数据量比较小，可以用下面方法：</p>
<ol>
<li><p><strong>bitmap（如果不是数字的话则用 hashmap）+ 堆 / 快排的分割 </strong><br>bitmap / hashmap 用来统计元素的出现次数，堆用来保存当前 top k，只需一次遍历即可。 用快排的分割的话，要先统计出次数再分割，不只一次遍历。</p>
</li>
<li><p>不要求精确的话，可以用 计数版本的 BloomFilter + 堆<br>BloomFilter 只保存了元素的次数，没有保存元素，因此只能边统计边记录 top k，一次遍历。</p>
</li>
</ol>
<p>如果是大数据量就需要先用一个 hadoop 任务来分割，保证同一个元素的记录被分配到同一个 reducer，这样可以求出每个元素的出现次数；以这个任务的输出为输入，用上面提到的 top k 算法求出每个 split 的 top k；最后用一个 reducer 进行 merge，求出 top k 的 top k。</p>
<h2 id="join"><a href="#join" class="headerlink" title="join"></a>join</h2><h3 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h3><p>join！</p>
<h3 id="解决-5"><a href="#解决-5" class="headerlink" title="解决"></a>解决</h3><p>通常有以下两种算法：</p>
<p><strong>Replicated Join (Map Join, Hash Join)</strong></p>
<p>如果 join 的一方数据量较小，可以载入内存，则可以用 Hadoop 的 Distributed Cache 将其分发到每个 Mapper 节点，在 Mapper 端进行 join。较小数据集在 Mapper 端通常被构造成一个 HashMap 以加速查找，因此 Mapper Join 实质上是一种 Hash join。</p>
<p><strong>Repartition Join (Reduce Join, Sort-Merge Join)</strong></p>
<p>如果两个数据集都很大，可在 Reducer 侧做 join：</p>
<p>Mapper 同时处理两个集合的数据，为遇到的每个记录生成一个键值对，key 是 join 的列值，value 除了该记录还需要一个 tag 表明它来自哪个集合:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">raw data    --&gt;    &lt;key,(record,fromA)&gt;, &lt;key,(record,fromB)&gt; ...</div></pre></td></tr></table></figure></p>
<p>Shuffle 后 Reducer 得到一个 key 对应的所有记录，无论是来自集合 A 还是 B。接下来 Reducer 用循环，根据 join 的类型对这些记录做连接即可。</p>
<p>该算法的关键在于 shuffle 阶段的排序，因此本质上是一种 Sort-Merge join。</p>
<p>Reducer 侧 join 是一种通用的 join 算法，但它有以下缺点：</p>
<ol>
<li>Mapper 侧根本不过滤数据，所有数据，即使是那些无法 join 的记录，都会被传输到 Reducer 侧，再由 Reducer 过滤，这样性能很差；</li>
<li>Reducer 侧可能没有足够的内存装下一个 key 对应的所有记录。<h3 id="join-优化"><a href="#join-优化" class="headerlink" title="join 优化"></a>join 优化</h3></li>
</ol>
<p>考虑这样一个场景：有两个数据集，Customer 和 Order，要求对他们进行 join，但仅限于地区在上海的顾客。</p>
<p>有几种可能的优化方式：</p>
<ol>
<li><p><strong>预先过滤一个集合，使用 Replicated Join</strong></p>
<p>利用“地区为上海”这个约束过滤 Customer，如果过滤后的数据集足够小，则可以采用 Replicated Join；</p>
</li>
<li><p>用半连接(semi join)优化 Reduce Join：先过滤集合 A ，再用得到的结果在 Mapper 处过滤集合 B，最后在 Reducer 处 Join</p>
<p>如果过滤后的数据集依然很大，那么只能采用低效率的 Reduce join。优化 Reduce join 的主要策略是 尽量将数据过滤动作放在 Mapper 进行（这也是一个通用准则），在上述例子中， Mapper 在处理某个 Order 时，如果知道其对应的 Customer 不在 Customer 集合中，或者不在上海地区，那么就可以跳过它而不用传输到 Reducer 侧。为了达到这一点，我们可以先对 Customer 过滤（就像1一样），将上海的顾客的<em> ID </em>选出来，这样得到的文件比1得到的文件更小（因为它只有一个 ID），很有可能可以被装入内存。用 Distributed Cache 将该 ID 文件分发到所有 Mapper 节点，Mapper 在处理 Customer 或 Order 的记录时就可以根据这个集合过滤所有非上海的顾客了。</p>
<p>如果过滤得到的 ID 文件依然很大，这时判重利器 BloomFilter 就派上用场了。我们可以建立一个 BloomFilter 表示过滤后的顾客 ID 集合，它的尺寸要远小于原始集合。BloomFilter 存在的误判率也不是问题，它只会把不存在的元素误判为存在，Reducer 处也会进行过滤，可以把误判的元素剔除掉。</p>
</li>
</ol>
<p><strong>基于 Mapreduce 为超大集合建立 BloomFilter 的方法：</strong></p>
<p>每个 Mapper 对自己负责的 split 建立 BloomFilter，用一个 Reducer 接收它们并两两相“或”，即得到整体集合的 BloomFilter。</p>
<p>这利用了 BloomFilter 的性质：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">filter1 | filter2 == 并集</div><div class="line">filter1 &amp; filter2 == 交集</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="http://highlyscalable.wordpress.com/2012/02/01/mapreduce-patterns/" target="_blank" rel="external">Mapreduce patterns</a></li>
<li><a href="http://blog.cloudera.com/wp-content/uploads/2010/01/5-MapReduceAlgorithms.pdf" target="_blank" rel="external">Mapreduce algorithms.pdf</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop执行过程]]></title>
      <url>http://Melodylican.github.io/2016/03/01/Hadoop%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</url>
      <content type="html"><![CDATA[<h1 id="Hadoop执行过程"><a href="#Hadoop执行过程" class="headerlink" title="Hadoop执行过程"></a>Hadoop执行过程</h1><p>根据Hadoop++论文的描述，Hadoop执行过程分为Load、Map、Shuffle、Reduce这四个阶段，可以看成是一个由split、itemize、map、reduce等10个函数或算子组成的DAG。其中每一个函数或算子，都可以提供自定义的实现以此来扩展Hadoop的功能或优化性能。<br><a id="more"></a></p>
<h2 id="1、Load阶段"><a href="#1、Load阶段" class="headerlink" title="1、Load阶段"></a>1、Load阶段</h2><p>输入数据经block函数，按配置的block大小切分成多个block，每个block按配置存储多个复本，Hadoop尽可能保证不同复本存储在不同结点上。</p>
<h2 id="2、Map阶段"><a href="#2、Map阶段" class="headerlink" title="2、Map阶段"></a>2、Map阶段</h2><p>每个mapper子任务读取一个split。每个split包含一个或多个block，是一个逻辑单元。split函数决定怎么划分split。split通过itemize函数分割成记录，框架对每条记录调用map函数。map的输出由mem函数切割成多个spill。spill中的每条记录由sh函数决定输出到哪个reducer，为每个reducer产生一个逻辑分区。每个逻辑分区根据cmp函数排序并根据grp函数分组，再根据combine函数进行预reduce处理后存储到文件。如果一台mapper机上对某个reducer产生了多个上述处理所得的spill文件，则进行合并，合并时同样执行排序、分组和combine流程。</p>
<h2 id="3、Shuffle阶段"><a href="#3、Shuffle阶段" class="headerlink" title="3、Shuffle阶段"></a>3、Shuffle阶段</h2><p>每个mapper产生的spill文件再次经过sh函数分派给每个reducer。每个reducer从每个mapper接收给它的数据，如果能在内存中合并就在内存中合并，否则接收后先存储，等全部完成后再来合并。最终为每个reducer准备好一个待处理的文件。</p>
<h2 id="4、Reduce阶段"><a href="#4、Reduce阶段" class="headerlink" title="4、Reduce阶段"></a>4、Reduce阶段</h2><p>每个reducer的输入文件先同样执行排序、分组和combine流程，然后根据reduce函数得到最终结果。</p>
<p>下面的图显示了一个有4个节点，4个mapper，2个reducer的Map Reduce程序的执行过程。</p>
<center><br><img src="http://img6.ph.126.net/8aoAyk6T4d3rGrB6WGB6ZQ==/2519763991530936746.jpg" alt=""><br></center>]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[如何正确地写出单例模式]]></title>
      <url>http://Melodylican.github.io/2016/02/19/%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%9C%B0%E5%86%99%E5%87%BA%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F.jpg" alt=""><br></center><br>单例模式算是设计模式中最容易理解，也是最容易手写代码的模式了吧。但是其中的坑却不少，所以也常作为面试题来考。本文主要对几种单例写法的整理，并分析其优缺点。很多都是一些老生常谈的问题，但如果你不知道如何创建一个线程安全的单例，不知道什么是双检锁，那这篇文章可能会帮助到你。<br><a id="more"></a></p>
<h2 id="懒汉式，线程不安全"><a href="#懒汉式，线程不安全" class="headerlink" title="懒汉式，线程不安全"></a>懒汉式，线程不安全</h2><p>当被问到要实现一个单例模式时，很多人的第一反应是写出如下的代码，包括教科书上也是这样教我们的。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;</div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">     <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</div><div class="line">         instance = <span class="keyword">new</span> Singleton();</div><div class="line">     &#125;</div><div class="line">     <span class="keyword">return</span> instance;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这段代码简单明了，而且使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例。也就是说在多线程下不能正常工作。</p>
<h2 id="懒汉式，线程安全"><a href="#懒汉式，线程安全" class="headerlink" title="懒汉式，线程安全"></a>懒汉式，线程安全</h2><p>为了解决上面的问题，最简单的方法是将整个 getInstance() 方法设为同步（synchronized）。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</div><div class="line">        instance = <span class="keyword">new</span> Singleton();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> instance;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance() 方法。但是同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。这就引出了双重检验锁。</p>
<h2 id="双重检验锁"><a href="#双重检验锁" class="headerlink" title="双重检验锁"></a>双重检验锁</h2><p>双重检验锁模式（double checked locking pattern），是一种使用同步块加锁的方法。程序员称其为双重检查锁，因为会有两次检查 instance == null，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的 if，如果在同步块内不进行二次检验的话就会生成多个实例了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getSingleton</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;                         <span class="comment">//Single Checked</span></div><div class="line">        <span class="keyword">synchronized</span> (Singleton.class) &#123;</div><div class="line">            <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;                 <span class="comment">//Double Checked</span></div><div class="line">                instance = <span class="keyword">new</span> Singleton();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> instance ;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这段代码看起来很完美，很可惜，它是有问题。主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。</p>
<ol>
<li>给 instance 分配内存</li>
<li>调用 Singleton 的构造函数来初始化成员变量</li>
<li>将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）</li>
</ol>
<p>但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。</p>
<p>我们只需要将 instance 变量声明成 <font color="red">volatile</font> 就可以了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton instance; <span class="comment">//声明成 volatile</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getSingleton</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;                         </div><div class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</div><div class="line">                <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;       </div><div class="line">                    instance = <span class="keyword">new</span> Singleton();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> instance;</div><div class="line">    &#125;</div><div class="line">   </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序）。</p>
<p>但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。</p>
<p>相信你不会喜欢这种复杂又隐含问题的方式，当然我们有更好的实现线程安全的单例模式的办法。</p>
<h2 id="饿汉式-static-final-field"><a href="#饿汉式-static-final-field" class="headerlink" title="饿汉式 static final field"></a>饿汉式 static final field</h2><p>这种方法非常简单，因为单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span></span>&#123;</div><div class="line">    <span class="comment">//类加载时就初始化</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton instance = <span class="keyword">new</span> Singleton();</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span></span>&#123;&#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">return</span> instance;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种写法如果完美的话，就没必要在啰嗦那么多双检锁的问题了。缺点是它不是一种懒加载模式（lazy initialization），单例会在加载类后一开始就被初始化，即使客户端没有调用 getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如 Singleton 实例的创建是依赖参数或者配置文件的，在 getInstance() 之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。</p>
<h2 id="静态内部类-static-nested-class"><a href="#静态内部类-static-nested-class" class="headerlink" title="静态内部类 static nested class"></a>静态内部类 static nested class</h2><p>我比较倾向于使用静态内部类的方法，这种方法也是《Effective Java》上所推荐的。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;  </div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;  </div><div class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();  </div><div class="line">    &#125;  </div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;  </div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;  </div><div class="line">        <span class="keyword">return</span> SingletonHolder.INSTANCE; </div><div class="line">    &#125;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。</p>
<h2 id="枚举-Enum"><a href="#枚举-Enum" class="headerlink" title="枚举 Enum"></a>枚举 Enum</h2><p>用枚举写单例实在太简单了！这也是它最大的优点。下面这段代码就是声明枚举实例的通常做法。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">enum</span> EasySingleton&#123;</div><div class="line">    INSTANCE;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们可以通过EasySingleton.INSTANCE来访问实例，这比调用getInstance()方法简单多了。创建枚举默认就是线程安全的，所以不需要担心double checked locking，而且还能防止反序列化导致重新创建新的对象。但是还是很少看到有人这样写，可能是因为不太熟悉吧。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一般来说，单例模式有五种写法：懒汉、饿汉、双重检验锁、静态内部类、枚举。上述所说都是线程安全的实现，文章开头给出的第一种方法不算正确的写法。</p>
<p>就我个人而言，一般情况下直接使用饿汉式就好了，如果明确要求要懒加载（lazy initialization）会倾向于使用静态内部类，如果涉及到反序列化创建对象时会试着使用枚举的方式来实现单例。</p>
<h2 id="Read-More"><a href="#Read-More" class="headerlink" title="Read More"></a>Read More</h2><p><a href="http://javarevisited.blogspot.sg/2014/05/double-checked-locking-on-singleton-in-java.html" target="_blank" rel="external">Double Checked Locking on Singleton Class in Java</a><br><a href="http://javarevisited.blogspot.sg/2012/07/why-enum-singleton-are-better-in-java.html" target="_blank" rel="external">Why Enum Singleton are better in Java</a><br><a href="http://javarevisited.blogspot.com/2012/12/how-to-create-thread-safe-singleton-in-java-example.html" target="_blank" rel="external">How to create thread safe Singleton in Java</a><br><a href="http://javarevisited.blogspot.com/2011/03/10-interview-questions-on-singleton.html" target="_blank" rel="external">10 Singleton Pattern Interview questions in Java</a></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 设计模式 </tag>
            
            <tag> 单例模式 </tag>
            
            <tag> 双检锁 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Restful设计规范]]></title>
      <url>http://Melodylican.github.io/2016/01/19/Restful%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/</url>
      <content type="html"><![CDATA[<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%8D%9A%E5%AE%A2%E8%83%8C%E6%99%AF%E5%9B%BE1.jpg" alt=""><br></center><br>本文总结了 RESTful API 设计相关的一些原则，只覆盖了常见的场景。有些规则只是针对自己项目而言，并非其他做法都是错误的。<br><a id="more"></a></p>
<h2 id="URI"><a href="#URI" class="headerlink" title="URI"></a>URI</h2><p>URI 表示资源，资源一般对应服务器端领域模型中的实体类。</p>
<h3 id="URI规范"><a href="#URI规范" class="headerlink" title="URI规范"></a>URI规范</h3><ol>
<li>不用大写；</li>
<li>用中杠-不用下杠_；</li>
<li>参数列表要encode；</li>
<li>URI中的名词表示资源集合，使用复数形式。<h3 id="资源集合-vs-单个资源"><a href="#资源集合-vs-单个资源" class="headerlink" title="资源集合 vs 单个资源"></a>资源集合 vs 单个资源</h3></li>
</ol>
<p>URI表示资源的两种方式：资源集合、单个资源。</p>
<p><strong>资源集合</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/zoos //所有动物园</div><div class="line">/zoos/1/animals //id为1的动物园中的所有动物</div></pre></td></tr></table></figure></p>
<p><strong>单个资源</strong>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/zoos/1 //id为1的动物园</div><div class="line">/zoos/1;2;3 //id为1，2，3的动物园</div></pre></td></tr></table></figure></p>
<h3 id="避免层级过深的URI"><a href="#避免层级过深的URI" class="headerlink" title="避免层级过深的URI"></a>避免层级过深的URI</h3><p>/在url中表达层级，用于按实体关联关系进行对象导航，一般根据id导航。</p>
<p>过深的导航容易导致url膨胀，不易维护，如 GET /zoos/1/areas/3/animals/4，尽量使用查询参数代替路径中的实体导航，如GET /animals?zoo=1&amp;area=3；</p>
<h3 id="对Composite资源的访问"><a href="#对Composite资源的访问" class="headerlink" title="对Composite资源的访问"></a>对Composite资源的访问</h3><p>服务器端的组合实体必须在uri中通过父实体的id导航访问。</p>
<blockquote>
<p>组合实体不是first-class的实体，它的生命周期完全依赖父实体，无法独立存在，在实现上通常是对数据库表中某些列的抽象，不直接对应表，也无id。一个常见的例子是 User — Address，Address是对User表中zipCode/country/city三个字段的简单抽象，无法独立于User存在。必须通过User索引到Address：GET /user/1/addresses</p>
</blockquote>
<h2 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h2><h3 id="HTTP方法"><a href="#HTTP方法" class="headerlink" title="HTTP方法"></a>HTTP方法</h3><p>通过标准HTTP方法对资源CRUD：</p>
<p><strong>GET：查询</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">GET /zoos</div><div class="line">GET /zoos/1</div><div class="line">GET /zoos/1/employees</div></pre></td></tr></table></figure></p>
<p>POST：创建单个资源。POST一般向“资源集合”型uri发起<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">POST /animals  //新增动物</div><div class="line">POST /zoos/1/employees //为id为1的动物园雇佣员工</div></pre></td></tr></table></figure></p>
<p>PUT：更新单个资源（全量），客户端提供完整的更新后的资源。与之对应的是 PATCH，PATCH 负责部分更新，客户端提供要更新的那些字段。PUT/PATCH一般向“单个资源”型uri发起<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PUT /animals/1</div><div class="line">PUT /zoos/1</div></pre></td></tr></table></figure></p>
<p>DELETE：删除<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">DELETE /zoos/1/employees/2</div><div class="line">DELETE /zoos/1/employees/2;4;5</div></pre></td></tr></table></figure></p>
<p>DELETE /zoos/1/animals  //删除id为1的动物园内的所有动物<br>HEAD / OPTION 用的不多，就不多解释了。</p>
<h3 id="安全性和幂等性"><a href="#安全性和幂等性" class="headerlink" title="安全性和幂等性"></a>安全性和幂等性</h3><ol>
<li>安全性：不会改变资源状态，可以理解为只读的；</li>
<li>幂等性：执行1次和执行N次，对资源状态改变的效果是等价的。<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">.	  安全性	  幂等性</div><div class="line">GET	     √	   √</div><div class="line">POST      ×	   ×</div><div class="line">PUT	     ×	   √</div><div class="line">DELETE    ×	   √</div></pre></td></tr></table></figure>
</li>
</ol>
<p>安全性和幂等性均不保证反复请求能拿到相同的response。以 DELETE 为例，第一次DELETE返回200表示删除成功，第二次返回404提示资源不存在，这是允许的。</p>
<h3 id="复杂查询"><a href="#复杂查询" class="headerlink" title="复杂查询"></a>复杂查询</h3><p>查询可以捎带以下参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">.	    	示例	      	 				备注</div><div class="line">过滤条件		?type=1&amp;age=16				允许一定的uri冗余，如/zoos/1与/zoos?id=1</div><div class="line">排序			?sort=age,desc	</div><div class="line">投影			?whitelist=id,name,email	</div><div class="line">分页			?limit=10&amp;offset=3</div></pre></td></tr></table></figure></p>
<h3 id="Bookmarker"><a href="#Bookmarker" class="headerlink" title="Bookmarker"></a>Bookmarker</h3><p>经常使用的、复杂的查询标签化，降低维护成本。</p>
<p>如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">GET /trades?status=closed&amp;sort=created,desc</div></pre></td></tr></table></figure></p>
<p>快捷方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">GET /trades#recently-closed</div><div class="line">或者</div><div class="line">GET /trades/recently-closed</div></pre></td></tr></table></figure></p>
<h3 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h3><p>只用以下常见的3种body format：</p>
<ol>
<li><p>Content-Type: application/json</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">POST /v1/animal HTTP/1.1</div><div class="line">Host: api.example.org</div><div class="line">Accept: application/json</div><div class="line">Content-Type: application/json</div><div class="line">Content-Length: 24</div><div class="line"></div><div class="line">&#123;   </div><div class="line">  &quot;name&quot;: &quot;Gir&quot;,</div><div class="line">  &quot;animalType&quot;: &quot;12&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>Content-Type: application/x-www-form-urlencoded (浏览器POST表单用的格式)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">POST /login HTTP/1.1</div><div class="line">Host: example.com</div><div class="line">Content-Length: 31</div><div class="line">Accept: text/html</div><div class="line">Content-Type: application/x-www-form-urlencoded</div><div class="line"></div><div class="line">username=root&amp;password=Zion0101</div></pre></td></tr></table></figure>
</li>
<li><p>Content-Type: multipart/form-data; boundary=—-RANDOM_jDMUxq4Ot5 (表单有文件上传时的格式)</p>
</li>
</ol>
<h3 id="Content-Negotiation"><a href="#Content-Negotiation" class="headerlink" title="Content Negotiation"></a>Content Negotiation</h3><p>资源可以有多种表示方式，如json、xml、pdf、excel等等，客户端可以指定自己期望的格式，通常有两种方式：</p>
<ol>
<li><p>http header Accept：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Accept:application/xml;q=0.6,application/atom+xml;q=1.0</div></pre></td></tr></table></figure>
<p>q为各项格式的偏好程度</p>
</li>
<li><p>url中加文件后缀：/zoo/1.json</p>
</li>
</ol>
<h2 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h2><ol>
<li><p>不要包装：<br> response 的 body 直接就是数据，不要做多余的包装。错误示例：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;success&quot;:true,</div><div class="line">    &quot;data&quot;:&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;xiaotuan&quot;&#125;,</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>各HTTP方法成功处理后的数据格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">·			response 格式</div><div class="line">GET			单个对象、集合</div><div class="line">POST		新增成功的对象</div><div class="line">PUT/PATCH	更新成功的对象</div><div class="line">DELETE		空</div></pre></td></tr></table></figure>
</li>
<li><p>json格式的约定：</p>
<ol>
<li>时间用长整形(毫秒数)，客户端自己按需解析（moment.js）</li>
<li>不传null字段</li>
</ol>
</li>
</ol>
<h3 id="分页response"><a href="#分页response" class="headerlink" title="分页response"></a>分页response</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;paging&quot;:&#123;&quot;limit&quot;:10,&quot;offset&quot;:0,&quot;total&quot;:729&#125;,</div><div class="line">    &quot;data&quot;:[&#123;&#125;,&#123;&#125;,&#123;&#125;...]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><ol>
<li>不要发生了错误但给2xx响应，客户端可能会缓存成功的http请求；</li>
<li>正确设置http状态码，不要自定义；</li>
<li>Response body 提供 1) 错误的代码（日志/问题追查）；2) 错误的描述文本（展示给用户）。<br>对第三点的实现稍微多说一点：</li>
</ol>
<p>Java 服务器端一般用异常表示 RESTful API 的错误。API 可能抛出两类异常：业务异常和非业务异常。业务异常由自己的业务代码抛出，表示一个用例的前置条件不满足、业务规则冲突等，比如参数校验不通过、权限校验失败。非业务类异常表示不在预期内的问题，通常由类库、框架抛出，或由于自己的代码逻辑错误导致，比如数据库连接失败、空指针异常、除0错误等等。</p>
<p>业务类异常必须提供2种信息：</p>
<ol>
<li>如果抛出该类异常，HTTP 响应状态码应该设成什么；</li>
<li>异常的文本描述；</li>
<li>在Controller层使用统一的异常拦截器：</li>
</ol>
<p>设置 HTTP 响应状态码：对业务类异常，用它指定的 HTTP code；对非业务类异常，统一500；<br>Response Body 的错误码：异常类名<br>Response Body 的错误描述：对业务类异常，用它指定的错误文本；对非业务类异常，线上可以统一文案如“服务器端错误，请稍后再试”，开发或测试环境中用异常的 stacktrace，服务器端提供该行为的开关。<br>常用的http状态码及使用场景：</p>
<p>状态码                            使用场景<br>400 bad request                    常用在参数校验<br>401 unauthorized                未经验证的用户，常见于未登录。如果经过验证后依然没权限，应该 403（即 authentication 和 authorization 的区别）。<br>403 forbidden                    无权限<br>404 not found                    资源不存在<br>500 internal server error        非业务类异常<br>503 service unavaliable            由容器抛出，自己的代码不要抛这个异常</p>
<h2 id="服务型资源"><a href="#服务型资源" class="headerlink" title="服务型资源"></a>服务型资源</h2><p>除了资源简单的CRUD，服务器端经常还会提供其他服务，这些服务无法直接用上面提到的URI映射。如：</p>
<ol>
<li>按关键字搜索；</li>
<li>计算地球上两点间的距离；</li>
<li>批量向用户推送消息<br>可以把这些服务看成资源，计算的结果是资源的presentation，按服务属性选择合适的HTTP方法。</li>
</ol>
<p>例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">GET /search?q=filter?category=file  搜索</div><div class="line">GET /distance-calc?lats=47.480&amp;lngs=-122.389&amp;late=37.108&amp;lnge=-122.448</div><div class="line">POST /batch-publish-msg</div><div class="line">[&#123;&quot;from&quot;:0,&quot;to&quot;:1,&quot;text&quot;:&quot;abc&quot;&#125;,&#123;&#125;,&#123;&#125;...]</div></pre></td></tr></table></figure></p>
<h2 id="异步任务"><a href="#异步任务" class="headerlink" title="异步任务"></a>异步任务</h2><p>对耗时的异步任务，服务器端接受客户端传递的参数后，应返回创建成功的任务资源，其中包含了任务的执行状态。客户端可以轮训该任务获得最新的执行进度。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">提交任务：</div><div class="line">POST /batch-publish-msg</div><div class="line">[&#123;&quot;from&quot;:0,&quot;to&quot;:1,&quot;text&quot;:&quot;abc&quot;&#125;,&#123;&#125;,&#123;&#125;...]</div><div class="line"></div><div class="line">返回：</div><div class="line">&#123;&quot;taskId&quot;:3,&quot;createBy&quot;:&quot;Anonymous&quot;,&quot;status&quot;:&quot;running&quot;&#125;</div><div class="line"></div><div class="line">GET /task/3</div><div class="line">&#123;&quot;taskId&quot;:3,&quot;createBy&quot;:&quot;Anonymous&quot;,&quot;status&quot;:&quot;success&quot;&#125;</div><div class="line">如果任务的执行状态包括较多信息，可以把“执行状态”抽象成组合资源，客户端查询该状态资源了解任务的执行情况。</div><div class="line"></div><div class="line">提交任务：</div><div class="line">POST /batch-publish-msg</div><div class="line">[&#123;&quot;from&quot;:0,&quot;to&quot;:1,&quot;text&quot;:&quot;abc&quot;&#125;,&#123;&#125;,&#123;&#125;...]</div><div class="line"></div><div class="line">返回：</div><div class="line">&#123;&quot;taskId&quot;:3,&quot;createBy&quot;:&quot;Anonymous&quot;&#125;</div><div class="line"></div><div class="line">GET /task/3/status</div><div class="line">&#123;&quot;progress&quot;:&quot;50%&quot;,&quot;total&quot;:18,&quot;success&quot;:8,&quot;fail&quot;:1&#125;</div></pre></td></tr></table></figure></p>
<h2 id="API的演进"><a href="#API的演进" class="headerlink" title="API的演进"></a>API的演进</h2><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>常见的三种方式：</p>
<ol>
<li>在uri中放版本信息：GET /v1/users/1</li>
<li>Accept Header：Accept: application/json+v1</li>
<li>自定义 Header：X-Api-Version: 1<br>用第一种，虽然没有那么优雅，但最明显最方便。</li>
</ol>
<h3 id="URI失效"><a href="#URI失效" class="headerlink" title="URI失效"></a>URI失效</h3><p>随着系统发展，总有一些API失效或者迁移，对失效的API，返回404 not found 或 410 gone；对迁移的API，返回 301 重定向。</p>
<h2 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h2><p>这个不熟，接触到的时候再说。</p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> restful </tag>
            
            <tag> 设计模式 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java多线程 生产者消费者的N种姿势]]></title>
      <url>http://Melodylican.github.io/2015/04/15/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%20%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84N%E7%A7%8D%E5%A7%BF%E5%8A%BF/</url>
      <content type="html"><![CDATA[<p>学校里有作业，需要实现生产者消费者模型，最简单的就是用synchronized同步锁一包，什么事情都没有了，不过由于是从最外层包起来的，所以总体而言就Low很多了。<br><a id="more"></a><br>一共用了四种方法，心好累：</p>
<h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2><p>synchronized同步锁同样踩到了坑，主要是关于extends Thread和implements Runnable的区别上，这是第一个坑。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.producer;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        ThreadSynchronized semaphore = <span class="keyword">new</span> ThreadSynchronized();</div><div class="line">        <span class="keyword">new</span> Thread(semaphore.new Producer(<span class="string">"Pro1"</span>), <span class="string">"Pro1"</span>).start();</div><div class="line">        <span class="keyword">new</span> Thread(semaphore.new Producer(<span class="string">"Pro2"</span>), <span class="string">"Pro2"</span>).start();</div><div class="line">        <span class="keyword">new</span> Thread(semaphore.new Producer(<span class="string">"Pro3"</span>), <span class="string">"Pro3"</span>).start();</div><div class="line">        <span class="keyword">new</span> Thread(semaphore.new Consumer(<span class="string">"Con1"</span>), <span class="string">"Con1"</span>).start();</div><div class="line">        <span class="keyword">new</span> Thread(semaphore.new Consumer(<span class="string">"Con2"</span>), <span class="string">"Con2"</span>).start();</div><div class="line">        <span class="comment">//System.out.println("你好");</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>总之代码相当的不干净，这是Main部分，之后我们除了声明基本上都不需要修改了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.producer;</div><div class="line"><span class="keyword">import</span> java.util.LinkedList;</div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by SkyAo on 15/10/18.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadSynchronized</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> pid;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> cid;</div><div class="line">    <span class="keyword">public</span> LinkedList&lt;Item&gt; items = <span class="keyword">new</span> LinkedList&lt;&gt;();</div><div class="line">    <span class="keyword">private</span> Item temp;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> item;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> flag = <span class="keyword">false</span>;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> id;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">        &#125;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.id = ++pid;</div><div class="line">            System.out.println(<span class="string">"Start Thread("</span> + <span class="keyword">this</span>.id + <span class="string">"): "</span> + Thread.currentThread().getName());</div><div class="line">            <span class="comment">//while (true)</span></div><div class="line">                <span class="keyword">this</span>.produce();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">produce</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>)</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                Thread.sleep((<span class="keyword">int</span>)(Math.random()*<span class="number">5000</span>)+<span class="number">3000</span>);</div><div class="line">                <span class="keyword">while</span> (items.size() == <span class="number">5</span>) &#123;</div><div class="line">                    <span class="keyword">super</span>.wait();</div><div class="line">                &#125;</div><div class="line">                items.add(<span class="keyword">new</span> Item(<span class="keyword">this</span>.id, Thread.currentThread().getName()));</div><div class="line">                temp = items.getLast();</div><div class="line">                System.out.println(temp.sourceName + <span class="string">" Produce: "</span> + temp.semi);</div><div class="line">                System.out.println(<span class="string">"Left: "</span>);</div><div class="line">                <span class="keyword">for</span> (Item item : items) &#123;</div><div class="line">                    System.out.println(item.sourceName + <span class="string">":"</span> + item.semi);</div><div class="line">                &#125;</div><div class="line">                System.out.println(<span class="string">"---Left: "</span> + items.size() + <span class="string">"---"</span>);</div><div class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                <span class="keyword">super</span>.notifyAll();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> id;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="comment">//this.id = ++cid;</span></div><div class="line">        &#125;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.id = ++cid;</div><div class="line">            System.out.println(<span class="string">"Start Thread("</span> + <span class="keyword">this</span>.id + <span class="string">"): "</span> + Thread.currentThread().getName());</div><div class="line">            <span class="keyword">this</span>.consume();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">consume</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>)</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                Thread.sleep((<span class="keyword">int</span>) (Math.random() * <span class="number">5000</span>) + <span class="number">3000</span>);</div><div class="line">                <span class="keyword">while</span> (items.size() == <span class="number">0</span>) &#123;</div><div class="line">                    <span class="keyword">this</span>.wait();</div><div class="line">                &#125;</div><div class="line">                temp = items.removeFirst();</div><div class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">" Consume: "</span> + temp.semi);</div><div class="line">                System.out.println(<span class="string">"Left: "</span>);</div><div class="line">                <span class="keyword">for</span> (Item item : items) &#123;</div><div class="line">                    System.out.println(item.sourceName + <span class="string">":"</span> + item.semi);</div><div class="line">                &#125;</div><div class="line">                System.out.println(<span class="string">"---Left: "</span> + items.size() + <span class="string">"---"</span>);</div><div class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                <span class="keyword">super</span>.notifyAll();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>调了半天，如果是implements Runnable会导致同一个线程重复工作。</p>
<p>wait()和notifyAll()就是拿来阻塞和通知的，notifyAll()和notify()的区别根据网上所说是随机通知和唤醒全部再去竞争，从现象而言其实是看不出效果的吧。</p>
<h2 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h2><p>信号量的方法实现起来就跟书上的代码一样，非常爽，没有之一。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.producer;</div><div class="line"><span class="keyword">import</span> java.util.LinkedList;</div><div class="line"><span class="keyword">import</span> java.util.concurrent.Semaphore;</div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by SkyAo on 15/10/18.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadSemaphore</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Semaphore mutex = <span class="keyword">new</span> Semaphore(<span class="number">1</span>);</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Semaphore notFull = <span class="keyword">new</span> Semaphore(<span class="number">5</span>);</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Semaphore notEmpty = <span class="keyword">new</span> Semaphore(<span class="number">0</span>);</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> pid;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> cid;</div><div class="line">    <span class="keyword">public</span> LinkedList&lt;Item&gt; items = <span class="keyword">new</span> LinkedList&lt;&gt;();</div><div class="line">    <span class="keyword">private</span> Item temp;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> id;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.id = ++pid;</div><div class="line">        &#125;</div><div class="line">         <span class="meta">@Override</span></div><div class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">             System.out.println(<span class="string">"Start Thread("</span> + <span class="keyword">this</span>.id + <span class="string">"): "</span> + <span class="keyword">this</span>.name);</div><div class="line">             <span class="keyword">this</span>.produce();</div><div class="line">         &#125;</div><div class="line">         <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">produce</span><span class="params">()</span> </span>&#123;</div><div class="line">             <span class="keyword">do</span> &#123;</div><div class="line">                 <span class="keyword">try</span> &#123;</div><div class="line">                     Thread.sleep(<span class="number">3000</span>);</div><div class="line">                     notFull.acquire();</div><div class="line">                     mutex.acquire();</div><div class="line">                     items.add(<span class="keyword">new</span> Item(<span class="keyword">this</span>.id, <span class="keyword">this</span>.name));</div><div class="line">                     temp =  items.getLast();</div><div class="line">                     System.out.println(temp.sourceName + <span class="string">" Produce: "</span> + temp.semi);</div><div class="line">                     System.out.println(<span class="string">"Left: "</span>);</div><div class="line">                     <span class="keyword">for</span> (Item item : items) &#123;</div><div class="line">                         System.out.println(item.sourceName + <span class="string">":"</span> + item.semi);</div><div class="line">                     &#125;</div><div class="line">                     System.out.println(<span class="string">"---Left: "</span> + items.size() + <span class="string">"---"</span>);</div><div class="line">                 &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                     e.printStackTrace();</div><div class="line">                 &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                     mutex.release();</div><div class="line">                     notEmpty.release();</div><div class="line">                 &#125;</div><div class="line">             &#125; <span class="keyword">while</span> (<span class="keyword">true</span>);</div><div class="line">         &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> id;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(String name)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.id = ++cid;</div><div class="line">        &#125;</div><div class="line">        <span class="meta">@Override</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Start Thread("</span> + <span class="keyword">this</span>.id + <span class="string">"): "</span> + <span class="keyword">this</span>.name);</div><div class="line">            <span class="keyword">this</span>.consume();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">consume</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">do</span> &#123;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    Thread.sleep(<span class="number">3000</span>);</div><div class="line">                    notEmpty.acquire();</div><div class="line">                    mutex.acquire();</div><div class="line">                    temp = items.removeFirst();</div><div class="line">                    System.out.println(<span class="keyword">this</span>.name + <span class="string">" Consume: "</span> + temp.semi);</div><div class="line">                    System.out.println(<span class="string">"Left: "</span>);</div><div class="line">                    <span class="keyword">for</span> (Item item : items) &#123;</div><div class="line">                        System.out.println(item.sourceName + <span class="string">":"</span> + item.semi);</div><div class="line">                    &#125;</div><div class="line">                    System.out.println(<span class="string">"---Left: "</span> + items.size() + <span class="string">"---"</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                    mutex.release();</div><div class="line">                    notFull.release();</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">while</span> (<span class="keyword">true</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>信号量就是通过初始化时设置令牌，然后去争抢令牌，用完记得释放。</p>
<p>如果是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> Semaphore notEmpty = <span class="keyword">new</span> Semaphore(<span class="number">0</span>);</div></pre></td></tr></table></figure></p>
<p>这个就得先等释放令牌了。</p>
<h2 id="Condition-ReentrantLock"><a href="#Condition-ReentrantLock" class="headerlink" title="Condition ReentrantLock"></a>Condition ReentrantLock</h2><p>Java更新之后有了一个更好的锁：ReentrantLock</p>
<p>跟synchronized差不多。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.Condition;  </div><div class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</div><div class="line"><span class="keyword">import</span> java.io.*;</div><div class="line"><span class="keyword">import</span> java.net.*;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadTest</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> items;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();     <span class="comment">// 设置锁</span></div><div class="line">    <span class="keyword">private</span> Condition notEmpty = lock.newCondition();           <span class="comment">// 设置条件</span></div><div class="line">    <span class="keyword">private</span> Condition notFull = lock.newCondition();            <span class="comment">// 设置条件</span></div><div class="line">    <span class="comment">/*</span></div><div class="line">        get方式发送数据</div><div class="line">    */</div><div class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">URLAction</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">url</span><span class="params">(String name, <span class="keyword">int</span> delete, <span class="keyword">int</span> num)</span></span>&#123;</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                URL url = <span class="keyword">new</span> URL(<span class="string">"http://localhost:3000/?name="</span>+name+<span class="string">"&amp;delete="</span> + delete + <span class="string">"&amp;num="</span> + num);</div><div class="line">                URLConnection conn = url.openConnection();</div><div class="line">                BufferedReader in = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(conn.getInputStream()));</div><div class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">/*</span></div><div class="line">        生产者模型</div><div class="line">    */</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        String name;</div><div class="line">        <span class="keyword">int</span> num;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String name, <span class="keyword">int</span> num)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.num = num;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Start Producer"</span>);</div><div class="line">            produce();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">produce</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">do</span> &#123;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    Thread.sleep((<span class="keyword">int</span>)(Math.random()*<span class="number">5000</span>)+<span class="number">3000</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">                lock.lock();</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    <span class="keyword">if</span> (items &gt;= <span class="number">5</span>) &#123;</div><div class="line">                        <span class="keyword">try</span> &#123;</div><div class="line">                            System.out.println(<span class="string">"位置用完了"</span>);</div><div class="line">                            notFull.await();</div><div class="line">                        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                            e.printStackTrace();</div><div class="line">                        &#125;</div><div class="line">                    &#125;</div><div class="line">                    System.out.println(name + <span class="string">"生产"</span> + ++items);</div><div class="line">                    URLAction.url(name, <span class="number">0</span>, num);</div><div class="line">                    notEmpty.signal();</div><div class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                    lock.unlock();</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">while</span> (<span class="keyword">true</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        String name;</div><div class="line">        <span class="keyword">int</span> num;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(String name, <span class="keyword">int</span> num)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.num = num;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Start Consumer"</span>);</div><div class="line">            consume();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">consume</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">do</span> &#123;</div><div class="line">                <span class="keyword">try</span>&#123;</div><div class="line">                        <span class="keyword">try</span> &#123;</div><div class="line">                            Thread.sleep((<span class="keyword">int</span>)(Math.random()*<span class="number">5000</span>)+<span class="number">2000</span>);</div><div class="line">                        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                            e.printStackTrace();</div><div class="line">                        &#125;</div><div class="line">                        lock.lock();</div><div class="line">                        <span class="keyword">if</span> (items &lt;= <span class="number">0</span>) &#123;</div><div class="line">                            <span class="keyword">try</span> &#123;</div><div class="line">                                System.out.println(<span class="string">"位置空，等待生产"</span>);</div><div class="line">                                notEmpty.await();</div><div class="line">                            &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                                e.printStackTrace();</div><div class="line">                            &#125;</div><div class="line">                        &#125;</div><div class="line">                        notFull.signal();</div><div class="line">                        System.out.println(name + <span class="string">"消费"</span> + --items);</div><div class="line">                        URLAction.url(name, <span class="number">1</span>, num);</div><div class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                    lock.unlock();</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">while</span> (<span class="keyword">true</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</div><div class="line">        ThreadTest test = <span class="keyword">new</span> ThreadTest();</div><div class="line">        System.out.println(<span class="string">"Start Thread, items:"</span> + test.items);</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"Pro1"</span>, <span class="number">0</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"Pro2"</span>, <span class="number">1</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"Pro3"</span>, <span class="number">2</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Consumer(<span class="string">"Con1"</span>, <span class="number">0</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Consumer(<span class="string">"Con2"</span>, <span class="number">1</span>)).start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="Mutex"><a href="#Mutex" class="headerlink" title="Mutex"></a>Mutex</h2><p>Mutex也是个锁，跟信号量一样要上两把锁，然后要及时释放，不然就会卡了。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.*;</div><div class="line"><span class="keyword">import</span> java.net.*;</div><div class="line"><span class="keyword">import</span> java.util.*;</div><div class="line"><span class="keyword">import</span> com.sun.corba.se.impl.orbutil.concurrent.*;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadTestMutex</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> Mutex mutex = <span class="keyword">new</span> Mutex();  <span class="comment">// 同步信号量</span></div><div class="line">    <span class="keyword">private</span> Mutex notFull = <span class="keyword">new</span> Mutex();    <span class="comment">// 是否满的信号量</span></div><div class="line">    <span class="keyword">private</span> Mutex notEmpty = <span class="keyword">new</span> Mutex();   <span class="comment">// 是否为空的信号量</span></div><div class="line">    <span class="keyword">private</span> Mutex access = <span class="keyword">new</span> Mutex();</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> items = <span class="number">0</span>;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">int</span> lock = <span class="number">1</span>;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> pid;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(String name, <span class="keyword">int</span> pid)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.pid = pid;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Start Producer: "</span>);</div><div class="line">            <span class="keyword">this</span>.produce();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">produce</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">do</span> &#123;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    <span class="keyword">try</span> &#123;</div><div class="line">                        Thread.sleep(<span class="number">400</span>);</div><div class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                        e.printStackTrace();</div><div class="line">                    &#125;</div><div class="line">                    notFull.acquire();</div><div class="line">                    mutex.acquire();</div><div class="line">                    <span class="keyword">if</span> (items &lt; <span class="number">5</span>) &#123;</div><div class="line">                        items++;</div><div class="line">                        <span class="comment">//System.out.println("位置用完了" + items);</span></div><div class="line">                        notEmpty.release();</div><div class="line">                    &#125;</div><div class="line">                    System.out.println(name + <span class="string">":"</span> + items);</div><div class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">finally</span> &#123;             </div><div class="line">                    mutex.release();</div><div class="line">                    notFull.release();</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">while</span>(<span class="keyword">true</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> String name;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">int</span> pid;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(String name, <span class="keyword">int</span> pid)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.name = name;</div><div class="line">            <span class="keyword">this</span>.pid = pid;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"Start Consumer: "</span>);</div><div class="line">            <span class="keyword">this</span>.consume();</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">consume</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">do</span>&#123;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    Thread.sleep(<span class="number">500</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    notEmpty.acquire();</div><div class="line">                    mutex.acquire();</div><div class="line">                    <span class="keyword">if</span> (items &gt; <span class="number">0</span>) &#123;</div><div class="line">                        items--;</div><div class="line">                        <span class="comment">//System.out.println("没有产品" + items);</span></div><div class="line">                        notFull.release();</div><div class="line">                    &#125;</div><div class="line">                    System.out.println(name + <span class="string">":"</span> + items);</div><div class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125; <span class="keyword">finally</span> &#123;</div><div class="line">                    mutex.release();</div><div class="line">                    notEmpty.release();</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">while</span>(<span class="keyword">true</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</div><div class="line">        ThreadTestMutex test = <span class="keyword">new</span> ThreadTestMutex();</div><div class="line">        System.out.println(<span class="string">"Start"</span>);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            test.notEmpty.acquire();</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"pro1"</span>, <span class="number">0</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"pro2"</span>, <span class="number">1</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"pro3"</span>, <span class="number">2</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"pro4"</span>, <span class="number">3</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Producer(<span class="string">"pro5"</span>, <span class="number">4</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Consumer(<span class="string">"con1"</span>, <span class="number">0</span>)).start();</div><div class="line">        <span class="keyword">new</span> Thread(test.new Consumer(<span class="string">"con2"</span>, <span class="number">1</span>)).start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 多线程 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[几个常见的概率问题]]></title>
      <url>http://Melodylican.github.io/2014/06/12/%E5%87%A0%E4%B8%AA%E5%B8%B8%E8%A7%81%E7%9A%84%E6%A6%82%E7%8E%87%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h2 id="几个常见的概率问题"><a href="#几个常见的概率问题" class="headerlink" title="几个常见的概率问题"></a>几个常见的概率问题</h2><h3 id="几个常见的概率问题-1"><a href="#几个常见的概率问题-1" class="headerlink" title="几个常见的概率问题"></a>几个常见的概率问题</h3><ol>
<li>洗牌</li>
<li>随机数生成器的转换</li>
<li>蓄水池抽样</li>
<li>参考<br>今天研究了下几个简单的概率问题，在这里记录下。<a id="more"></a>
<h3 id="1-洗牌"><a href="#1-洗牌" class="headerlink" title="1. 洗牌"></a>1. 洗牌</h3></li>
</ol>
<p>问题很简单，有 n 个元素，设计一个能保证随机性的洗牌算法。</p>
<p>直觉想到的算法是：</p>
<p>用一个数组作为新牌堆，不停地从原数组剩下的元素中随机挑一个放入新牌堆，直到原牌堆耗尽。<br>我们来验证一下它的随机性。考虑一个元素，洗牌后它在第一个位置（即第一次抽牌就选中它）的概率是:</p>
<p><center><br><img src="http://novoland.github.io/assets/img/3f17656b5cb9a1ea355e0e7d4b423a8b" alt=""><br></center><br>在第二个位置的概率是：</p>
<p><center><br><img src="http://novoland.github.io/assets/img/475c80801a60fc5e09d937b6f1afe68e" alt=""><br></center><br>依次类推，可知该元素将被等概率地分配到任意位置，符合要求。</p>
<p>按该思路实现洗牌算法时有两个问题。首先，新牌堆显然需要<font color="red"> O(n)</font> 的空间；其次，元素从旧数组移入新牌堆后势必会留下空洞，在后续抽牌时要跳过这些空洞位置。</p>
<p>但实际上，新牌堆和旧牌堆元素之和始终为<font color="red"> n</font>，因此整个洗牌过程可以就地完成。我们可以从前向后遍历，对元素<font color="red"> i</font>，前<font color="red"> i-1</font> 个位置构成新牌堆，<font color="red">i </font>及其后续元素属于旧牌堆。从旧牌堆中随机抽一个元素，与 i 处元素交换，即完成了一次抽牌动作：</p>
<p><center><br><img src="http://novoland.github.io/assets/img/1a87c760b2ed0738a84555935ac5928d.png" alt=""><br></center><br>这个算法还有个名字，<font color="red">Fisher–Yates shuffle</font>。</p>
<p>代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">function shuffle(array) &#123;</div><div class="line">  var m = array.length, i;</div><div class="line"></div><div class="line">  // While there remain elements to shuffle…</div><div class="line">  // 为了方便这里是从后往前遍历的</div><div class="line">  <span class="keyword">while</span> (m) &#123;</div><div class="line"></div><div class="line">    // Pick a remaining element…</div><div class="line">    i = Math.floor(Math.random() * m--);</div><div class="line"></div><div class="line">    // And swap it <span class="keyword">with</span> the current element.</div><div class="line">    var t = array[m];</div><div class="line">    array[m] = array[i];</div><div class="line">    array[i] = t;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-随机数生成器的转换"><a href="#2-随机数生成器的转换" class="headerlink" title="2. 随机数生成器的转换"></a>2. 随机数生成器的转换</h3><p>听名字有点绕，其实就是给你一个<font color="red">Rand5()</font>，表示随机生成<font color="red">[0,5)</font>之间的数字，让你实现一个<font color="red">Rand3()</font>。</p>
<pre><code class="python">int Rand3()  
{  
    int x = <span class="number">5</span>;  
    <span class="keyword">while</span>(x &gt;= <span class="number">3</span>) 
        x = Rand5();  
    <span class="keyword">return</span> x;  
}
</code></pre>
<p>逻辑很简单，用<font color="red">Rand5()</font>不停地产生随机数，直到某个数字落在了<font color="red">[0,3)</font> 内。最终只会生成 0/1/2 三个数字，看起来似乎每个数字都是等概率的。下面来证明这个结论：</p>
<blockquote>
<p>以输出<font color="red">0</font>为例，看看概率是多少。第一次<font color="red">Rand5</font> 返回<font color="red">0</font>的概率是<font color="red">1/5</font>，如果返回<font color="red">3</font>或<font color="red">4</font>（2/5 的概率），则需要调用第二次，同样的，也是1/5的概率得到 0，2/5 的概率得到3或4导致循环继续执行下去，如此反复。因此输出 0 的概率为：</p>
<p><center><br><img src="http://novoland.github.io/assets/img/0beca4bfb94ae7df66d05986a90c919f" alt=""><br></center><br>显然这种方法是正确的。</p>
</blockquote>
<p>换一下题目，给一个<font color="red">Rand(3)</font>，怎么生成一个<font color="red">Rand(5)</font>呢？由于<font color="red">Rand3()X3+Rand3()</font> 可以构造出<font color="red">Rand(9)</font>，对它再应用上述算法即可。</p>
<p>解释下<font color="red">Rand3()X3+Rand3()</font>为什么可以得到<font color="red">Rand(9)</font>。<font color="red">Rand3()X3</font>得到一个随机数集合<font color="red">0,3,6，Rand3()</font>得到<font color="red">0,1,2</font>，二者相加的结果刚好均匀地分布在<font color="red">[0,9)</font>区间内。推广这个结论可得，<font color="red">RandM()XM+RandM()</font>可以得到<font color="red">[0,M^2)</font>区间内的随机数生成器。</p>
<h3 id="3-蓄水池抽样"><a href="#3-蓄水池抽样" class="headerlink" title="3. 蓄水池抽样"></a>3. 蓄水池抽样</h3><p>蓄水池抽样是要解决这样一个问题：给定一个很大的集合，集合总数 n 不能确定，只能遍历一遍，要求从中随机选取 k 个元素。</p>
<p>蓄水池算法的原理是：维护一个大小为 k 的蓄水池，用集合的前 k 个元素初始化之；对后续每个元素 i，都以k/i 的概率替换掉蓄水池中的某个元素。</p>
<p>代码：</p>
<pre><code class="python">Init : a reservoir <span class="keyword">with</span> the size： k  
<span class="keyword">for</span> i= k+<span class="number">1</span> to n  
   M=random(<span class="number">1</span>, i);  
   <span class="keyword">if</span>( M &lt; k)  
        SWAP the Mth value <span class="keyword">and</span> ith value  
end <span class="keyword">for</span>
</code></pre>
<p>下面来证明一下该算法的正确性。</p>
<p>对某个元素，第一次就选中它的概率是 1/n，第二次才选中它的概率是(1-1/n)X1/(n-1)=1/n ，第三次第四次也类似，这跟之前的洗牌场景很像。因此，最终该元素被选中的概率就等于k/n 。</p>
<ol>
<li>当 n == k 时，每个元素出现在蓄水池的概率都是1，即 k/k；</li>
<li>当 n == k+1 时，第一次考察发生在元素 k+1 处，根据算法，它被放入蓄水池的概率为k/(k+1) ；对原蓄水池中的任一元素，该次考察后被换出去的概率等于：<br><center><br><img src="http://novoland.github.io/assets/img/a85c57c8be70611b24f70a80575f386a" alt=""><br></center><br>所以，元素依然在蓄水池内的概率为<img src="http://novoland.github.io/assets/img/025327d6f9171ce2d2c76897e38ff021" alt=""> 。</li>
<li><p>当 n == k+2 时，根据2，前 k+1 内的元素在第二次考察（即考察第 k+2 个元素）前在蓄水池内的概率为 。</p>
<p>同样的，第 k+2 个元素被放入蓄水池的概率为 k/(k+2)；</p>
<p>对前 k+1 的元素，在第二次考察后在蓄水池要求 1)之前就在蓄水池；2)这次没有被交换出去：<br><center><br><img src="http://novoland.github.io/assets/img/98099a39d68c6dbf4895a6d91c019aed" alt=""><br></center><br>也符合条件。</p>
</li>
<li>推广上述过程即可得证。<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><a href="http://novoland.github.io/%E7%AE%97%E6%B3%95/2014/08/05/%E5%87%A0%E4%B8%AA%E5%B8%B8%E8%A7%81%E7%9A%84%E6%A6%82%E7%8E%87%E9%97%AE%E9%A2%98.html" target="_blank" rel="external">常见概率问题</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 概率问题 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SpringBoot快速入门]]></title>
      <url>http://Melodylican.github.io/2014/05/01/Springboot%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<p>今天给大家介绍一下spring Boot MVC，让我们学习一下如何利用Spring Boot快速的搭建一个简单的web应用。<br><a id="more"></a></p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">•一个称手的文本编辑器（例如Vim、Emacs、Sublime Text）或者IDE（Eclipse、Idea Intellij）</div><div class="line">•Java环境（JDK 1.7或以上版本）</div><div class="line">•Maven 3.0+（Eclipse和Idea IntelliJ内置，如果使用IDE并且不使用命令行工具可以不安装）</div></pre></td></tr></table></figure>
<h2 id="一个最简单的Web应用"><a href="#一个最简单的Web应用" class="headerlink" title="一个最简单的Web应用"></a>一个最简单的Web应用</h2><p>使用Spring Boot框架可以大大加速Web应用的开发过程，首先在Maven项目依赖中引入spring-boot-starter-web：</p>
<p><font color="red">pom.xml</font><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"> &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</div><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</div><div class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</div><div class="line">  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line"></div><div class="line">  &lt;groupId&gt;com.tianmaying&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;spring-web-demo&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</div><div class="line">  &lt;packaging&gt;jar&lt;/packaging&gt;</div><div class="line"></div><div class="line">  &lt;name&gt;spring-web-demo&lt;/name&gt;</div><div class="line">  &lt;description&gt;Demo project for Spring WebMvc&lt;/description&gt;</div><div class="line"></div><div class="line">  &lt;parent&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.2.5.RELEASE&lt;/version&gt;</div><div class="line">    &lt;relativePath/&gt;</div><div class="line">  &lt;/parent&gt;</div><div class="line"></div><div class="line">  &lt;properties&gt;</div><div class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</div><div class="line">    &lt;java.version&gt;1.8&lt;/java.version&gt;</div><div class="line">  &lt;/properties&gt;</div><div class="line"></div><div class="line">  &lt;dependencies&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">  &lt;/dependencies&gt;</div><div class="line"></div><div class="line">  &lt;build&gt;</div><div class="line">    &lt;plugins&gt;</div><div class="line">      &lt;plugin&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</div><div class="line">      &lt;/plugin&gt;</div><div class="line">    &lt;/plugins&gt;</div><div class="line">  &lt;/build&gt;</div><div class="line"></div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p>接下来创建<font color="red">src/main/Java/Application.java</font>:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</div><div class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</div><div class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</div><div class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</div><div class="line"></div><div class="line"><span class="meta">@SpringBootApplication</span></div><div class="line"><span class="meta">@RestController</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/"</span>)</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">greeting</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"Hello World!"</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        SpringApplication.run(Application.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>运行应用：<font color="red">mvn spring-boot:run</font>或在IDE中运行<font color="red">main()</font>方法，在浏览器中访问<font color="red"><a href="http://localhost:8080" target="_blank" rel="external">http://localhost:8080</a></font>，Hello World!就出现在了页面中。只用了区区十几行Java代码，一个Hello World应用就可以正确运行了，那么这段代码究竟做了什么呢？我们从程序的入口<font color="red">SpringApplication.run(Application.class, args)</font>;开始分析：</p>
<ul>
<li>1.SpringApplication是Spring Boot框架中描述Spring应用的类，它的<font color="red">run()</font>方法会创建一个Spring应用上下文（Application Context）。另一方面它会扫描当前应用类路径上的依赖，例如本例中发现spring-webmvc（由 spring-boot-starter-web传递引入）在类路径中，那么Spring Boot会判断这是一个Web应用，并启动一个内嵌的Servlet容器（默认是Tomcat）用于处理HTTP请求。</li>
<li>2.Spring WebMvc框架会将Servlet容器里收到的HTTP请求根据路径分发给对应的<font color="red">@Controller</font>类进行处理，<font color="red">@RestController</font>是一类特殊的<font color="red">@Controller</font>，它的返回值直接作为HTTP Response的Body部分返回给浏览器。</li>
<li>3.<font color="red">@RequestMapping</font>注解表明该方法处理那些URL对应的HTTP请求，也就是我们常说的URL路由（routing)，请求的分发工作是有Spring完成的。例如上面的代码中<font color="red"><a href="http://localhost:8080/" target="_blank" rel="external">http://localhost:8080/</a></font>根路径就被路由至greeting()方法进行处理。如果访问<font color="red"><a href="http://localhost:8080/hello" target="_blank" rel="external">http://localhost:8080/hello</a></font>，则会出现404 Not Found错误，因为我们并没有编写任何方法来处理/hello请求。</li>
</ul>
<h2 id="使用-Controller实现URL路由"><a href="#使用-Controller实现URL路由" class="headerlink" title="使用@Controller实现URL路由"></a>使用@Controller实现URL路由</h2><p>现代Web应用往往包括很多页面，不同的页面也对应着不同的URL。对于不同的URL，通常需要不同的方法进行处理并返回不同的内容。</p>
<h3 id="匹配多个URL"><a href="#匹配多个URL" class="headerlink" title="匹配多个URL"></a>匹配多个URL</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"> <span class="meta">@RestController</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/"</span>)</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">index</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"Index Page"</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/hello"</span>)</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"Hello World!"</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><font color="red">@RequestMapping</font>可以注解<font color="red">@Controller</font>类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@RestController</span></div><div class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/classPath"</span>)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</div><div class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/methodPath"</span>)</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">method</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"mapping url is /classPath/methodPath"</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>method方法匹配的URL是/classPath/methodPath”。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">提示</div><div class="line"></div><div class="line">可以定义多个@Controller将不同URL的处理方法分散在不同的类中</div></pre></td></tr></table></figure></p>
<h2 id="URL中的变量——PathVariable"><a href="#URL中的变量——PathVariable" class="headerlink" title="URL中的变量——PathVariable"></a>URL中的变量——PathVariable</h2><p>在Web应用中URL通常不是一成不变的，例如微博两个不同用户的个人主页对应两个不同的URL:<font color="red"><a href="http://weibo.com/user1，http://weibo.com/user2" target="_blank" rel="external">http://weibo.com/user1，http://weibo.com/user2</a></font>。我们不可能对于每一个用户都编写一个被@RequestMapping注解的方法来处理其请求，Spring MVC提供了一套机制来处理这种情况：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> <span class="meta">@RequestMapping</span>(<span class="string">"/users/&#123;username&#125;"</span>)</div><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">userProfile</span><span class="params">(@PathVariable(<span class="string">"username"</span>)</span> String username) </span>&#123;</div><div class="line">    <span class="keyword">return</span> String.format(<span class="string">"user %s"</span>, username);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="meta">@RequestMapping</span>(<span class="string">"/posts/&#123;id&#125;"</span>)</div><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">post</span><span class="params">(@PathVariable(<span class="string">"id"</span>)</span> <span class="keyword">int</span> id) </span>&#123;</div><div class="line">    <span class="keyword">return</span> String.format(<span class="string">"post %d"</span>, id);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在上述例子中，URL中的变量可以用<font color="red">{variableName}</font>来表示，同时在方法的参数中加上<font color="red">@PathVariable(“variableName”)</font>，那么当请求被转发给该方法处理时，对应的URL中的变量会被自动赋值给被<font color="red">@PathVariable</font>注解的参数（能够自动根据参数类型赋值，例如上例中的int）。</p>
<h2 id="支持HTTP方法"><a href="#支持HTTP方法" class="headerlink" title="支持HTTP方法"></a>支持HTTP方法</h2><p>对于HTTP请求除了其URL，还需要注意它的方法（Method）。例如我们在浏览器中访问一个页面通常是GET方法，而表单的提交一般是POST方法。<font color="red">@Controller</font>中的方法同样需要对其进行区分：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> <span class="meta">@RequestMapping</span>(value = <span class="string">"/login"</span>, method = RequestMethod.GET)</div><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">loginGet</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="string">"Login Page"</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/login"</span>, method = RequestMethod.POST)</div><div class="line"><span class="function"><span class="keyword">public</span> String <span class="title">loginPost</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="string">"Login Post Request"</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="模板渲染"><a href="#模板渲染" class="headerlink" title="模板渲染"></a>模板渲染</h2><p>在之前所有的<font color="red">@RequestMapping</font>注解的方法中，返回值字符串都被直接传送到浏览器端并显示给用户。但是为了能够呈现更加丰富、美观的页面，我们需要将HTML代码返回给浏览器，浏览器再进行页面的渲染、显示。</p>
<p>一种很直观的方法是在处理请求的方法中，直接返回HTML代码，但是这样做的问题在于——一个复杂的页面HTML代码往往也非常复杂，并且嵌入在Java代码中十分不利于维护。更好的做法是将页面的HTML代码写在模板文件中，渲染后再返回给用户。为了能够进行模板渲染，需要将<font color="red">@RestController</font>改成<font color="red">@Controller</font>：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"> <span class="keyword">import</span> org.springframework.ui.Model;</div><div class="line"></div><div class="line"><span class="meta">@Controller</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloController</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/hello/&#123;name&#125;"</span>)</div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">(@PathVariable(<span class="string">"name"</span>)</span> String name, Model model) </span>&#123;</div><div class="line">        model.addAttribute(<span class="string">"name"</span>, name);</div><div class="line">        <span class="keyword">return</span> <span class="string">"hello"</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在上述例子中，返回值”hello”并非直接将字符串返回给浏览器，而是寻找名字为hello的模板进行渲染，我们使用Thymeleaf模板引擎进行模板渲染，需要引入依赖：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"> &lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<p>接下来需要在默认的模板文件夹<font color="red">src/main/resources/templates/</font>目录下添加一个模板文件hello.html：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"> &lt;!DOCTYPE HTML&gt;</div><div class="line">&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot;&gt;</div><div class="line">&lt;head&gt;</div><div class="line">    &lt;title&gt;Getting Started: Serving Web Content&lt;/title&gt;</div><div class="line">    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">    &lt;p th:text=&quot;&apos;Hello, &apos; + $&#123;name&#125; + &apos;!&apos;&quot; /&gt;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure></p>
<p><font color="red">th:text=”‘Hello, ‘ + ${name} + ‘!’”</font>也就是将我们之前在<font color="red">@Controller</font>方法里添加至Model的属性name进行渲染，并放入</p><p>标签中（因为th:text是’</p><p>‘标签的属性）。模板渲染还有更多的用法，请参考Thymeleaf官方文档。</p>
<h2 id="处理静态文件"><a href="#处理静态文件" class="headerlink" title="处理静态文件"></a>处理静态文件</h2><p>浏览器页面使用HTML作为描述语言，那么必然也脱离不了CSS以及JavaScript。为了能够浏览器能够正确加载类似/css/style.css, /js/main.js等资源，默认情况下我们只需要在src/main/resources/static目录下添加css/style.css和js/main.js文件后，Spring MVC能够自动将他们发布，通过访问/css/style.css, /js/main.js也就可以正确加载这些资源。</p>
]]></content>
      
        <categories>
            
            <category> SpringBoot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[排序算法总结]]></title>
      <url>http://Melodylican.github.io/2014/04/10/%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93/</url>
      <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><h3 id="基于比较"><a href="#基于比较" class="headerlink" title="基于比较"></a>基于比较</h3><p>插入：直接插入 / 希尔<br>交换：冒泡 / 快排<br>选择：堆排序<br>归并<br><a id="more"></a></p>
<h2 id="2-插入"><a href="#2-插入" class="headerlink" title="2. 插入"></a>2. 插入</h2><h3 id="直接插入"><a href="#直接插入" class="headerlink" title="直接插入"></a>直接插入</h3><p>特点：<strong>稳定，就地，平均 <em>O</em>(n^2)，</strong>最好情况(初始有序)下<strong><em>O</em>(n)</strong> </p>
<p>思想：数组被分成两个部分，一个有序一个无序，依次将无序中的元素插入有序部分。</p>
<p>数据若基本有序，插入排序可以大大减少数据交换次数，提升效率。</p>
<h3 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h3><p>特点：<strong>非稳定，就地</strong>，<em>O</em>(n^λ) (1 &lt; λ &lt; 2)</p>
<p>思想：先将序列按增量划分为元素个数近似的若干组，使用直接插入排序法对每组进行排序，不断缩小增量并排序，直到增量为1。</p>
<p>因为增量初始值不容易选择，所以该算法不常用。</p>
<h2 id="3-交换"><a href="#3-交换" class="headerlink" title="3. 交换"></a>3. 交换</h2><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><p>特点：<strong>稳定，就地，平均</strong> <em>O</em>(n^2)，最好(初始有序)<em>O</em>(n) </p>
<p>思想：数组被分成两个部分，一个有序一个无序，不断将较大元素冒泡到无序子序列首。</p>
<p>若某趟冒泡未发生交换，说明数组已经有序，可提前结束。</p>
<h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><p>特点：<strong>不稳定，就地</strong>，平均<em>O(nlgn)</em> ，最差情况(每次 partition 后 pivot 在最前或最后)<em>O(n^2)</em> </p>
<p>思想：每次选定一个 pivot 将数组分割成两个部分，对二者递归应用这个过程。</p>
<h2 id="3-选择"><a href="#3-选择" class="headerlink" title="3. 选择"></a>3. 选择</h2><h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><p>特点：<strong>不稳定，就地</strong>，始终 <em>O(nlgn)</em></p>
<p>思想： 数组建大根堆，不停地 remove 第一个元素放到最后，并重新调整堆。</p>
<h2 id="4-其他"><a href="#4-其他" class="headerlink" title="4. 其他"></a>4. 其他</h2><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>特点：稳定，非就地，时间始终是 ，空间</p>
<p>思想：首先，将整个序列（共N个元素）看成N个有序子序列，然后依次合并相邻的两个子序列，这样一直下去，直至变成一个整体有序的序列。</p>
<p>适用场景：外部排序</p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>大部分简单排序(直接插入排序 / 冒泡排序)都是稳定排序；<br>大部分高级排序都是不稳定排序，除了<strong> 归并排序</strong>。</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 排序 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BloomFilter]]></title>
      <url>http://Melodylican.github.io/2014/03/31/BloomFilter/</url>
      <content type="html"><![CDATA[<h2 id="1-原理"><a href="#1-原理" class="headerlink" title="1. 原理"></a>1. 原理</h2><p>BloomFilter 是一种基于<strong> bit 数组 + 多重hash</strong> 的数据结构，用于判断一个元素是否在一个集合中。<br><a id="more"></a><br>BloomFilter 在内部维护一个长度为 <strong>m</strong> 的bit数组，并提供 <strong>k</strong> 个 hash 函数。当一个元素被加入集合时，用这些 hash 函数计算出 <strong>k</strong> 个数组位置并赋为 1。为了查询一个元素是否在集合中，同样地用 hash 函数计算出该元素在 bit 数组中的 k 个位置，如果全部为 1 就认为在集合中。</p>
<p>当<strong>k</strong>很大时，设计k个独立的hash function是不现实并且困难的。对于一个输出范围很大的hash function（例如MD5产生的128 bits数），如果不同bit位的相关性很小，则可把此输出分割为k份。或者可将k个不同的初始值（例如0,1,2, … ,k-1）结合元素，feed给一个hash function从而产生k个不同的数。</p>
<p>可以看到，BloomFilter 有两个缺点：</p>
<ol>
<li>不支持 remove 元素；</li>
<li>对一个不在集合中的元素，有可能误判；而且误判率会随着元素的增多而升高。因此不适合要求精确的场合。<br>BloomFilter 最大的优点是它是基于 bit 数组的，不保存元素本身，因此非常节省空间；同等规模的集合，BloomFilter 占用的空间可能只有 HashSet 的 1/4 或更少。</li>
</ol>
<h2 id="2-误判率的计算"><a href="#2-误判率的计算" class="headerlink" title="2. 误判率的计算"></a>2. 误判率的计算</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">m: bit 数组长度 </div><div class="line">n: 集合元素个数 </div><div class="line">k: hash 函数个数 </div><div class="line">p: 误判概率\</div></pre></td></tr></table></figure>
<p>很显然，误判概率 p 是关于 m/n/k 的函数:</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter1.jpg" alt=""><br></center>

<p>假设一个 hash 函数计算得到的位置等概率地分布在 bit 数组范围内，那么对于一个 bit 位，一次 hash 后它为 0 的概率是：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter2.jpg" alt=""><br></center>

<p>一个元素被加入集合后，该 bit 依然为 0 的概率是:</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter3.jpg" alt=""><br></center>

<p>n 个元素加入集合后，该 bit 为 0 的概率是：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter4.jpg" alt=""><br></center>

<p>现在查询一个不在集合中的元素，当它所对应的 k 个位置都为 1 时会发生误判，这个概率 p 是：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter5.jpg" alt=""><br></center>

<p>由于  当x逼近0时约等于 ，因此有：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter6.jpg" alt=""><br></center>

<p>对于该函数，省略推导过程给出结论，如果给定 m 和 n，当 k 取以下值时，误判率 p 的值最小：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter7.jpg" alt=""><br></center>

<p>此时误判率 p 等于：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/bloomfilter8.jpg" alt=""><br></center>

<p>公式1 和 公式2 是实现一个 BloomFilter 需要的理论支撑。</p>
<h2 id="3-实现"><a href="#3-实现" class="headerlink" title="3. 实现"></a>3. 实现</h2><p>一个 BloomFilter 需要用户提供两个参数：</p>
<ol>
<li><em>n</em>预计集合规模；</li>
<li><em>p</em>当元素个数达到 n 时，可以接受的误判率<br>bit 数组长度 <em>m</em> 和 hash 函数个数 <em>k</em> 在初始化时由上述两个公式计算而得。</li>
</ol>
<p>在爬虫项目中用了 BloomFilter 作为 url 的判重器。其中 k 个 hash 函数是通过为 MD5 提供 k 个不同的 salt 构造的。实际使用中当集合规模为 500 万，误判率为万分之一时，所占空间仅为 11.5M。</p>
<h2 id="4-其他技巧"><a href="#4-其他技巧" class="headerlink" title="4. 其他技巧"></a>4. 其他技巧</h2><ol>
<li><p>两个 BloomFilter 的交集、并集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">filter1 | filter2 == 并集</div><div class="line">filter1 &amp; filter2 == 交集</div></pre></td></tr></table></figure>
</li>
<li><font color="red">counting BloomFilter</font>

</li>
</ol>
<p>传统 BloomFilter 只能添加元素，不能对元素计数，也无法删除元素。如果把底层数组的 bit 换成 int，就可以支持计数和删除动作。每次插入元素时，将对应的 k 个 int 加一；查询时，返回 k 个 int 的最小值；删除时，将对应的 k 个 int 减一。</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> BloomFilter </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[二叉树的各种遍历方式]]></title>
      <url>http://Melodylican.github.io/2014/02/22/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%84%E7%A7%8D%E9%81%8D%E5%8E%86/</url>
      <content type="html"><![CDATA[<h2 id="1-先序-后序-中序遍历"><a href="#1-先序-后序-中序遍历" class="headerlink" title="1. 先序/后序/中序遍历"></a>1. 先序/后序/中序遍历</h2><p>递归版本的就不谈了，主要看非递归版本。</p>
<p>首先定义一个术语<strong> 左路径</strong>，它指的是从某个节点开始（包括该节点），沿着左孩子向下走直到叶子节点，所形成的路径。</p>
<p>3个顺序的遍历都遵循以下代码框架：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">Node root = ... ;</div><div class="line"></div><div class="line"><span class="keyword">while</span>(root != <span class="keyword">null</span>)&#123;        <span class="comment">// 1. 用以 root 为起点的左路径初始化栈</span></div><div class="line">    stack.push(root);</div><div class="line">    root = root.left;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">while</span>(stack不为空)&#123;         <span class="comment">// 当栈不为空，循环：</span></div><div class="line">    Node n = stack.pop();   <span class="comment">// 2. 从栈中 pop 一个节点出来</span></div><div class="line"></div><div class="line">    Node tmp = n.right;     <span class="comment">// 3. 将该节点 *右孩子* 的左路径入栈</span></div><div class="line">    <span class="keyword">while</span>(tmp != <span class="keyword">null</span>)&#123;</div><div class="line">        stack.push(tmp);</div><div class="line">        tmp = tmp.left;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>简单来说就是下面两步：</p>
<ol>
<li>用根的左路径初始化栈；</li>
<li>循环从栈中 pop 节点，并将该节点右孩子的左路径入栈<br>其实就是 <strong>深度优先遍历</strong> 的思路，只在一些细节地方不同。是不是很简单呢？</li>
</ol>
<h3 id="先序和中序"><a href="#先序和中序" class="headerlink" title="先序和中序"></a>先序和中序</h3><p>先序遍历的过程中，每个节点的访问时机是在节点 <strong>入栈</strong> 时，因此对上述代码框架，在两处 push 处加上对节点的访问逻辑即可。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">Stack&lt;TreeNode&gt; s = <span class="keyword">new</span> Stack&lt;TreeNode&gt;();</div><div class="line"></div><div class="line"><span class="keyword">while</span>(root != <span class="keyword">null</span>)&#123;</div><div class="line">    visit(root);    <span class="comment">// &lt;-- 1 visit when push</span></div><div class="line">    s.push(root);</div><div class="line">    root = root.left;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">while</span>(!s.isEmpty())&#123;</div><div class="line">    TreeNode tmp = s.pop();</div><div class="line"></div><div class="line">    tmp = tmp.right;</div><div class="line">    <span class="keyword">while</span>(tmp != <span class="keyword">null</span>)&#123;</div><div class="line">        visit(tmp); <span class="comment">// &lt;-- 2 visit when push</span></div><div class="line">        s.push(tmp);</div><div class="line">        tmp = tmp.left;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>对于中序，每个节点的访问时机是在节点 <strong>出栈</strong> 时，因此应当在 while 循环内每次 pop 时对节点进行访问。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">Stack&lt;TreeNode&gt; s = <span class="keyword">new</span> Stack&lt;TreeNode&gt;();</div><div class="line"></div><div class="line"><span class="keyword">while</span>(root != <span class="keyword">null</span>)&#123;</div><div class="line">    s.push(root);</div><div class="line">    root = root.left;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">while</span>(!s.isEmpty())&#123;</div><div class="line">    TreeNode tmp = s.pop();</div><div class="line">    visit(tmp);  <span class="comment">// &lt;-- visit when pop</span></div><div class="line"></div><div class="line">    tmp = tmp.right;</div><div class="line">    <span class="keyword">while</span>(tmp != <span class="keyword">null</span>)&#123;</div><div class="line">        s.push(tmp);</div><div class="line">        tmp = tmp.left;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="后序"><a href="#后序" class="headerlink" title="后序"></a>后序</h3><p>后序稍微复杂一些，当一个节点从 stack pop 出来时，意味着 它的左子树已经访问完毕 了，先序和中序此时都可以直接去处理它的右子树；但是后序遍历要求访问完它的右子树后，再访问该节点。</p>
<p>因此对于后序遍历，节点第一次出栈时，必须将其重新入栈，再走后续流程（将右孩子的左路径入栈）；当节点第二次出栈，说明 它的右子树也访问完了，这时才可以访问该节点。所以，对每个节点都必须用一个额外的标志位，记录它是初次还是第二次出栈。</p>
<p>代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">Stack&lt;TreeNode&gt; s = <span class="keyword">new</span> Stack&lt;TreeNode&gt;();</div><div class="line"></div><div class="line"><span class="keyword">while</span>(root != <span class="keyword">null</span>)&#123;</div><div class="line">    s.push(root);</div><div class="line">    root = root.left;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">while</span>(!s.isEmpty())&#123;</div><div class="line">    TreeNode tmp = s.pop();</div><div class="line"></div><div class="line">    <span class="keyword">if</span>(tmp.poped)&#123;          <span class="comment">// 1. 如果是第二次出栈，访问它</span></div><div class="line">        visit(tmp);</div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">        tmp.poped = <span class="keyword">true</span>;   <span class="comment">// 2. 如果是第一次出栈，标记并重新入栈</span></div><div class="line">        s.push(tmp);</div><div class="line"></div><div class="line">        tmp = tmp.right;</div><div class="line">        <span class="keyword">while</span>(tmp != <span class="keyword">null</span>)&#123;</div><div class="line">            s.push(tmp);</div><div class="line">            tmp = tmp.left;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-层序遍历"><a href="#2-层序遍历" class="headerlink" title="2. 层序遍历"></a>2. 层序遍历</h2><p>基本的层序遍历用一个队列，循环出队并将其左右孩子依次入队，比较简单。</p>
<p>如果要区分每一行，则可以用一个标记节点标记一行的结束。遍历的过程中，如果出队的是标记节点，说明已经访问完了一行；此外也意味着这一行的孩子都已入队，标记节点应当重新入队。队列为空时遍历完成。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">TreeNode mark = <span class="keyword">new</span> TreeNode(<span class="number">0</span>);        <span class="comment">// 行末标记</span></div><div class="line"></div><div class="line">LinkedList&lt;TreeNode&gt; q = <span class="keyword">new</span> LinkedList&lt;TreeNode&gt;();</div><div class="line">q.add(root);</div><div class="line">q.add(mark);</div><div class="line"></div><div class="line">List&lt;Integer&gt; row = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</div><div class="line">List&lt;List&lt;Integer&gt;&gt; rows = <span class="keyword">new</span> LinkedList&lt;List&lt;Integer&gt;&gt; ();</div><div class="line"></div><div class="line"><span class="keyword">while</span>(!q.isEmpty())&#123;</div><div class="line">    TreeNode n = q.removeFirst();</div><div class="line"></div><div class="line">    <span class="keyword">if</span>(n == mark)&#123;                  <span class="comment">// 碰到行末标记了</span></div><div class="line">        rows.add(row);              <span class="comment">// 说明访问完了一行</span></div><div class="line">        <span class="keyword">if</span>(q.isEmpty()) <span class="keyword">break</span>;      <span class="comment">// 队列为空则遍历完成</span></div><div class="line">        q.add(mark);                <span class="comment">// 这一行的全部孩子也已入队，将标记节点重新入队</span></div><div class="line">        row = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</div><div class="line">    &#125;<span class="keyword">else</span>&#123;</div><div class="line">        row.add(n.val);</div><div class="line">        <span class="keyword">if</span>(n.left != <span class="keyword">null</span>) q.add(n.left);</div><div class="line">        <span class="keyword">if</span>(n.right != <span class="keyword">null</span>) q.add(n.right);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 二叉树 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[贝叶斯]]></title>
      <url>http://Melodylican.github.io/2014/02/20/%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
      <content type="html"><![CDATA[<h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p>贝叶斯定理是一个关于 <strong>条件概率</strong> 的公式。所谓”条件概率”（Conditional probability），就是指在事件B发生的情况下，事件A发生的概率，用 <em>P**</em>(A|B)** 来表示。<br><a id="more"></a><br>先来看一个问题：</p>
<blockquote>
<p>两个一模一样的碗，一号碗有30颗水果糖和10颗巧克力糖，二号碗有水果糖和巧克力糖各20颗。随机选择一个碗并从中摸一颗糖，求抽到1号碗且摸到的是水果糖的概率。</p>
</blockquote>
<p>如果把 <strong>“抽到1号碗” 称为事件 A，“摸到水果糖” 称为事件 B</strong>，问题即求 A/B 两个事件同时发生的概率<em>P(AB)</em> ，很明显结果等于<font color="red">抽到1号碗的概率 * 抽到1号碗后，在1号碗中摸到水果糖的概率：</font></p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/beyes1.jpg" alt=""><br></center><br>现在换一种问法：<br><br>&gt; 随机选择一个碗，从中摸出一颗糖，发现是水果糖。请问这颗水果糖来自一号碗的概率有多大？<br><br>问题变成了求 事件B（从两个碗中摸到水果糖）发生的前提下，事件A（抽到1号碗）的概率，即条件概率<em>P**</em>(A|B)** 。在之前公式的基础上进行推导：<br><center><br>P(AB)=P(A)XP(B|A)<br>P(BA)=P(B)XP(A|B)<br>P(AB)=P(BA)<br><img src="http://ojwkevhas.bkt.clouddn.com/beyes3.jpg" alt=""><br></center>

<ol>
<li><em>P(A)</em>抽到1号碗的概率</li>
<li><em>P(B)</em> 从两个碗中摸到一个水果糖的概率</li>
<li><em>P(B|A)</em>从1号碗中摸到水果糖的概率，为 0.75<br>假设两个碗是一样的，不考虑摸糖的动作，事件A（即抽到1号碗）的概率<em>P(A)</em>为 0.5，我们把这个概率称为 <strong>先验概率</strong>，即根据经验或其他统计信息得到的一个已知概率。</li>
</ol>
<p><em>P(A|B)</em>，即B发生的前提下，A事件的概率<em>P(A)</em>，被称为 <strong>后验概率</strong>，指的是当我们做了一次实验，或观测到新的更具体的数据（事件B，这里是摸到水果糖）后，对 <strong>先验概率</strong>进行修正。</p>
<p>剩下的问题就是如何求<em>P(B)</em>了，它等于抽到第一个碗且从中摸到一颗水果糖的概率，加上抽到第二个碗且从中摸到一颗水果糖的概率。如果称抽到第一个碗为事件A1，第二个碗为A2，则：</p>
<center><br><em>P(B)=P(A1)P(B|A1)+P(A2)P(B|A2)<br>P(B)=0.5X0.75+0.5X0.5=0.625</em><br></center>

<p>上式亦即所谓的 <strong>全概率公式</strong>。</p>
<p>最后由贝叶斯公式，有： </p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/beyes5.jpg" alt=""><br></center><br>这表明，来自一号碗的概率是0.6。<br><br>我们可以看到一个有趣的现象，如果仅选择碗，选中1号的概率是0.5；一旦摸到一颗水果糖，这个概率立刻被增加到0.6，即 <strong>摸出水果糖这个事件加强了先验概率</strong>。<br><br>## 贝叶斯定理的应用 ##<br><br>贝叶斯定理经常被用来计算：<strong>当观测到某些事实/特征/数据后， 一个推测成立的概率</strong>。<br><br>在实际应用中，事件 B 通常是一个已经发生的，可被观测到的数据，而 A 是我们根据事件B提供的数据提出来的一个猜测（假设），后验概率<strong>P(A|B)</strong> 可以告诉我们这个猜测有多靠谱。如果有很多可能的猜测，对所有猜测都计算一遍后验概率，就能找到最靠谱的那个。<br><br>### 拼写纠正问题 ###<br><br>拼写纠正器需要解决这样一个问题：<br><br>当用户输入一个不存在的单词时，他真正是想输入什么单词呢？<br>我们可以先从词典中找出所有编辑距离为2的单词作为候选单词，但其中哪个单词概率最大呢？在这个问题中，事件 B 是用户已经输入的单词，我们需要找到这样一个单词，使得以下概率最大：<br><center><br><em>p(猜测的单词1|实际输入的单词)</em><br></center>

<p>不妨将我们的多个猜测记为 h1 h2 .. （ h 代表 hypothesis），它们都属于一个有限且离散的猜测空间 H （单词总共就那么多而已），将用户实际输入的单词记为 D （Data ，即观测数据），应用贝叶斯公式：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/beyes6.jpg" alt=""><br></center>

<p>求最佳猜测这种场景中，对所有的猜测而言，<em>P(D)</em>的值都是一定的，我们在比较时可以忽略这个值，得到（符号 ∝ 表示 “正比例于”）：</p>
<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/beyes7.jpg" alt=""><br></center><br>这个结论非常重要，它意味着对于给定观测数据，一个猜测是好是坏，取决于：</p>
<ol>
<li><em>P(h)</em>猜测自身独立成立的可能性， 即猜测的<font color="red"><strong>先验概率</strong></font></li>
<li><em>p(D|h)</em>这个猜测下出现观察到的数据的可能性，又称为<font color="red"><strong>似然 Likelihood</strong></font><br>判断一个猜测的质量，往往就是这两个因素的拉锯。</li>
</ol>
<p>回到问题。对于一个猜测的单词，<font color="red"><strong>先验概率</strong></font> <em>P(h)</em>指用户实际输入的单词是 h 的概率，这由 h 本身在文本中被使用的频繁程度决定。<font color="red"><strong>似然</strong></font><em>P(D|h)</em>  指用户想要输入 h，但却输错成了 D 的概率。比如单词 ‘the’ 就比 ‘thaw’ 更容易被打成 ‘thew’，因为 e 和 a 离得较远而且使用的指头相差一个指头（一个是中指一个是小指，不像 e 和 w 使用的指头靠在一块——神经科学的证据表明紧邻的身体设施之间容易串位）。</p>
<p>对所有的候选单词都计算一下<em>p(h)Xp(D|h)</em>，取最大值，就是最靠谱的猜测。</p>
<h2 id="最大似然-amp-奥卡姆剃刀"><a href="#最大似然-amp-奥卡姆剃刀" class="headerlink" title="最大似然 &amp; 奥卡姆剃刀"></a>最大似然 &amp; 奥卡姆剃刀</h2><p>最大似然：如果两个猜测的先验概率一样，那么越符合观测数据的猜测（即<em>P(D|h)</em>越大）越靠谱；</p>
<p>奥卡姆剃刀：如果两个猜测的似然一样，那么优先选更常见更简单（即<em>P(h)</em>更高）的猜测。</p>
<blockquote>
<p>最大似然还有另一个问题：即便一个猜测与数据非常符合，也并不代表这个猜测就是更好的猜测，因为这个猜测本身的可能性也许就非常低。比如 MacKay 在《Information Theory : Inference and Learning Algorithms》里面就举了一个很好的例子：-1 3 7 11 你说是等差数列更有可能呢？还是 -X^3 / 11 + 9/11*X^2 + 23/11 每项把前项作为 X 带入后计算得到的数列？此外曲线拟合也是，平面上 N 个点总是可以用 N-1 阶多项式来完全拟合，当 N 个点近似但不精确共线的时候，用 N-1 阶多项式来拟合能够精确通过每一个点，然而用直线来做拟合/线性回归的时候却会使得某些点不能位于直线上。你说到底哪个好呢？多项式？还是直线？一般地说肯定是越低阶的多项式越靠谱（当然前提是也不能忽视“似然”P(D | h) ，明摆着一个多项式分布您愣是去拿直线拟合也是不靠谱的，这就是为什么要把它们两者乘起来考虑。），原因之一就是低阶多项式更常见，先验概率（ P(h) ）较大（原因之二则隐藏在 P(D | h) 里面），这就是为什么我们要用样条 来插值，而不是直接搞一个 N-1 阶多项式来通过任意 N 个点的原因。</p>
</blockquote>
<p>以上分析当中隐含的哲学是，观测数据总是会有各种各样的误差，比如观测误差（比如你观测的时候一个 MM 经过你一不留神，手一抖就是一个误差出现了），所以如果过分去寻求能够完美解释观测数据的模型，就会落入所谓的数据过配（overfitting） 的境地，一个过配的模型试图连误差（噪音）都去解释（而实际上噪音又是不需要解释的），显然就过犹不及了。所以 P(D | h) 大不代表你的 h （猜测）就是更好的 h。还要看 P(h) 是怎样的。所谓奥卡姆剃刀 精神就是说：如果两个理论具有相似的解释力度，那么优先选择那个更简单的（往往也正是更平凡的，更少繁复的，更常见的）。</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 贝叶斯 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[线段树]]></title>
      <url>http://Melodylican.github.io/2014/02/18/%E7%BA%BF%E6%AE%B5%E6%A0%91/</url>
      <content type="html"><![CDATA[<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E7%BA%BF%E6%AE%B5%E6%A0%91.png" alt=""><br></center><br><a id="more"></a><br>特点：</p>
<ol>
<li>完全二叉树</li>
<li>每个节点代表一个区间，孩子节点分别代表两个子区间</li>
<li>节点保存着 <strong>该区间内问题的解</strong>，以及求解需要的其他数据<br>用一个数组保存，和 heap 结构类似。</li>
</ol>
<p>分治，要求能够从若干子区间的解推导出父区间的解，且对父区间的更新可以传导给子区间</p>
<p>适用于区间查询 / 区间维护等问题</p>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>线段树支持以下操作：</p>
<ol>
<li>构造</li>
<li>更新 <ul>
<li>单点更新</li>
<li>区间更新</li>
</ul>
</li>
<li>区间查询</li>
</ol>
<p>以区间和问题为例：</p>
<h2 id="构造"><a href="#构造" class="headerlink" title="构造"></a>构造</h2><p>O(N)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">tree = <span class="keyword">None</span></div><div class="line"><span class="comment">#### Utils</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval</span><span class="params">(i)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    由孩子节点计算某节点的 sum</div><div class="line">    """</div><div class="line">    tree[i][<span class="string">'sum'</span>] = tree[lc(i)][<span class="string">'sum'</span>] + tree[rc(i)][<span class="string">'sum'</span>]    </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lc</span><span class="params">(i)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    左孩子</div><div class="line">    """</div><div class="line">    <span class="keyword">return</span> <span class="number">2</span>*(i+<span class="number">1</span>) - <span class="number">1</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rc</span><span class="params">(i)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    右孩子</div><div class="line">    """</div><div class="line">    <span class="keyword">return</span> <span class="number">2</span>*(i+<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">mid</span><span class="params">(i)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    计算节点所代表区间的中间位置</div><div class="line">    """</div><div class="line">    <span class="keyword">return</span> tree[i][<span class="string">'start'</span>] + (tree[i][<span class="string">'end'</span>]-tree[i][<span class="string">'start'</span>])/<span class="number">2</span></div><div class="line"><span class="comment">####</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">init</span><span class="params">(array)</span>:</span></div><div class="line">    <span class="keyword">global</span> tree</div><div class="line"></div><div class="line">    <span class="comment"># 计算线段树节点个数，完全二叉树的节点数 = 2^(height+1) - 1</span></div><div class="line">    length = len(array) <span class="comment"># range length</span></div><div class="line">    height = math.ceil(math.log(length,<span class="number">2</span>)) </div><div class="line">    maxSize = int(math.pow(<span class="number">2</span>,height + <span class="number">1</span>) - <span class="number">1</span>) </div><div class="line"></div><div class="line">    _init(array,<span class="number">0</span>,<span class="number">0</span>,length - <span class="number">1</span>) <span class="comment"># 默认区间为数组下标区间</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_init</span><span class="params">(array,i,s,e)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    构造一棵线段树，节点格式：&#123;start:1,end:2,sum:8&#125;</div><div class="line">    array -- 原始数组</div><div class="line">    i -- 根节点</div><div class="line">    s -- 根节点代表的区间开始处</div><div class="line">    e -- 根节点代表的区间结束处</div><div class="line">    """</div><div class="line">    tree[i] = &#123;<span class="string">'start'</span>:s,<span class="string">'end'</span>:e,<span class="string">'sum'</span>:<span class="keyword">None</span>&#125;</div><div class="line">    <span class="comment">## 如果是原子区间，即叶子节点</span></div><div class="line">    <span class="keyword">if</span> s == e:</div><div class="line">        tree[i][<span class="string">'sum'</span>] = array[s]</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    _init(array, lc(i), s, mid(i))</div><div class="line">    _init(array, rc(i), mid(i) + <span class="number">1</span>, e)</div><div class="line">    eval(i)</div></pre></td></tr></table></figure></p>
<h2 id="单点更新"><a href="#单点更新" class="headerlink" title="单点更新"></a>单点更新</h2><p>O(log2N)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(i,value)</span>:</span>    </div><div class="line">    _update(<span class="number">0</span>,i,value)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_update</span><span class="params">(root,i,value)</span>:</span></div><div class="line">    <span class="comment"># 找到了这个点，更新其sum并返回</span></div><div class="line">    <span class="keyword">if</span> tree[root][<span class="string">'start'</span>] == i <span class="keyword">and</span> tree[root][<span class="string">'end'</span>] == i:</div><div class="line">        tree[root][<span class="string">'sum'</span>] = value</div><div class="line">        <span class="keyword">return</span></div><div class="line">    <span class="keyword">if</span> i&lt;= mid(root):</div><div class="line">        _update(lc(root),i,value)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        _update(rc(root),i,value)</div><div class="line">    eval(root)</div></pre></td></tr></table></figure></p>
<h2 id="区间更新"><a href="#区间更新" class="headerlink" title="区间更新"></a>区间更新</h2><p>O(log2N)</p>
<p>基本思路是将要修改的区间顺着根一层一层往下查找，直到找到一批子区间刚好组成目标区间，再将更新动作应用在这些区间内。比如文章开始的线段树中，如果要更新[1,7]，则可以在树中找到节点[1,5], [6,7]刚好凑成[1,7]，更新这两个区间，重新计算二者祖先节点值即可。</p>
<p>问题是[1,5]并不是叶子节点，如果将以它为根的整个子树全部更新，那么一次更新的动作涉及到的节点就很多了。因此引入延迟更新的思路：</p>
<blockquote>
<p>当更新[1,5]时，只更新该节点，并给它加上一个更新动作的标记，子节点不更新。</p>
<p>查询或修改时，如果碰到了节点[1,5]，并决定进入其子节点考察，为了不访问到错误的值，需要看[1,5]的更新标记，如果有，则将更新动作应用到子节点，并清除自身的标记。子节点的更新则继续 lazy 的思路。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rangeUpdate</span><span class="params">(start,end,value)</span>:</span></div><div class="line">    _rangeUpdate(<span class="number">0</span>,start,end,value)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_rangeUpdate</span><span class="params">(root,start,end,value)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    线段树的区间update，必须满足父区间的update可以传递到左右子区间.</div><div class="line">    -- 即update(a,b)的效果 等价于 update(a,i) &amp; update(i+1,b).</div><div class="line"></div><div class="line">    lazy update后，其子树的data是过时的, 因此 rangeUpdate 和 query 时，在进入孩子节点考察前，必须先将父节点的 update 动作推送给它的左右孩子。</div><div class="line">    """</div><div class="line">    <span class="comment"># 到了某个最大组成子区间，lazy更新并返回</span></div><div class="line">    <span class="keyword">if</span> tree[root][<span class="string">'start'</span>] == start <span class="keyword">and</span> tree[root][<span class="string">'end'</span>] == end:</div><div class="line">        tree[root][<span class="string">'sum'</span>] = (end - start + <span class="number">1</span>) * value</div><div class="line">        tree[root][<span class="string">'update'</span>] = value    <span class="comment"># 标记</span></div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    <span class="comment"># 推送更新动作到子区间</span></div><div class="line">    _pushDownUpdate(root)</div><div class="line"></div><div class="line">    <span class="comment"># 更新子区间</span></div><div class="line">    <span class="keyword">if</span> end &lt;= mid(root):</div><div class="line">        _rangeUpdate(lc(root),start,end,value)</div><div class="line">    <span class="keyword">elif</span> start &gt; mid(root):</div><div class="line">        _rangeUpdate(rc(root),start,end,value)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        _rangeUpdate(lc(root),start,mid(root),value)</div><div class="line">        _rangeUpdate(rc(root),mid(root) + <span class="number">1</span>,end,value)</div><div class="line"></div><div class="line">    <span class="comment"># 子区间更新完毕，重新计算当前节点的值</span></div><div class="line">    eval(root)  </div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_pushDownUpdate</span><span class="params">(parent)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    将update动作传递给孩子</div><div class="line">    """</div><div class="line">    p = tree[parent] <span class="comment"># parent</span></div><div class="line">    <span class="keyword">if</span> <span class="string">'update'</span> <span class="keyword">in</span> p:</div><div class="line">        u = p[<span class="string">'update'</span>]</div><div class="line">        l = tree[lc(parent)] <span class="comment"># left child</span></div><div class="line">        r = tree[rc(parent)] <span class="comment"># right child</span></div><div class="line">        <span class="comment"># 给左右子区间记录update动作</span></div><div class="line">        l[<span class="string">'update'</span>] = r[<span class="string">'update'</span>] = u</div><div class="line">        <span class="comment"># 更新左右子区间</span></div><div class="line">        l[<span class="string">'sum'</span>] = (l[<span class="string">'end'</span>] - l[<span class="string">'start'</span>] + <span class="number">1</span>) * u</div><div class="line">        r[<span class="string">'sum'</span>] = (r[<span class="string">'end'</span>] - r[<span class="string">'start'</span>] + <span class="number">1</span>) * u</div><div class="line">        <span class="comment"># 清除父区间的update动作</span></div><div class="line">        <span class="keyword">del</span> p[<span class="string">'update'</span>]</div></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="区间查询"><a href="#区间查询" class="headerlink" title="区间查询"></a>区间查询</h2><p>O(log2N)</p>
<p>找最大组成子区间，merge结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">query</span><span class="params">(start,end)</span>:</span></div><div class="line">    <span class="keyword">return</span> _query(<span class="number">0</span>,start,end)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_query</span><span class="params">(root,start,end)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    对root的子区间进行查询, [start,end]必须是root所代表的子区间</div><div class="line">    """</div><div class="line">    <span class="comment"># 查询的区间就是root的区间时，直接返回root保存的data</span></div><div class="line">    <span class="keyword">if</span> tree[root][<span class="string">'start'</span>] == start <span class="keyword">and</span> tree[root][<span class="string">'end'</span>] == end:</div><div class="line">        <span class="keyword">return</span> tree[root][<span class="string">'sum'</span>]</div><div class="line"></div><div class="line">    _pushDownUpdate(root)</div><div class="line"></div><div class="line">    <span class="comment"># [start,end]:</span></div><div class="line">    <span class="comment"># 1. 如果在左子区间内，进入左子树</span></div><div class="line">    <span class="keyword">if</span> end &lt;= mid(root):</div><div class="line">        <span class="keyword">return</span> _query(lc(root),start,end)</div><div class="line"></div><div class="line">    <span class="comment"># 2. 如果在右子区间内，进入右子树</span></div><div class="line">    <span class="keyword">if</span> start &gt; mid(root):</div><div class="line">        <span class="keyword">return</span> _query(rc(root),start,end)</div><div class="line"></div><div class="line">    <span class="comment"># 3. 跨越了左右子区间，则将[start,end]拆分为[start,mid] &amp; [mid+1,end]，</span></div><div class="line">    <span class="comment">#    分别进入左右子树查询，并merge这两个区间上的查询结果</span></div><div class="line">    <span class="keyword">return</span> _query(lc(root),start,mid(root)) + _query(rc(root),mid(root) + <span class="number">1</span>,end)</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 线段树 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[桶排序在排行榜中的应用]]></title>
      <url>http://Melodylican.github.io/2014/02/16/%E6%A1%B6%E6%8E%92%E5%BA%8F%E5%9C%A8%E6%8E%92%E8%A1%8C%E6%A6%9C%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      <content type="html"><![CDATA[<h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><ol>
<li>将集合的值的范围分割成n个桶，极端情况下一个值一个桶；</li>
<li>遍历集合，每个值入桶；</li>
<li>桶内用其他方式如快速排序排序。</li>
</ol>
<a id="more"></a>
<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><blockquote>
<p>集合总体取值范围较小的场景</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2></blockquote>
<p>在这种场景中经常使用，一个例子：</p>
<blockquote>
<p>针对陌陌争霸我们是这样做的：</p>
<p>陌陌争霸中用于排名的分数区间不大，也就是 0 分到 5000 分。而参与排名的人数众多，数以百万计。对百万用户做插入排序，每个插入即使是 O(N) 的也不可接受。可事实是大量玩家的分数相同，都是并列排名的。所以我们只需要做 5000 个桶，每个桶里仅记录这个分数有多少个人就可以了。</p>
<p>当玩家分数变迁，把原来的桶减一，新的桶加一。这个操作就是 O(1) 的。</p>
<p>而排行榜的查询仅需要把当前分数靠前的桶累加，就能获知查询者的名次。对于上百万玩家，看到哪些人和你并列的人的名字是没有意义的。这个查询虽然是 O(n) 复杂度，但 n 只有区区 5000 ，还可以做 cache 以应对查询频率远高于更新频率的情况。</p>
<p>真正需要精确知道人名的是榜单的前 200 个人，而对前 200 个人做插入排序也很快，所以并不会造成性能问题。</p>
<p>我们在系统的单点做排行榜的维持，完全没有外部数据库操作，它只是一小段操作普通内存结构的 c 代码。而这个单点远远成为不了整个系统的热点。</p>
<p>我们在系统临时退出时，把已经排好的榜单落地，下次启动的时候恢复。但也不必完全信任落地的数据，可以用离线脚本检索整个数据库重新生成一份正确的榜单。所以数据库中的榜单只是被 cache 起来而已，系统运行期间是不需要写入数据库的，也不用担心数据丢失。</p>
</blockquote>
<p>一个分值一个桶，给一个玩家计算排名时，统计他所在桶之前所有桶的玩家数即可。这不是一个精确的值，因为同分的没有计算在内。</p>
<p>同样的思路也可以用在 <strong>在线时长排名</strong> 等类似场景，只要：</p>
<ol>
<li>集合取值范围不大；</li>
<li>不要求精确，因为不计入得分并列的人数</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 桶排序 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[并查集]]></title>
      <url>http://Melodylican.github.io/2014/02/15/%E5%B9%B6%E6%9F%A5%E9%9B%86/</url>
      <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>树形数据结构，通常用来解决连通集合相关的问题。</p>
<p>一个容量为n的集合，对应的并查集是一个等长数组，a[i] 保存着第i个元素的父节点，这样递归地组成若干棵树，每个树是一个连通集合，树根的父节点指向自己。<br><a id="more"></a></p>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>并查集最基本的两个操作：</p>
<ol>
<li><p>查询元素所在集合<font color="red">findSet(i)</font></p>
<p>从元素 i 向上回溯找树根即可。一个集合由其根元素标识。</p>
</li>
<li><p>合并集合<font color="red">union(i,j)</font>：合并元素 i，j 所在集合</p>
</li>
</ol>
<p>分别找到 i，j 所在集合的根，将其中一个挂在另一个下即可。 </p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%B9%B6%E6%9F%A5%E9%9B%861.png" alt=""><br></center>

<p><strong>初始化：每个元素独立成为一个集合</strong>。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><ol>
<li><p>&lt;font color=”red’&gt;findSet<strong>路径压缩 </strong><br>极端情况下一棵集合树退化成一个链表，此时查找根节点耗时O(n)。&lt;font color=”red’&gt;findSet中可以做这样一个优化：在找到根后，将路上碰到的节点都直接挂在根下，树的高度被压缩成了2，之后的查询都是O(1)的。这是一个扁平化树的过程：</p>
<center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%B9%B6%E6%9F%A5%E9%9B%862.png" alt=""><br></center>
</li>
<li><p><font color="red">union</font> <strong>按集合大小合并</strong><br>合并的时候将元素少的集合合并到元素多的集合中，这样合并之后树的高度会相对较小。</p>
</li>
</ol>
<p>这两个动作都可以认为是O(1)的。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#! /usr/bin/python</span></div><div class="line"><span class="comment"># coding=utf-8</span></div><div class="line"></div><div class="line">raw = [<span class="number">8</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">1</span>,<span class="number">3</span>]</div><div class="line">set = range(len(raw))   <span class="comment"># 并查集 [0,1,2...]</span></div><div class="line">size = [<span class="number">1</span>] * len(raw)   <span class="comment"># 每个集合的大小</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">findSet</span><span class="params">(i)</span>:</span></div><div class="line">    <span class="keyword">if</span> set[i] == i:</div><div class="line">        <span class="keyword">return</span> i</div><div class="line"></div><div class="line">    set[i] = findSet(set[i])</div><div class="line">    <span class="keyword">return</span> set[i]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span><span class="params">(i,j)</span>:</span></div><div class="line">    root1 = findSet(i)</div><div class="line">    size1 = size[root1]</div><div class="line"></div><div class="line">    root2 = findSet(j)</div><div class="line">    size2 = size[root2]</div><div class="line"></div><div class="line">    <span class="keyword">if</span> size1 &gt; size2:       <span class="comment"># 把2挂在1下</span></div><div class="line">        set[root2] = root1</div><div class="line">        size[root1] += size2</div><div class="line">        size[root2] = <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:                   <span class="comment"># 把1挂在2下</span></div><div class="line">        set[root1] = root2</div><div class="line">        size[root2] += size1</div><div class="line">        size[root1] = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="comment"># 测试</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">print</span> size[<span class="number">3</span>],size[<span class="number">5</span>]   <span class="comment"># 1,1</span></div><div class="line">    union(<span class="number">3</span>,<span class="number">2</span>)</div><div class="line">    union(<span class="number">1</span>,<span class="number">2</span>)              </div><div class="line">    union(<span class="number">5</span>,<span class="number">6</span>)</div><div class="line">    <span class="keyword">print</span> findSet(<span class="number">3</span>) == findSet(<span class="number">1</span>), findSet(<span class="number">5</span>) == findSet(<span class="number">6</span>) <span class="comment"># True True</span></div><div class="line">    <span class="keyword">print</span> size[findSet(<span class="number">1</span>)],size[findSet(<span class="number">5</span>)] <span class="comment"># 3,2</span></div><div class="line"></div><div class="line">test()</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 并查集 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[堆排序]]></title>
      <url>http://Melodylican.github.io/2014/02/13/%E5%A0%86%E6%8E%92%E5%BA%8F/</url>
      <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>堆是一个完全二叉树，其中每个节点的值都大于（或小于）其所有孩子节点的值，Top K 问题是堆的一个典型应用。</p>
<p>在很多地方又被称为 优先级队列，JDK 中的PriorityQueue就是基于堆实现的。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>和其他完全二叉树一样，堆通常用一个数组实现，同时用一个变量记录当前堆内元素个数。</p>
<p>对元素 i，它的左孩子和右孩子分别为 2i+1，2i+2，它的父节点为(i-1)/2向下取整。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">int[] heap;</div><div class="line">int heapLength;</div><div class="line"></div><div class="line">// helper funcs for parent/left child/right child fast access</div><div class="line">Integer parent(int i)&#123;return (i-1)/2 &gt;= 0 ? (i-1)/2 : null;&#125;</div><div class="line">Integer left(int i)&#123;return (2*i + 1) &lt;= heapLength - 1? (2*i + 1) : null;&#125;</div><div class="line">Integer right(int i)&#123;return (2*i + 2) &lt;= heapLength - 1? (2*i + 2) : null;&#125;</div></pre></td></tr></table></figure></p>
<p>堆常见的操作有：</p>
<ol>
<li>init：用一个集合初始化堆</li>
<li>removeTop：删除堆顶</li>
<li>replaceTop：用一个元素代替堆顶，并返回原堆顶<br>堆也支持元素的增加、更新、删除等操作，但用的不多。</li>
</ol>
<p>下面的讲解都是以小顶堆为例。</p>
<h2 id="sink-和-float"><a href="#sink-和-float" class="headerlink" title="sink 和 float"></a>sink 和 float</h2><p>sink和float是调整堆的两个核心动作。对于一个已经构造好了的对，当某个元素变大了，它需要往下下沉到合适的位置；反之则要上浮。</p>
<p>sink 的递归实现如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">void sink(int i)&#123;</div><div class="line">    Integer left = left(i),right = right(i);</div><div class="line"></div><div class="line">    // 叶子节点，结束 sink 动作</div><div class="line">    if(left == null &amp;&amp; right == null) return;   </div><div class="line"></div><div class="line">    // 如果只有左孩子且比它大，则交换二者的值，并继续 sink</div><div class="line">    if(left != null &amp;&amp; right == null &amp;&amp; heap[i] &gt; heap[left]) &#123;</div><div class="line">        swap(i,left);</div><div class="line">        sink(left);</div><div class="line">        return;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // 如果同时有左右孩子，则跟较小的孩子比较，如果比它大，则交换并继续 sink</div><div class="line">    if(left != null &amp;&amp; right != null)&#123;</div><div class="line">        int min = heap[left] &lt; heap[right] ? left:right;</div><div class="line">        if(heap[i] &gt; heap[min])&#123;</div><div class="line">            swap(i,min);</div><div class="line">            sink(min);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>float 的逻辑类似。</p>
<p>二者的时间复杂度都是 O(logN)。</p>
<h2 id="init"><a href="#init" class="headerlink" title="init"></a>init</h2><p>从最后一个非叶子节点开始到根节点，依次对其调用sink()调整堆即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">void initHeap()&#123;</div><div class="line">    <span class="keyword">for</span>(int i = parent(heapLength - <span class="number">1</span>); i&gt;=<span class="number">0</span> ; i--)&#123;</div><div class="line">        sink(i);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="removeTop"><a href="#removeTop" class="headerlink" title="removeTop"></a>removeTop</h2><p>用最后一个元素代替当前堆顶，并对其用sink()调整堆：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">int removeTop()&#123;</div><div class="line">    int top = heap[<span class="number">0</span>];</div><div class="line">    heap[<span class="number">0</span>] = heap[heapLength<span class="number">-1</span>];</div><div class="line">    heapLength -= <span class="number">1</span>;</div><div class="line">    sink(<span class="number">0</span>);</div><div class="line">    <span class="keyword">return</span> top;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>replaceTop</p>
<p>用指定元素代替当前堆顶，再调用sink()：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">int replaceTop(int n)&#123;</div><div class="line">    int top = heap[<span class="number">0</span>];</div><div class="line">    heap[<span class="number">0</span>] = n;</div><div class="line">    sink(<span class="number">0</span>);</div><div class="line">    <span class="keyword">return</span> top;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="add"><a href="#add" class="headerlink" title="add"></a>add</h2><p>将元素加入数组最末，并用float()将其上浮到合适位置。</p>
<h2 id="update"><a href="#update" class="headerlink" title="update"></a>update</h2><p>将新值和旧值比较，决定是用float()还是sink()调整堆。</p>
<h2 id="delete"><a href="#delete" class="headerlink" title="delete"></a>delete</h2><p>将堆的最后一个元素放到该位置，再通过float / sink调整堆。</p>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 堆排序 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[快速排序]]></title>
      <url>http://Melodylican.github.io/2014/01/10/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/</url>
      <content type="html"><![CDATA[<h2 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h2><p>怎么写一个正确的快速排序？</p>
<p><font color="red">sort()</font>方法很简单：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(<span class="keyword">int</span>[] num,<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span>&#123;</div><div class="line">    <span class="keyword">if</span>(start &gt;= end) <span class="keyword">return</span>;</div><div class="line"></div><div class="line">    <span class="keyword">int</span> i = partition(num,start,end);</div><div class="line">    sort(num,start, i - <span class="number">1</span>);</div><div class="line">    sort(num,i+<span class="number">1</span>,end);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<a id="more"></a>
<p>主要的难点在<font color="red">partition()</font>方法。假定选定第一个元素为 pivot，且一次 partition 后数组分为两部分，左侧&lt;font color=”red’&gt;&lt;= pivot，右侧<font color="red"> &gt;= </font>pivot。</p>
<p>首先考虑一般情况。根据算法，我们需要两个指针 i/j 初始指向数组的两端，i 之前的元素 &lt;= pivot，j 之后的元素 &gt;= pivot。两个指针均向中间移动，直到找到第一个不符合条件的元素。二者均停止时，交换 i/j 指针指向的元素，并重复这个过程。</p>
<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F1.png" alt=""><br></center><br>很快可以写出算法的主要框架：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span>(...)&#123;</div><div class="line">    <span class="keyword">while</span>(a[i] &lt;= pivot) i++;</div><div class="line">    <span class="keyword">while</span>(a[j] &gt;= pivot) j--;</div><div class="line">    swap(a,i,j);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>循环写出来了，自然要考虑什么时候停下来。稍微推演可知，当 i/j 两个指针穷尽了各自的区间时应当停止循环，此时 i和j 是个 交错的状态，i 指向 &gt;= 区域的第一个元素，j 指向 &lt;= 区域的最后一个元素，如下所示：</p>
<p><center><br><img src="http://ojwkevhas.bkt.clouddn.com/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F2.png" alt=""><br></center><br>这时不能再交换 i/j 上的元素，而应将 pivot 移动到 j 处，并 return 该位置；至此一次 partition 就完成了。把这些想法加上，代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span>(i&lt;j)&#123;</div><div class="line">    <span class="keyword">while</span>(a[i] &lt;= pivot) i++;   <span class="comment">// 1</span></div><div class="line">    <span class="keyword">while</span>(a[j] &gt;= pivot) j--;    <span class="comment">// 2</span></div><div class="line">    <span class="keyword">if</span>(i&lt;j)</div><div class="line">        swap(a,i,j);</div><div class="line">&#125;</div><div class="line">swap(a,start,j);</div><div class="line"></div><div class="line"><span class="keyword">return</span> j;</div></pre></td></tr></table></figure></p>
<p>上述 1/2 处的循环看起来很有数组越界的危险，而事实也是如此。用几个 edge case 考察下，假设所有元素都 &lt;= pivot，很明显循环1会越界，因此这里需要加上对边界的判断；当数组除 pivot 之外的元素都 &gt; pivot 时，循环2也是一样的情况。这两个越界问题都可以通过 i&lt;=j 这个判断解决。注意要加上等号，否则 i/j 不会交错，逻辑错误。</p>
<p>用 edge case 对其他逻辑测试下都没问题，因此加上数组越界的防范就够了；最后<font color="red">partition()</font>的完整代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">partition</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span>&#123;</div><div class="line">    <span class="keyword">int</span> i = start, j = end, pivot = a[start];</div><div class="line"></div><div class="line">    <span class="keyword">while</span>(i &lt; j)&#123;</div><div class="line">        <span class="keyword">while</span>(i &lt;= j &amp;&amp; a[i] &lt;= pivot) i++;   <span class="comment">// 加上越界判断</span></div><div class="line">        <span class="keyword">while</span>(i &lt;= j &amp;&amp; a[j] &gt;= pivot) j--;   <span class="comment">// 加上越界判断</span></div><div class="line">        <span class="keyword">if</span>(i &lt; j)&#123;</div><div class="line">            swap(a,i,j);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    swap(a,start,j);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> j;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>从这个过程总结一下平常写（算法）代码的思路：</p>
<ol>
<li>根据抽象流程定下算法框架；</li>
<li>考虑循环（或递归）何时结束，结束时的处理方式；</li>
<li>用 edge case 测试代码，修正如数组越界 / 空指针异常等错误。<br>总体而言是个从抽象到细节的过程。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> 快速排序 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第四章 Spring-MVC初体验]]></title>
      <url>http://Melodylican.github.io/2012/07/18/spring%E7%AC%AC%E5%9B%9B%E7%AB%A0/</url>
      <content type="html"><![CDATA[<div class="note success"><h2 id="第四章-Spring-MVC初体验"><a href="#第四章-Spring-MVC初体验" class="headerlink" title="第四章 Spring-MVC初体验"></a>第四章 Spring-MVC初体验</h2></div>
<p>接下来我们将利用<strong>Spring-MVC</strong>构建一个简单的web应用<br><br><strong>1.</strong> 首先，我们通过<strong>Maven</strong>来构建一个web应用的工程<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Maven构建工程命令：</div><div class="line">	mvn archetype:generate -DgroupId=imooc-arthur -DartifactId=spring-mvc-study -DarchetypeArtifactId=maven-archetype-webapp</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<p><strong>2.</strong> 配置<strong>Maven</strong>编译工程所依赖的工程或者文件<strong>pom.xml</strong><br><br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line">pom.xml</div><div class="line">    &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"</div><div class="line">	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;</div><div class="line">	&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line">	&lt;groupId&gt;xxxx&lt;/groupId&gt;</div><div class="line">	&lt;artifactId&gt;spring-mvc-study&lt;/artifactId&gt;</div><div class="line">	&lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;</div><div class="line"></div><div class="line">	&lt;properties&gt;</div><div class="line">		&lt;commons-lang.version&gt;2.6&lt;/commons-lang.version&gt;</div><div class="line">		&lt;slf4j.version&gt;1.7.6&lt;/slf4j.version&gt;</div><div class="line">		&lt;spring.version&gt;4.1.3.RELEASE&lt;/spring.version&gt;</div><div class="line">        &lt;jackson.version&gt;2.5.4&lt;/jackson.version&gt;</div><div class="line">	&lt;/properties&gt;</div><div class="line"></div><div class="line"></div><div class="line">	&lt;dependencyManagement&gt;</div><div class="line">		&lt;dependencies&gt;</div><div class="line">			&lt;dependency&gt;</div><div class="line">				&lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">				&lt;artifactId&gt;spring-framework-bom&lt;/artifactId&gt;</div><div class="line">				&lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;</div><div class="line">				&lt;type&gt;pom&lt;/type&gt;</div><div class="line">				&lt;scope&gt;import&lt;/scope&gt;</div><div class="line">			&lt;/dependency&gt;</div><div class="line">		&lt;/dependencies&gt;</div><div class="line">	&lt;/dependencyManagement&gt;</div><div class="line"></div><div class="line">	&lt;dependencies&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;commons-lang&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;commons-lang&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;$&#123;commons-lang.version&#125;&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;org.slf4j&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;</div><div class="line">			&lt;exclusions&gt;</div><div class="line">				&lt;exclusion&gt;</div><div class="line">					&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;</div><div class="line">					&lt;groupId&gt;org.slf4j&lt;/groupId&gt;</div><div class="line">				&lt;/exclusion&gt;</div><div class="line">			&lt;/exclusions&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;org.slf4j&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;javax.servlet&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;servlet-api&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;2.5&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;commons-fileupload&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;1.3.1&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">	&lt;/dependencies&gt;</div><div class="line"></div><div class="line">	&lt;build&gt;</div><div class="line">		&lt;plugins&gt;</div><div class="line">			&lt;plugin&gt;</div><div class="line">				&lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt;</div><div class="line">				&lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt;</div><div class="line">				&lt;version&gt;9.2.2.v20140723&lt;/version&gt;</div><div class="line">			&lt;/plugin&gt;</div><div class="line">		&lt;/plugins&gt;</div><div class="line">	&lt;/build&gt;</div><div class="line"></div><div class="line">	&lt;packaging&gt;war&lt;/packaging&gt;</div><div class="line">    &lt;/project&gt;</div></pre></td></tr></table></figure></p>
<p><strong>3.</strong> 在<strong>Maven</strong>创建的工程中<strong>web.xml</strong>文件中增加<strong>spring-mvc</strong><br><br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">web.xml</div><div class="line">	&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line">	&lt;web-app version="2.4" xmlns="http://java.sun.com/xml/ns/j2ee"</div><div class="line">	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"</div><div class="line">	xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee </div><div class="line">	http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd"&gt;</div><div class="line">  		&lt;display-name&gt;Spring MVC Study&lt;/display-name&gt;</div><div class="line">  		&lt;!-- Spring应用上下文， 理解层次化的ApplicationContext --&gt;</div><div class="line">  		&lt;context-param&gt;</div><div class="line"> 			&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;</div><div class="line">			&lt;param-value&gt;/WEB-INF/configs/spring/applicationContext*.xml&lt;/param-value&gt;</div><div class="line">  		&lt;/context-param&gt;</div><div class="line">  </div><div class="line">  		&lt;listener&gt;</div><div class="line">			&lt;listener-class&gt;</div><div class="line">				org.springframework.web.context.ContextLoaderListener</div><div class="line">			&lt;/listener-class&gt;</div><div class="line">  		&lt;/listener&gt;</div><div class="line">  </div><div class="line">  		&lt;!-- DispatcherServlet, Spring MVC的核心 --&gt;</div><div class="line">  		&lt;servlet&gt;</div><div class="line">			&lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt;</div><div class="line">			&lt;servlet-class&gt; org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;</div><div class="line">			&lt;!-- DispatcherServlet对应的上下文配置， 默认为/WEB-INF/$servlet-name$-servlet.xml--&gt;</div><div class="line">			&lt;init-param&gt;</div><div class="line">          		&lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;</div><div class="line">          		&lt;param-value&gt;/WEB-INF/configs/spring/mvc-dispatcher-servlet.xml&lt;/param-value&gt;</div><div class="line">        	&lt;/init-param&gt;</div><div class="line">			&lt;load-on-startup&gt;1&lt;/load-on-startup&gt;</div><div class="line">		&lt;/servlet&gt;</div><div class="line">		&lt;servlet-mapping&gt;</div><div class="line">			&lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt;</div><div class="line">	    	&lt;!-- mvc-dispatcher拦截所有的请求--&gt;</div><div class="line">			&lt;url-pattern&gt;/&lt;/url-pattern&gt;</div><div class="line">		&lt;/servlet-mapping&gt;</div><div class="line">	&lt;/web-app&gt;</div></pre></td></tr></table></figure></p>
<p><strong>4.</strong> 接下来开始完成<strong>Spring-MVC</strong>框架中的的 <strong>M,V,C</strong>各个模块的代码【在这里只展示<strong>C</strong>部分的代码和相关配置文件，其它部分详见工程代码展示】<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">CourseController.java</div><div class="line">	<span class="meta">@Controller</span></div><div class="line">	<span class="meta">@RequestMapping</span>(<span class="string">"/courses"</span>)</div><div class="line">	<span class="comment">// /courses/**</span></div><div class="line">	<span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CourseController</span> </span>&#123;</div><div class="line">	</div><div class="line">		<span class="keyword">private</span> <span class="keyword">static</span> Logger log = LoggerFactory.getLogger(CourseController.class);</div><div class="line">		<span class="keyword">private</span> CourseService courseService;</div><div class="line"></div><div class="line">		<span class="meta">@Autowired</span></div><div class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCourseService</span><span class="params">(CourseService courseService)</span> </span>&#123;</div><div class="line">			<span class="keyword">this</span>.courseService = courseService;</div><div class="line">		&#125;</div><div class="line">	</div><div class="line">		<span class="comment">//本方法将处理 /courses/view?courseId=123 形式的URL</span></div><div class="line">		<span class="meta">@RequestMapping</span>(value=<span class="string">"/view"</span>, method=RequestMethod.GET)</div><div class="line">		<span class="function"><span class="keyword">public</span> String <span class="title">viewCourse</span><span class="params">(@RequestParam(<span class="string">"courseId"</span>)</span> Integer courseId,</span></div><div class="line">			Model model) &#123;</div><div class="line">		</div><div class="line">			log.debug(<span class="string">"In viewCourse, courseId = &#123;&#125;"</span>, courseId);</div><div class="line">			Course course = courseService.getCoursebyId(courseId);</div><div class="line">			model.addAttribute(course);</div><div class="line">			<span class="keyword">return</span> <span class="string">"course_overview"</span>;</div><div class="line">		&#125;</div><div class="line">	</div><div class="line">		<span class="comment">//本方法将处理 /courses/view2/123 形式的URL</span></div><div class="line">		<span class="meta">@RequestMapping</span>(<span class="string">"/view2/&#123;courseId&#125;"</span>)</div><div class="line">		<span class="function"><span class="keyword">public</span> String <span class="title">viewCourse2</span><span class="params">(@PathVariable(<span class="string">"courseId"</span>)</span> Integer courseId,</span></div><div class="line">			Map&lt;String, Object&gt; model) &#123;</div><div class="line">		</div><div class="line">			log.debug(<span class="string">"In viewCourse2, courseId = &#123;&#125;"</span>, courseId);</div><div class="line">			Course course = courseService.getCoursebyId(courseId);</div><div class="line">			model.put(<span class="string">"course"</span>,course);</div><div class="line">			<span class="keyword">return</span> <span class="string">"course_overview"</span>;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		<span class="comment">//本方法将处理 /courses/view3?courseId=123 形式的URL</span></div><div class="line">		<span class="meta">@RequestMapping</span>(<span class="string">"/view3"</span>)</div><div class="line">		<span class="function"><span class="keyword">public</span> String <span class="title">viewCourse3</span><span class="params">(HttpServletRequest request)</span> </span>&#123;</div><div class="line">		</div><div class="line">			Integer courseId = Integer.valueOf(request.getParameter(<span class="string">"courseId"</span>));		</div><div class="line">			Course course = courseService.getCoursebyId(courseId);</div><div class="line">			request.setAttribute(<span class="string">"course"</span>,course);</div><div class="line">			<span class="keyword">return</span> <span class="string">"course_overview"</span>;</div><div class="line">		&#125;</div><div class="line">	</div><div class="line">		<span class="meta">@RequestMapping</span>(value=<span class="string">"/admin"</span>, method = RequestMethod.GET, params = <span class="string">"add"</span>)</div><div class="line">		<span class="function"><span class="keyword">public</span> String <span class="title">createCourse</span><span class="params">()</span></span>&#123;</div><div class="line">			<span class="keyword">return</span> <span class="string">"course_admin/edit"</span>;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		<span class="meta">@RequestMapping</span>(value=<span class="string">"/save"</span>, method = RequestMethod.POST)</div><div class="line">		<span class="function"><span class="keyword">public</span> String  <span class="title">doSave</span><span class="params">(@ModelAttribute Course course)</span></span>&#123;		</div><div class="line">			</div><div class="line">			log.debug(<span class="string">"Info of Course:"</span>);</div><div class="line">			log.debug(ReflectionToStringBuilder.toString(course));</div><div class="line">			</div><div class="line">			<span class="comment">//在此进行业务操作，比如数据库持久化</span></div><div class="line">			course.setCourseId(<span class="number">123</span>);</div><div class="line">			<span class="keyword">return</span> <span class="string">"redirect:view2/"</span>+course.getCourseId();</div><div class="line">		&#125;</div><div class="line">	&#125;</div></pre></td></tr></table></figure></p>
<p><strong>5.</strong> mvc-dispatcher-servlet.xml文件的配置<br><br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line">mvc-dispatcher-servlet.xml</div><div class="line"></div><div class="line">&lt;!-- 本配置文件是工名为mvc-dispatcher的DispatcherServlet使用， 提供其相关的Spring MVC配置 --&gt;</div><div class="line"></div><div class="line">	&lt;!-- 启用Spring基于annotation的DI, 使用户可以在Spring MVC中使用Spring的强大功能。 激活 @Required </div><div class="line">		@Autowired,JSR 250's @PostConstruct, @PreDestroy and @Resource 等标注 --&gt;</div><div class="line">	&lt;context:annotation-config /&gt;</div><div class="line"></div><div class="line">	&lt;!-- DispatcherServlet上下文， 只管理@Controller类型的bean， 忽略其他型的bean, 如@Service --&gt;</div><div class="line">	&lt;context:component-scan base-package="com.imooc.mvcdemo"&gt;</div><div class="line">		&lt;context:include-filter type="annotation"</div><div class="line">			expression="org.springframework.stereotype.Controller" /&gt;</div><div class="line">	&lt;/context:component-scan&gt;</div><div class="line"></div><div class="line">	&lt;!-- HandlerMapping, 无需配置， Spring MVC可以默认启动。 DefaultAnnotationHandlerMapping </div><div class="line">		annotation-driven HandlerMapping --&gt;</div><div class="line"></div><div class="line">	&lt;!-- 扩充了注解驱动，可以将请求参数绑定到控制器参数 --&gt;</div><div class="line">	&lt;mvc:annotation-driven /&gt;</div><div class="line"></div><div class="line">	&lt;!-- 静态资源处理， css， js， imgs --&gt;</div><div class="line">	&lt;mvc:resources mapping="/resources/**" location="/resources/" /&gt;</div><div class="line"></div><div class="line"></div><div class="line">	&lt;!-- 配置ViewResolver。 可以用多个ViewResolver。 使用order属性排序。 InternalResourceViewResolver放在最后。 --&gt;</div><div class="line">	&lt;bean</div><div class="line">		class="org.springframework.web.servlet.view.ContentNegotiatingViewResolver"&gt;</div><div class="line">		&lt;property name="order" value="1" /&gt;</div><div class="line">		&lt;property name="mediaTypes"&gt;</div><div class="line">			&lt;map&gt;</div><div class="line">				&lt;entry key="json" value="application/json" /&gt;</div><div class="line">				&lt;entry key="xml" value="application/xml" /&gt;</div><div class="line">				&lt;entry key="htm" value="text/html" /&gt;</div><div class="line">			&lt;/map&gt;</div><div class="line">		&lt;/property&gt;</div><div class="line"></div><div class="line">		&lt;property name="defaultViews"&gt;</div><div class="line">			&lt;list&gt;</div><div class="line">				&lt;!-- JSON View --&gt;</div><div class="line">				&lt;bean</div><div class="line">					class="org.springframework.web.servlet.view.json.MappingJackson2JsonView"&gt;</div><div class="line">				&lt;/bean&gt;</div><div class="line">			&lt;/list&gt;</div><div class="line">		&lt;/property&gt;</div><div class="line">		&lt;property name="ignoreAcceptHeader" value="true" /&gt;</div><div class="line">	&lt;/bean&gt;</div><div class="line"></div><div class="line">	&lt;bean</div><div class="line">		class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt;</div><div class="line">		&lt;property name="viewClass"</div><div class="line">			value="org.springframework.web.servlet.view.JstlView" /&gt;</div><div class="line">		&lt;property name="prefix" value="/WEB-INF/jsps/" /&gt;</div><div class="line">		&lt;property name="suffix" value=".jsp" /&gt;</div><div class="line">	&lt;/bean&gt;</div><div class="line"></div><div class="line"></div><div class="line">	&lt;!--200*1024*1024即200M resolveLazily属性启用是为了推迟文件解析，以便捕获文件大小异常 --&gt;</div><div class="line">	&lt;bean id="multipartResolver"</div><div class="line">		class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt;</div><div class="line">		&lt;property name="maxUploadSize" value="209715200" /&gt;</div><div class="line">		&lt;property name="defaultEncoding" value="UTF-8" /&gt;</div><div class="line">		&lt;property name="resolveLazily" value="true" /&gt;</div><div class="line">	&lt;/bean&gt;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第三章 Spring-MVC]]></title>
      <url>http://Melodylican.github.io/2012/07/05/spring%E7%AC%AC%E4%B8%89%E7%AB%A0/</url>
      <content type="html"><![CDATA[<div class="note success"><h2 id="第三章-Spring-MVC"><a href="#第三章-Spring-MVC" class="headerlink" title="第三章 Spring-MVC"></a>第三章 Spring-MVC</h2></div>
<p><strong>Spring Web MVC</strong>框架也是一个基于请求驱动的Web框架，并且也使用了 <font color="#FF3030">前端控制器模式</font>来进行设计，再根据请求映射规则分发给相应的页面控制器（动作/处理器）进行处理。首先让我们整体看一下<strong>Spring Web MVC处</strong>理请求的流程：<br><a id="more"></a><br>核心架构的具体流程步骤如下：</p>
<p><center><br><img src="http://i.imgur.com/VS5Plrc.png" alt=""></center><br>1、  首先用户发送请求——&gt;<font color="#FF3030">DispatcherServlet</font>，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；<br><br>2、  DispatcherServlet——&gt;HandlerMapping， <font color="#FF3030">HandlerMapping</font>将会把请求映射为<font color="#FF3030">HandlerExecutionChain</font>对象（包含一个Handler处理器（页面控制器）对象、多个HandlerInterceptor拦截器）对象，通过这种策略模式，很容易添加新的映射策略；<br><br>3、  DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；<br><br>4、  HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView对象（包含模型数据、逻辑视图名）；<br><br>5、  ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；<br><br>6、  View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；<br><br>7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。<br></p>
<p>此处我们只是讲了核心流程，没有考虑拦截器、本地解析、文件上传解析等。<br></p>
<right><font color="grey" size="2">资料整理来自：<a><a href="http://jinnianshilongnian.iteye.com/blog/1594806" target="_blank" rel="external">http://jinnianshilongnian.iteye.com/blog/1594806</a></a></font></right>


]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring MVC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第二章 Spring依赖注入]]></title>
      <url>http://Melodylican.github.io/2012/06/22/spring%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
      <content type="html"><![CDATA[<div class="note success"><h2 id="第二章-Spring依赖注入"><a href="#第二章-Spring依赖注入" class="headerlink" title="第二章 Spring依赖注入"></a>第二章 Spring依赖注入</h2></div>
<p><strong>spring</strong>框架为我们提供了三种注入方式，分别是 <font color="#FF3030">set</font> 注入，<font color="#FF3030">构造方法</font>注入，<font color="#FF3030">接口</font>注入。接口注入不作要求，下面介绍前两种方式。<br><a id="more"></a></p>
<ol>
<li><strong>set注入</strong><br>采用属性的<font color="#FF3030">set</font>方法进行初始化，就称为<font color="#FF3030">set</font>注入。<br>(1)给普通字符类型赋值<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">User.java</div><div class="line">     <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;  </div><div class="line">         <span class="keyword">private</span> String username;  </div><div class="line">         <span class="function"><span class="keyword">public</span> String <span class="title">getUsername</span><span class="params">()</span> </span>&#123;  </div><div class="line">             <span class="keyword">return</span> username;  </div><div class="line">         &#125;  </div><div class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsername</span><span class="params">(String username)</span> </span>&#123;  </div><div class="line">             <span class="keyword">this</span>.username= username;  </div><div class="line">         &#125;  </div><div class="line">    &#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>我们只需要提供属性的 <font color="#FF3030">set</font> 方法，然后去属性文件中去配置好让框架能够找到 <font color="#FF3030">applicationContext.xml</font> 文件的<font color="#FF3030">beans</font>标签。标签 <font color="#FF3030">beans</font>中添加<font color="#FF3030">bean</font>标签， 指定<font color="#FF3030">id</font>，<font color="#FF3030">class</font>值，<font color="#FF3030">id</font>值不做要求，<font color="#FF3030">class</font>值为对象所在的完整路径。<font color="#FF3030">bean</font>标签再添加 <font color="#FF3030">property</font> 标签，要求，<font color="#FF3030">name</font> 值与 <font color="#FF3030">User</font>类中对应的属性名称一致。<font color="#FF3030">value</font>值就是我们要给<font color="#FF3030">User</font>类中的<font color="#FF3030">username</font>属性赋的值。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">applicationContext.xml</div><div class="line">    &lt;bean id="userAction"class="com.dsky.spring.action.User" &gt;  </div><div class="line">         &lt;property name="username" value="admin"&gt;&lt;/property&gt;  </div><div class="line">    &lt;/bean&gt;</div><div class="line">``` </div><div class="line">(2)给对象赋值</div><div class="line"></div><div class="line">``` java</div><div class="line">User.java</div><div class="line">    public class User &#123;  </div><div class="line">        private UserService userservice;  </div><div class="line">        public void setUserservice(UserService userservice) &#123;  </div><div class="line">            this.userservice= userservice;  </div><div class="line">        &#125;  </div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">applicationContext.xml</div><div class="line">    &lt;!--对象的声明--&gt;  </div><div class="line">    &lt;bean id="userService" class="com.dsky.spring.service.UserService"&gt;&lt;/bean&gt;  </div><div class="line">       </div><div class="line">    &lt;bean id="userAction"class="com.idreamsky.spring.action.User" &gt;  </div><div class="line">       &lt;property name="userservice" ref="userService"&gt;&lt;/property&gt;  </div><div class="line">    &lt;/bean&gt;</div></pre></td></tr></table></figure>
<p>(3)给List集合赋值<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">User.java</div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span></span>&#123;  </div><div class="line">        <span class="keyword">private</span> List&lt;String&gt; username;  </div><div class="line">         <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUsername</span><span class="params">(List&lt;String&gt; username)</span> </span>&#123;  </div><div class="line">            <span class="keyword">this</span>.username= username;  </div><div class="line">        &#125;  </div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">applicationContext.xml</div><div class="line">    &lt;bean id="userAction"class="com.dsky.spring.action.User" &gt;  </div><div class="line">       &lt;propertynamepropertyname="username"&gt;  </div><div class="line">          &lt;list&gt;  </div><div class="line">            &lt;value&gt;zhang,san&lt;/value&gt;  </div><div class="line">            &lt;value&gt;lisi&lt;/value&gt;  </div><div class="line">            &lt;value&gt;wangwu&lt;/value&gt;  </div><div class="line">        &lt;/list&gt;  </div><div class="line">     &lt;/property&gt;  </div><div class="line">    &lt;/bean&gt;</div></pre></td></tr></table></figure>
<p>(4)给属性文件中的字段赋值<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">User.java</div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span></span>&#123;  </div><div class="line">        <span class="keyword">private</span> Properties props ;  </div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProps</span><span class="params">(Properties props)</span> </span>&#123;  </div><div class="line">            <span class="keyword">this</span>.props= props;  </div><div class="line">        &#125;  </div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">applicationContext.xml</div><div class="line">    &lt;bean&gt;  </div><div class="line">        &lt;propertynamepropertyname="props"&gt;  </div><div class="line">            &lt;props&gt;  </div><div class="line">                &lt;propkey="url"&gt;jdbc:oracle:thin:@localhost:orl&lt;/prop&gt;  </div><div class="line">                &lt;propkey="driverName"&gt;oracle.jdbc.driver.OracleDriver&lt;/prop&gt;  </div><div class="line">                &lt;propkey="username"&gt;scott&lt;/prop&gt;  </div><div class="line">                &lt;propkey="password"&gt;tiger&lt;/prop&gt;  </div><div class="line">           &lt;/props&gt;  </div><div class="line">        &lt;/property&gt;  </div><div class="line">    &lt;/bean&gt;</div></pre></td></tr></table></figure>
<p><prop>标签中的 <font color="#FF3030">key</font>值是 <font color="#FF3030">.properties</font>属性文件中的名称。<br><br><strong><font color="red">[注意]</font></strong>：无论给什么赋值，配置文件中<property>标签的 <font color="#FF3030">name</font>属性值一定是和对象中名称一致。  </property></prop></p>
<ol>
<li>构造方法的注入<br>(1)构造方法只有一个参数时<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">User.java</div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">User</span></span>&#123;  </div><div class="line">        <span class="keyword">private</span> String usercode;  </div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(String usercode)</span> </span>&#123;  </div><div class="line">            <span class="keyword">this</span>.usercode=usercode;  </div><div class="line">        &#125;  </div><div class="line">    &#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">applicationContext.xml</div><div class="line">    &lt;bean id="userAction"class="com.dsky.spring.action.User"&gt;                          </div><div class="line">        &lt;constructor-arg value="admin"&gt;&lt;/constructor-arg&gt;                          </div><div class="line">    &lt;/bean&gt;</div></pre></td></tr></table></figure>
<p>(2)构造方法只有两个参数时<br>当参数为非字符串类型时，在配置文件中需要指定类型，如果不指定类型一律按照字符串类型赋值。<br>当参数类型不一致时，框架是按照字符串的类型进行查找的，因此需要在配置文件中指定是参数的位置 。</p>
<pre><code class="java">&lt;constructor-arg value="admin"index="0"&gt;&lt;/constructor-arg&gt;  
&lt;constructor-arg value="23" type="int"index="1"&gt;&lt;/constructor-arg&gt;
</code></pre>
<right><font color="grey" size="2">资料整理来自：<a><a href="http://blog.csdn.net/lishuangzhe7047/article/details/20740835" target="_blank" rel="external">http://blog.csdn.net/lishuangzhe7047/article/details/20740835</a></a></font></right>


]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
            <tag> Spring IOC </tag>
            
            <tag> Spring POI </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第一章 Spring基础知识]]></title>
      <url>http://Melodylican.github.io/2012/06/12/spring%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
      <content type="html"><![CDATA[<div class="note success"><h2 id="第一章-Spring基础知识"><a href="#第一章-Spring基础知识" class="headerlink" title="第一章 Spring基础知识"></a>第一章 Spring基础知识</h2></div>
<p><strong>Spring</strong>  是一个开源框架，是为了解决企业应用程序开发复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许您选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架。<br><a id="more"></a></p>
<h3 id="Spring-框架"><a href="#Spring-框架" class="headerlink" title="Spring 框架"></a>Spring 框架</h3><p><strong>Spring</strong> 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式，如图 1 所示。<br>图 1. Spring 框架的 7 个模块</p>
<p><center><br><img src="http://i.imgur.com/qYbhAoC.gif" alt=""><br></center><br>组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。每个模块的功能如下： </p>
<ul>
<li><strong>核心容器</strong>：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转 （IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。</li>
<li><strong>Spring AOP</strong>：通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。</li>
<li><strong>Spring DAO</strong>：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。</li>
<li><strong>Spring ORM</strong>：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。</li>
<li><strong>Spring Web 模块</strong>：Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。</li>
<li><strong>Spring MVC 框架</strong>：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。<h3 id="Spring-IOC原理"><a href="#Spring-IOC原理" class="headerlink" title="Spring IOC原理"></a>Spring IOC原理</h3><h4 id="IOC是什么"><a href="#IOC是什么" class="headerlink" title="IOC是什么"></a>IOC是什么</h4><center><br><img src="http://i.imgur.com/0DkVQ8t.png" alt=""></center><br>先来看看字面上怎么来解释：当一个对象创建时，它所依赖的对象由外部传递给它，而非自己去创建所依赖的对象（比如通过<font color="#FF7F00" size="3"> <strong>new</strong> </font>操作）。因此，也可以说在对象如何获取它的依赖对象这件事情上，控制权反转了。这便不难理解控制反转和依赖注入这两个名字的由来了。<h4 id="有个这样的场景"><a href="#有个这样的场景" class="headerlink" title="有个这样的场景"></a>有个这样的场景</h4>有个土豪老板，经常要出差，因此经常要订机票。定机票呢，可以通过<font color="red">去哪儿网</font>订票，也可以通过<font color="red">携程</font>订票。<br><br>我们马上可以想到可以通过三个类来表达这个场景，<font color="#FF3030">Boss</font>，<font color="#FF3030">QunarBookingService</font>，<font color="#FF3030">CtripBookingService</font>。当然了，我们还应该提供一个<font color="#FF3030">BookingService</font>接口，作为<font color="#FF3030">QunarBookingService</font>，<font color="#FF3030">CtripBookingService</font>的公共抽象。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">BookingService.java</div><div class="line"></div><div class="line">    <span class="keyword">package</span> com.dsky.iocdemo;</div><div class="line">    </div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BookingService</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">bookFlight</span><span class="params">()</span></span>;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">QunarBookingService.java</div><div class="line"></div><div class="line">    <span class="keyword">package</span> com.dsky.iocdemo;</div><div class="line">    </div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QunarBookingService</span> <span class="keyword">implements</span> <span class="title">BookingService</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bookFlight</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"book fight by Qunar!"</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">CtripBookingService.java</div><div class="line"></div><div class="line">    <span class="keyword">package</span> com.dsky.iocdemo;</div><div class="line">    </div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CtripBookingService</span> <span class="keyword">implements</span> <span class="title">BookingService</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">bookFlight</span><span class="params">()</span> </span>&#123;</div><div class="line">            System.out.println(<span class="string">"book fight by Ctrip!"</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>好了，土豪出门谈生意，得订机票了，Boss就琢磨着怎么订票呢，Boss比较了一下价格，这一次决定用去哪儿，对应的<font color="#FF3030">Boss</font>的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">Boss.java</div><div class="line"></div><div class="line">    <span class="keyword">package</span> com.tianmaying.iocdemo;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Boss</span> </span>&#123;</div><div class="line"></div><div class="line">        <span class="keyword">private</span> BookingService bookingService;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Boss</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.bookingService = <span class="keyword">new</span> QunarBookingService();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> BookingService <span class="title">getBookingService</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">return</span> bookingService;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBookingService</span><span class="params">(BookingService bookingService)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.bookingService = bookingService;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">goSomewhere</span><span class="params">()</span> </span>&#123;</div><div class="line">            bookingService.bookFlight();</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p>在 <font color="#FF3030">Boss</font>的构造函数中，将其 <font color="#FF3030">bookingService</font> 成员变量实例化为 <font color="#FF3030">​QunarBookingService</font> ， <font color="#FF3030">goSomewhere()</font> 函数中就可以调用 <font color="#FF3030">bookingService </font>的 <font color="#FF3030">bookFlight</font>方法了！</p>
<p>为了把这个场景Run起来，我们还需要一个main函数：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">App.java</div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">            bossGoSomewhere();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bossGoSomewhere</span><span class="params">()</span> </span>&#123;</div><div class="line">            Boss boss = <span class="keyword">new</span> Boss();</div><div class="line">            boss.goSomewhere();</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<h4 id="使用IoC的场景"><a href="#使用IoC的场景" class="headerlink" title="使用IoC的场景"></a>使用IoC的场景</h4><p>在这个例子中，我们看到 <font color="#FF3030">Boss</font> 需要使用<font color="#FF3030">BookingService</font>，于是 <font color="#FF3030">Boss</font> 自己实例化了一个 <font color="#FF3030">QunarBookingService</font> 对象。同志们想想，身为土豪 <font color="#FF3030">Boss</font>，思考的都是公司战略的事儿，定个票还要自己选择通过什么方式来完成，这个 <font color="#FF3030">Boss</font> 是不是当得实在太苦逼。</p>
<p>所以土豪赶紧给自己找了个美女秘书（别想歪!），<font color="#FF3030">Boss</font> 要出差时，只需要说一声他需要订票服务，至于是哪个服务，让美女秘书选好后告诉他即可（注入啊！注入！）。（别跟我较真说美女秘书直接把票送上就行！）</p>
<p>这样的话，<font color="">Boss</font>是不是一身轻松了？ 而这个美女秘书还是免费包邮的，这正是<strong>Spring</strong>扮演的角色！来看看使用<strong>Spring</strong>之后的代码。</p>
<p>我们在<strong>pom.xml</strong>文件中加入依赖（项目使用<strong>Maven</strong>作为构建工具）：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;4.2.0.RELEASE&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">``` java</div><div class="line">QunarBookingService.java</div><div class="line"></div><div class="line">    import org.springframework.stereotype.Component;</div><div class="line"></div><div class="line">    @Component</div><div class="line">    public class QunarBookingService implements BookingService &#123;</div><div class="line">        public void bookFlight() &#123;</div><div class="line">            System.out.println("book fight by Qunar!");</div><div class="line">        &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p>这里我们使用<strong>Spring</strong>的<strong>@Component</strong>标注将 <font color="#FF3030">QunarBookingService</font> 注册进<strong>Spring</strong>的<strong>Context</strong>，这样它就可以被注入到需要它的地方！相应地，创建 <font color="#FF3030">QunarBookingService</font>实例的责任也交给了<strong>Spring</strong><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">SmartBoss.java</div><div class="line"></div><div class="line">    <span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</div><div class="line">    <span class="keyword">import</span> org.springframework.stereotype.Component;</div><div class="line"></div><div class="line">    <span class="meta">@Component</span></div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SmartBoss</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> BookingService bookingService;</div><div class="line"></div><div class="line">        <span class="meta">@Autowired</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBookingService</span><span class="params">(BookingService bookingService)</span> </span>&#123;</div><div class="line">            <span class="keyword">this</span>.bookingService = bookingService;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> BookingService <span class="title">getBookingService</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">return</span> bookingService;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">goSomewhere</span><span class="params">()</span> </span>&#123;</div><div class="line">            bookingService.bookFlight();</div><div class="line">       &#125;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<h4 id="IoC的好处"><a href="#IoC的好处" class="headerlink" title="IoC的好处"></a>IoC的好处</h4><p>回到正题，通过上面的例子，我们来看看IoC到底带来了哪些好处？</p>
<p><font color="#FF3030">Boss</font> 没有和某个具体的 <font color="#FF3030">BookingService</font> 类耦合到一起了，这样 <font color="#FF3030">Boss</font> 的维护和演化就更加方便。想象一下，如果 <font color="#FF3030">Boss</font>需要改用 <font color="#FF3030">CtripBookingService</font>，这时也不需要修改 <font color="#FF3030">Boss.java</font>的代码，更换接口的实现非常方便，给 <font color="#FF3030">Boss</font> 注入新的实现即可，轻松惬意。（当然，要做到热插拔还需要进一步的工作，要么得玩转类加载器这玩意，或者借助 <font color="#FF3030">OSGi</font> 这样的神器）。这也是典型的开放-封闭原则的例子，即对现有模块，功能扩展应该是开放的，而对其代码修改应该是封闭的，即能够做到不需要修改已有代码来扩展新的功能。</p>
<p>想象一下，如果Boss自己直接去实例化 <font color="#FF3030">QunarBookingService</font>，而 <font color="#FF3030">QunarBookingService</font> 在另外一个<strong>Package</strong>中甚至另外一个<strong>Jar</strong>包中，你可得import进来才能使用，紧耦合啊！现在好了， <font color="#FF3030">Boss</font>只依赖于抽象接口，测试更方便了吧，Mock一下就轻松搞定！ <font color="#FF3030">Boss</font>和 <font color="#FF3030">QunarBookingService</font> 彼此不知道对方，Spring帮两者粘合在一起。</p>
<p>为什么IoC是个大招，因为它会自然而然得促进你应用一些好的设计原则，会帮助你开发出更加“高内聚低耦合”的软件</p>
<right><font color="grey" size="2">资料整理来自：<a><a href="http://www.tianmaying.com/tutorial/spring-ioc" target="_blank" rel="external">http://www.tianmaying.com/tutorial/spring-ioc</a></a></font></right>

<h3 id="Spring-AOP"><a href="#Spring-AOP" class="headerlink" title="Spring AOP"></a>Spring AOP</h3><p><strong>AOP</strong>其实就是一种关注点分离的技术，在软件工程领域一度是非常火的研究领域。软件开发时我们往往不能专注于业务逻辑，比如我们写业务逻辑代码的同时，还要写事务管理、缓存、日志等等通用化的功能，而且每个业务功能都要和这些业务功能混在一起。为了将业务功能的关注点和通用化功能的关注点分离开来，就出现了AOP技术。这些通用化功能的代码实现，对应的就是我们说的切面（<strong>Aspect</strong>）。</p>
<p>业务功能代码和切面代码分开之后，责任明确，比如有以下好处：</p>
<ul>
<li><strong>开发者就能各自专注解决问题</strong></li>
<li><strong>代码可以优雅的组织</strong></li>
<li><strong>设计更加高内聚低耦合</strong><br>###AOP的实现技术###<br>但是代码分开的同时，为了保证功能的完整性，业务功能依然需要有事务和日志等特性，即切面最终需要合并（专业术语叫做织入, Weave)到业务功能中，这涉及AOP的实现技术，有三种方式：</li>
</ul>
<p><strong><font color="#FF3030">1.编译时织入</font>：</strong>在代码编译时，把切面代码融合进来，生成完整功能的Java字节码，这就需要特殊的Java编译器了，AspectJ属于这一类<br><br><strong><font color="#FF3030">2.类加载时织入</font>：</strong>在Java字节码加载时，把切面的字节码融合进来，这就需要特殊的类加载器，AspectJ和AspectWerkz实现了类加载时织入<br><br><strong><font color="#FF3030">3.运行时织入</font>：</strong>在运行时，通过动态代理的方式，调用切面代码增强业务功能，Spring采用的正是这种方式。动态代理会有性能上的开销，但是好处就是不需要扩展编译器或者类加载器，和写普通Java程序没有区别。</p>
<p>###关键概念###</p>
<ul>
<li><strong>切面（Aspect）：</strong>指的就是通用功能的代码实现。</li>
<li><strong>目标对象（Target）：</strong>要被织入切面的对象，有了AOP，目标对象可以专注于核心业务逻辑代码了。</li>
<li><strong>切入点（Pointcut）：定</strong>义通知应该切入到什么地方，Spring支持的切入点就是方法调用，切入点的定义可以使用正则表达式，用以描述什么类型的方法调用。</li>
<li><strong>通知（Advice）：</strong>切面是一个类，而通知就是类里的方法以及这个方法如何织入到目标方法的方式，根据织入到目标方法方式的不同，一共可以分为5种：<br><font color="#FF3030" size="3"><br>    <strong>(1).前置通知（Before)</strong><br><br>    <strong>(2).后置通知（AfterReturning）</strong><br><br>    <strong>(3).异常通知（AfterThrowing）</strong><br><br>    <strong>(4).最终通知（After）</strong><br><br>    <strong>(5).环绕通知（Around）</strong><br><br></font></li>
<li><strong>织入（Weaving）：</strong>AOP实现的过程，即将切面应用到目标对象，从而创建一个新的代理对象的过程，对于Spring来说，就是初始化Context中的对象时，完成织入操作。<br><right><font color="grey" size="2">资料整理来自：<a><a href="http://www.tianmaying.com/qa/24" target="_blank" rel="external">http://www.tianmaying.com/qa/24</a></a></font></right>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo常用命令笔记]]></title>
      <url>http://Melodylican.github.io/2012/06/01/Hexo%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">npm install hexo -g #安装  </div><div class="line">npm update hexo -g #升级  </div><div class="line">hexo init #初始化</div></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="简写"><a href="#简写" class="headerlink" title="简写"></a>简写</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">hexo n "我的博客" == hexo new "我的博客" #新建文章</div><div class="line">hexo p == hexo publish</div><div class="line">hexo g == hexo generate#生成</div><div class="line">hexo s == hexo server #启动服务预览</div><div class="line">hexo d == hexo deploy#部署</div></pre></td></tr></table></figure>
<h2 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。</div><div class="line">hexo server -s #静态模式</div><div class="line">hexo server -p 5000 #更改端口</div><div class="line">hexo server -i 192.168.1.1 #自定义 IP</div><div class="line"></div><div class="line">hexo clean #清除缓存 网页正常情况下可以忽略此条命令</div><div class="line">hexo g #生成静态网页</div><div class="line">hexo d #开始部署</div></pre></td></tr></table></figure>
<h2 id="监视文件变动"><a href="#监视文件变动" class="headerlink" title="监视文件变动"></a>监视文件变动</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo generate #使用 Hexo 生成静态文件快速而且简单</div><div class="line">hexo generate --watch #监视文件变动</div></pre></td></tr></table></figure>
<h2 id="完成后部署"><a href="#完成后部署" class="headerlink" title="完成后部署"></a>完成后部署</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">两个命令的作用是相同的</div><div class="line">hexo generate --deploy</div><div class="line">hexo deploy --generate</div><div class="line"></div><div class="line">hexo deploy -g</div><div class="line">hexo server -g</div></pre></td></tr></table></figure>
<h2 id="草稿"><a href="#草稿" class="headerlink" title="草稿"></a>草稿</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo publish [layout] &lt;title&gt;</div></pre></td></tr></table></figure>
<h2 id="模版"><a href="#模版" class="headerlink" title="模版"></a>模版</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">hexo new "postName" #新建文章</div><div class="line">hexo new page "pageName" #新建页面</div><div class="line">hexo generate #生成静态页面至public目录</div><div class="line">hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）</div><div class="line">hexo deploy #将.deploy目录部署到GitHub</div><div class="line"></div><div class="line">hexo new [layout] &lt;title&gt;</div><div class="line">hexo new photo "My Gallery"</div><div class="line">hexo new "Hello World" --lang tw</div><div class="line"></div><div class="line">title: 使用Hexo搭建个人博客</div><div class="line">layout: post</div><div class="line">date: 2014-03-03 19:07:43</div><div class="line">comments: true</div><div class="line">categories: Blog</div><div class="line">tags: [Hexo]</div><div class="line">keywords: Hexo, Blog</div><div class="line">description: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。</div></pre></td></tr></table></figure>
<h2 id="模版（Scaffold）"><a href="#模版（Scaffold）" class="headerlink" title="模版（Scaffold）"></a>模版（Scaffold）</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo <span class="keyword">new</span> photo <span class="string">"My Gallery"</span></div></pre></td></tr></table></figure>
<h2 id="设置文章摘要"><a href="#设置文章摘要" class="headerlink" title="设置文章摘要"></a>设置文章摘要</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">以上是文章摘要 &lt;!--more--&gt; 以下是余下全文</div></pre></td></tr></table></figure>
<h2 id="写作"><a href="#写作" class="headerlink" title="写作"></a>写作</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo <span class="keyword">new</span> page &lt;title&gt;</div><div class="line">hexo <span class="keyword">new</span> post &lt;title&gt;</div></pre></td></tr></table></figure>
<h2 id="推送到服务器上"><a href="#推送到服务器上" class="headerlink" title="推送到服务器上"></a>推送到服务器上</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hexo n #写文章</div><div class="line">hexo g #生成</div><div class="line">hexo d #部署 #可与hexo g合并为 hexo d -g</div></pre></td></tr></table></figure>
<h2 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h2><h3 id="1-找不到git部署"><a href="#1-找不到git部署" class="headerlink" title="1.找不到git部署"></a>1.找不到git部署</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ERROR Deployer not found: git</div></pre></td></tr></table></figure>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save</div></pre></td></tr></table></figure>
<h3 id="2-部署类型设置git"><a href="#2-部署类型设置git" class="headerlink" title="2.部署类型设置git"></a>2.部署类型设置git</h3><p>hexo 3.0 部署类型不再是github，_config.yml 中修改<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># Deployment</div><div class="line">## Docs: http://hexo.io/docs/deployment.html</div><div class="line">deploy:</div><div class="line">  type: git</div><div class="line">  repository: git@***.github.com:***/***.github.io.git</div><div class="line">  branch: master</div></pre></td></tr></table></figure></p>
<h3 id="3-xcodebuild"><a href="#3-xcodebuild" class="headerlink" title="3. xcodebuild"></a>3. xcodebuild</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">xcode-select: error: tool <span class="string">'xcodebuild'</span> <span class="keyword">requires</span> Xcode, but active developer directory <span class="string">'/Library/Developer/CommandLineTools'</span> is a command line tools instance</div><div class="line"></div><div class="line">npm install bcrypt</div></pre></td></tr></table></figure>
<h3 id="4-RSS不显示"><a href="#4-RSS不显示" class="headerlink" title="4. RSS不显示"></a>4. RSS不显示</h3><h3 id="安装RSS插件"><a href="#安装RSS插件" class="headerlink" title="安装RSS插件"></a>安装RSS插件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-generator-feed --save</div></pre></td></tr></table></figure>
<h3 id="开启RSS功能"><a href="#开启RSS功能" class="headerlink" title="开启RSS功能"></a>开启RSS功能</h3><p>编辑hexo/_config.yml，添加如下代码：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rss: /atom.xml #rss地址  默认即可</div></pre></td></tr></table></figure></p>
<h2 id="开启评论"><a href="#开启评论" class="headerlink" title="开启评论"></a>开启评论</h2><p>1.我使用多说代替自带的评论，在多说 网站注册 &gt; 后台管理 &gt; 添加新站点 &gt; 工具 === 复制通用代码 里面有 short_name</p>
<p>1.在根目录 _config.yml 添加一行 disqus_shortname: jslite 是在多说注册时产生的</p>
<p>2.复制到 themes\landscape\layout_partial\article.ejs把<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt;</div><div class="line">&lt;section id="comments"&gt;</div><div class="line">&lt;div id="disqus_thread"&gt;</div><div class="line">  &lt;noscript&gt;Please enable JavaScript to view the &lt;a href="//disqus.com/?ref_noscript"&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;</div><div class="line">&lt;/div&gt;</div><div class="line">&lt;/section&gt;</div><div class="line">&lt;% &#125; %&gt;</div></pre></td></tr></table></figure></p>
<p>改为<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&lt;% if (!index &amp;&amp; post.comments &amp;&amp; config.disqus_shortname)&#123; %&gt;</div><div class="line">  &lt;section id="comments"&gt;</div><div class="line">    &lt;!-- 多说评论框 start --&gt;</div><div class="line">    &lt;div class="ds-thread" data-thread-key="&lt;%= post.layout %&gt;-&lt;%= post.slug %&gt;" data-title="&lt;%= post.title %&gt;" data-url="&lt;%= page.permalink %&gt;"&gt;&lt;/div&gt;</div><div class="line">    &lt;!-- 多说评论框 end --&gt;</div><div class="line">    &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt;</div><div class="line">    &lt;script type="text/javascript"&gt;</div><div class="line">    var duoshuoQuery = &#123;short_name:'&lt;%= config.disqus_shortname %&gt;'&#125;;</div><div class="line">      (function() &#123;</div><div class="line">        var ds = document.createElement('script');</div><div class="line">        ds.type = 'text/javascript';ds.async = true;</div><div class="line">        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';</div><div class="line">        ds.charset = 'UTF-8';</div><div class="line">        (document.getElementsByTagName('head')[0] </div><div class="line">         || document.getElementsByTagName('body')[0]).appendChild(ds);</div><div class="line">      &#125;)();</div><div class="line">      &lt;/script&gt;</div><div class="line">    &lt;!-- 多说公共JS代码 end --&gt;</div><div class="line">  &lt;/section&gt;</div><div class="line">&lt;% &#125; %&gt;</div></pre></td></tr></table></figure></p>
]]></content>
      
        <categories>
            
            <category> 笔记 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>http://Melodylican.github.io/2012/06/01/test/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.<br><a id="more"></a></p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        <categories>
            
            <category> Hexo学习 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>http://Melodylican.github.io/2012/06/01/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.<br><a id="more"></a></p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        <categories>
            
            <category> Hexo学习 </category>
            
        </categories>
        
        
    </entry>
    
  
  
</search>
